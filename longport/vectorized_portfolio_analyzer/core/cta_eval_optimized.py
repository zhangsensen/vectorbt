#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ğŸš€ Phase 3 - å†…å­˜ä¸ç¼“å­˜æè‡´ä¼˜åŒ–
===============================

é©å‘½æ€§ä¼˜åŒ–ç›®æ ‡ï¼š3.5s â†’ 0.4s (8.75xåŠ é€Ÿ)ï¼Œ710MB â†’ 400MB (1.77xå†…å­˜ä¼˜åŒ–)
æ ¸å¿ƒï¼šå› å­ç¼“å­˜ + ç²¾åº¦é™çº§ + ç¨€ç–çŸ©é˜µ + å†…å­˜ç›‘æ§
"""

import time
import os
import sys
import numpy as np
import pandas as pd
import vectorbt as vbt
from typing import Dict, List, Any, Tuple
import psutil
import warnings
from functools import lru_cache
from scipy import sparse
import gc
warnings.filterwarnings('ignore')

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
from factors.factor_pool import AdvancedFactorPool
from utils.dtype_fixer import CategoricalDtypeFixer

class CTAEvaluatorOptimized:
    """ğŸš€ Phase 3: å†…å­˜ä¸ç¼“å­˜æè‡´ä¼˜åŒ–è¯„ä¼°å™¨"""
    
    def __init__(self, 
                 look_ahead: int = 6,
                 entry_percentile: float = 0.90,
                 exit_percentile: float = 0.10,
                 sl_stop: float = 0.02,
                 tp_stop: float = 0.03,
                 direction: str = 'both',
                 slippage: float = 0.001,
                 fees: float = 0.0005,
                 min_trades: int = 30):
        """åˆå§‹åŒ–æè‡´ä¼˜åŒ–è¯„ä¼°å™¨"""
        self.look_ahead = look_ahead
        self.entry_percentile = entry_percentile
        self.exit_percentile = exit_percentile
        self.sl_stop = sl_stop
        self.tp_stop = tp_stop
        self.direction = direction
        self.slippage = slippage
        self.fees = fees
        self.min_trades = min_trades
        
        # ä¼˜åŒ–ç»„ä»¶
        self.factor_pool = AdvancedFactorPool()
        self.dtype_fixer = CategoricalDtypeFixer()
        
        # å†…å­˜ç›‘æ§
        self.process = psutil.Process(os.getpid())
        
    def log_memory(self, stage: str) -> float:
        """ğŸ” ç²¾ç¡®å†…å­˜ç›‘æ§"""
        try:
            memory_mb = self.process.memory_info().rss / 1024 / 1024
            print(f"ğŸ’¾ PeakRAM {memory_mb:.1f} MB ({stage})")
            return memory_mb
        except:
            return 0.0
    
    def force_gc(self, stage: str):
        """ğŸ§¹ å¼ºåˆ¶åƒåœ¾å›æ”¶"""
        gc.collect()
        print(f"ğŸ§¹ GCæ¸…ç† ({stage})")
    
    @lru_cache(maxsize=1)
    def get_cached_symbols_tuple(self, symbols_tuple: Tuple[str]) -> Tuple[str]:
        """ç¼“å­˜ç¬¦å·å…ƒç»„ä»¥æ”¯æŒlru_cache"""
        return symbols_tuple
    
    @lru_cache(maxsize=10)
    def load_cached_price_data(self, symbols_tuple: Tuple[str], data_dir: str, timeframe: str) -> pd.DataFrame:
        """ğŸ”¥ Phase 3æ ¸å¿ƒ: ç¼“å­˜ä»·æ ¼æ•°æ®åŠ è½½"""
        print(f"ğŸ’¾ ç¼“å­˜åŠ è½½ä»·æ ¼æ•°æ®: {len(symbols_tuple)}åªè‚¡ç¥¨")
        
        timeframe_dir = f"{data_dir}/{timeframe}"
        price_dfs = []
        
        for symbol in symbols_tuple:
            try:
                file_path = f"{timeframe_dir}/{symbol}.parquet"
                if os.path.exists(file_path):
                    df = pd.read_parquet(file_path)
                    if not df.empty and 'close' in df.columns:
                        # ğŸ”¥ é™ç²¾åº¦ä¼˜åŒ–: float64 â†’ float32
                        price_series = df['close'].astype('float32')
                        price_series.name = symbol
                        price_dfs.append(price_series)
            except Exception as e:
                print(f"âš ï¸ åŠ è½½ {symbol} å¤±è´¥: {e}")
                continue
        
        if not price_dfs:
            raise ValueError("æ²¡æœ‰æˆåŠŸåŠ è½½ä»»ä½•ä»·æ ¼æ•°æ®")
        
        # æ„å»ºä»·æ ¼DataFrameå¹¶é™ç²¾åº¦
        price_df = pd.concat(price_dfs, axis=1, sort=True).dropna()
        price_df = price_df.astype('float32')
        
        print(f"âœ… ç¼“å­˜ä»·æ ¼çŸ©é˜µ: {price_df.shape} (time Ã— asset)")
        return price_df
    
    @lru_cache(maxsize=10)
    def calculate_cached_factors(self, symbols_tuple: Tuple[str], data_dir: str, timeframe: str) -> Dict[str, Any]:
        """ğŸ”¥ Phase 3æ ¸å¿ƒ: ç¼“å­˜å› å­è®¡ç®—"""
        print(f"ğŸ§  ç¼“å­˜è®¡ç®—å› å­: {len(symbols_tuple)}åªè‚¡ç¥¨")
        
        timeframe_dir = f"{data_dir}/{timeframe}"
        aligned_factor_data = {}
        all_factor_names = set()
        
        # ç¬¬ä¸€éï¼šè®¡ç®—æ‰€æœ‰å› å­å¹¶æ”¶é›†åç§°
        temp_factor_data = {}
        for symbol in symbols_tuple:
            try:
                file_path = f"{timeframe_dir}/{symbol}.parquet"
                if os.path.exists(file_path):
                    df = pd.read_parquet(file_path)
                    if not df.empty and 'close' in df.columns:
                        # è®¡ç®—å› å­
                        factors_df = self.factor_pool.calculate_all_factors(df)
                        factors_df = self.dtype_fixer.fix_categorical_dataframe(factors_df)
                        
                        # ğŸ”¥ é™ç²¾åº¦ä¼˜åŒ–: æ•°å€¼åˆ— â†’ float32
                        numeric_cols = factors_df.select_dtypes(include=[np.number]).columns
                        factors_df[numeric_cols] = factors_df[numeric_cols].astype('float32')
                        
                        # å»é™¤NaNå’Œå¸¸æ•°åˆ—
                        factors_df = factors_df.dropna(axis=1, how='all')
                        for col in factors_df.columns:
                            if factors_df[col].nunique() <= 1:
                                factors_df = factors_df.drop(columns=[col])
                        
                        temp_factor_data[symbol] = factors_df
                        all_factor_names.update(factors_df.columns)
            except Exception as e:
                print(f"âš ï¸ è®¡ç®— {symbol} å› å­å¤±è´¥: {e}")
                continue
        
        all_factor_names = sorted(list(all_factor_names))
        
        # ç¬¬äºŒéï¼šå¯¹é½æ‰€æœ‰å› å­
        common_index = None
        for symbol_factors in temp_factor_data.values():
            if common_index is None:
                common_index = symbol_factors.index
            else:
                common_index = common_index.intersection(symbol_factors.index)
        
        if common_index is None or len(common_index) == 0:
            raise ValueError("æ²¡æœ‰å…±åŒçš„æ—¶é—´ç´¢å¼•")
        
        for symbol in symbols_tuple:
            if symbol in temp_factor_data:
                symbol_factors = temp_factor_data[symbol].reindex(common_index)
                
                # ç¡®ä¿æ‰€æœ‰å› å­éƒ½å­˜åœ¨
                for factor_name in all_factor_names:
                    if factor_name not in symbol_factors.columns:
                        symbol_factors[factor_name] = np.nan
                
                # é‡æ–°æ’åºå¹¶é™ç²¾åº¦
                symbol_factors = symbol_factors.reindex(columns=all_factor_names)
                symbol_factors = symbol_factors.astype('float32')
                
                aligned_factor_data[symbol] = symbol_factors
        
        factor_info = {
            'data': aligned_factor_data,
            'factor_names': all_factor_names,
            'shape': (len(common_index), len(symbols_tuple), len(all_factor_names)),
            'index': common_index
        }
        
        print(f"âœ… ç¼“å­˜å› å­æ•°æ®: {factor_info['shape']} (time Ã— asset Ã— factor)")
        return factor_info
    
    def generate_sparse_signals(self, factor_info: Dict[str, Any], price_df: pd.DataFrame) -> Tuple[sparse.csr_matrix, sparse.csr_matrix]:
        """ğŸ”¥ Phase 3æ ¸å¿ƒ: ç”Ÿæˆç¨€ç–ä¿¡å·çŸ©é˜µ"""
        print(f"âš¡ ç”Ÿæˆç¨€ç–ä¿¡å·çŸ©é˜µ...")
        
        # åŠ¨æ€çª—å£å¤§å°
        time_len = len(price_df)
        window = min(288, time_len // 4) if time_len > 100 else time_len
        min_periods = min(20, window // 2)
        
        print(f"   ä¿¡å·çª—å£: {window}, æœ€å°å‘¨æœŸ: {min_periods}")
        
        # é¢„åˆ†é…ç¨€ç–çŸ©é˜µæ•°æ®
        n_time = len(price_df)
        n_combinations = len(price_df.columns) * len(factor_info['factor_names'])
        
        # ä½¿ç”¨åˆ—è¡¨æ”¶é›†éé›¶å…ƒç´ 
        entries_rows, entries_cols, entries_data = [], [], []
        exits_rows, exits_cols, exits_data = [], [], []
        
        col_idx = 0
        for asset in price_df.columns:
            if asset in factor_info['data']:
                asset_factors = factor_info['data'][asset]
                
                for factor_name in factor_info['factor_names']:
                    factor_series = asset_factors[factor_name]
                    
                    # è®¡ç®—æ»šåŠ¨åˆ†ä½æ•°
                    entry_threshold = factor_series.rolling(window=window, min_periods=min_periods).quantile(self.entry_percentile)
                    exit_threshold = factor_series.rolling(window=window, min_periods=min_periods).quantile(self.exit_percentile)
                    
                    # ç”Ÿæˆä¿¡å· (bool â†’ int8)
                    entries = (factor_series > entry_threshold).astype('int8')
                    exits = (factor_series < exit_threshold).astype('int8')
                    
                    # æ”¶é›†éé›¶å…ƒç´ 
                    entry_nonzero = np.where(entries == 1)[0]
                    exit_nonzero = np.where(exits == 1)[0]
                    
                    entries_rows.extend(entry_nonzero)
                    entries_cols.extend([col_idx] * len(entry_nonzero))
                    entries_data.extend([1] * len(entry_nonzero))
                    
                    exits_rows.extend(exit_nonzero)
                    exits_cols.extend([col_idx] * len(exit_nonzero))
                    exits_data.extend([1] * len(exit_nonzero))
                    
                    col_idx += 1
        
        # æ„å»ºç¨€ç–çŸ©é˜µ
        entries_sparse = sparse.csr_matrix(
            (entries_data, (entries_rows, entries_cols)), 
            shape=(n_time, n_combinations),
            dtype='int8'
        )
        
        exits_sparse = sparse.csr_matrix(
            (exits_data, (exits_rows, exits_cols)), 
            shape=(n_time, n_combinations),
            dtype='int8'
        )
        
        print(f"âœ… ç¨€ç–ä¿¡å·ç”Ÿæˆå®Œæˆ:")
        print(f"   entries: {entries_sparse.shape}, éé›¶å…ƒç´ : {entries_sparse.nnz}/{entries_sparse.size} ({100*entries_sparse.nnz/entries_sparse.size:.2f}%)")
        print(f"   exits: {exits_sparse.shape}, éé›¶å…ƒç´ : {exits_sparse.nnz}/{exits_sparse.size} ({100*exits_sparse.nnz/exits_sparse.size:.2f}%)")
        
        return entries_sparse, exits_sparse
    
    def get_annual_factor(self, timeframe: str = '5m') -> float:
        """è®¡ç®—å¹´åŒ–å› å­ - æŒ‰æŒä»“å‘¨æœŸè°ƒæ•´"""
        periods_per_year = {
            '1m': 252 * 240,
            '5m': 252 * 48,
            '15m': 252 * 16,
            '30m': 252 * 8,
            '1h': 252 * 4,
            '4h': 252,
            '1d': 252
        }
        
        base_periods = periods_per_year.get(timeframe, 252 * 48)
        holding_periods = self.look_ahead
        adjusted_periods = base_periods / holding_periods
        
        return np.sqrt(adjusted_periods)
    
    def batch_evaluate(self, symbols: List[str], factor_data: Dict[str, pd.DataFrame],
                      price_data: Dict[str, pd.DataFrame], factor_names: List[str],
                      timeframe: str = '5m') -> pd.DataFrame:
        """ğŸš€ Phase 3æ ¸å¿ƒ: æè‡´ä¼˜åŒ–æ‰¹é‡è¯„ä¼°"""
        
        print(f"ğŸš€ Phase 3 æè‡´ä¼˜åŒ–æ‰¹é‡å›æµ‹å¯åŠ¨...")
        total_start = time.time()
        
        # è®°å½•åˆå§‹å†…å­˜
        start_memory = self.log_memory("å¼€å§‹")
        
        try:
            # Step 1: ç¼“å­˜åŠ è½½æ•°æ®
            symbols_tuple = tuple(symbols)
            data_dir = "../vectorbt_workspace/data"
            
            # ğŸ”¥ ç¼“å­˜ä»·æ ¼æ•°æ® (ç¬¬äºŒæ¬¡è°ƒç”¨å°†ä»ç¼“å­˜è¿”å›)
            price_df = self.load_cached_price_data(symbols_tuple, data_dir, timeframe)
            self.log_memory("ç¼“å­˜ä»·æ ¼åŠ è½½")
            
            # ğŸ”¥ ç¼“å­˜å› å­æ•°æ® (ç¬¬äºŒæ¬¡è°ƒç”¨å°†ä»ç¼“å­˜è¿”å›)
            factor_info = self.calculate_cached_factors(symbols_tuple, data_dir, timeframe)
            self.log_memory("ç¼“å­˜å› å­è®¡ç®—")
            
            # éªŒè¯ç¼“å­˜æ•ˆæœ
            print(f"ğŸ§  ç¼“å­˜ç»Ÿè®¡: price_dataç¼“å­˜={self.load_cached_price_data.cache_info()}")
            print(f"ğŸ§  ç¼“å­˜ç»Ÿè®¡: factor_dataç¼“å­˜={self.calculate_cached_factors.cache_info()}")
            
            # Step 2: ç”Ÿæˆç¨€ç–ä¿¡å·
            entries_sparse, exits_sparse = self.generate_sparse_signals(factor_info, price_df)
            self.log_memory("ç¨€ç–ä¿¡å·ç”Ÿæˆ")
            
            # å¼ºåˆ¶åƒåœ¾å›æ”¶
            self.force_gc("ä¿¡å·ç”Ÿæˆå")
            
            # Step 3: æ„å»ºä»·æ ¼çŸ©é˜µ (é™ç²¾åº¦)
            print(f"ğŸ”§ æ„å»ºä¼˜åŒ–ä»·æ ¼çŸ©é˜µ...")
            
            price_matrix = []
            for asset in price_df.columns:
                for factor_name in factor_info['factor_names']:
                    price_matrix.append(price_df[asset])
            
            price_matrix_df = pd.concat(price_matrix, axis=1).astype('float32')
            
            # åˆ›å»ºMultiIndexåˆ—å
            multi_columns = []
            for asset in price_df.columns:
                for factor in factor_info['factor_names']:
                    multi_columns.append((asset, factor))
            
            price_matrix_df.columns = pd.MultiIndex.from_tuples(multi_columns, names=['asset', 'factor'])
            
            print(f"âœ… ä¼˜åŒ–ä»·æ ¼çŸ©é˜µ: {price_matrix_df.shape} (time Ã— [asset_factor])")
            self.log_memory("ä»·æ ¼çŸ©é˜µæ„å»º")
            
            # Step 4: è½¬æ¢ç¨€ç–çŸ©é˜µä¸ºå¯†é›†çŸ©é˜µ (VectorBTè¦æ±‚)
            print(f"ğŸ”„ è½¬æ¢ç¨€ç–çŸ©é˜µä¸ºVectorBTæ ¼å¼...")
            
            entries_dense = entries_sparse.toarray().astype('int8')
            exits_dense = exits_sparse.toarray().astype('int8')
            
            entries_df = pd.DataFrame(entries_dense, index=price_df.index, columns=price_matrix_df.columns, dtype='int8')
            exits_df = pd.DataFrame(exits_dense, index=price_df.index, columns=price_matrix_df.columns, dtype='int8')
            
            # æ¸…ç†ç¨€ç–çŸ©é˜µ
            del entries_sparse, exits_sparse
            self.force_gc("ç¨€ç–çŸ©é˜µæ¸…ç†")
            self.log_memory("å¯†é›†çŸ©é˜µè½¬æ¢")
            
            # Step 5: ğŸ”¥ VectorBTæè‡´ä¼˜åŒ–å›æµ‹
            print(f"ğŸš€ æ‰§è¡ŒVectorBTæè‡´ä¼˜åŒ–å›æµ‹...")
            
            pf = vbt.Portfolio.from_signals(
                close=price_matrix_df,
                entries=entries_df,
                exits=exits_df,
                sl_stop=self.sl_stop if self.sl_stop > 0 else None,
                tp_stop=self.tp_stop if self.tp_stop > 0 else None,
                direction=self.direction,
                init_cash=100000,
                fees=self.fees,
                slippage=self.slippage,
                freq='5min'
            )
            
            print(f"âœ… VectorBTæè‡´å›æµ‹å®Œæˆ")
            self.log_memory("å›æµ‹å®Œæˆ")
            
            # Step 6: æå–å’Œä¼˜åŒ–ç»“æœ
            print(f"ğŸ“Š æå–ä¼˜åŒ–ç»“æœ...")
            
            # è·å–æŒ‡æ ‡
            sharpe_ratios = pf.sharpe_ratio()
            
            # å¹´åŒ–è°ƒæ•´å’Œæ•°å€¼å¤„ç†
            annual_factor = self.get_annual_factor(timeframe)
            adjusted_sharpe = sharpe_ratios / annual_factor
            adjusted_sharpe = adjusted_sharpe.replace([np.inf, -np.inf], np.nan).fillna(0)
            
            # æŒ‰å› å­èšåˆ
            results = []
            for factor in factor_info['factor_names']:
                factor_mask = adjusted_sharpe.index.get_level_values('factor') == factor
                factor_sharpes = adjusted_sharpe[factor_mask]
                
                if len(factor_sharpes) > 0:
                    valid_sharpes = factor_sharpes[~factor_sharpes.isna()]
                    
                    if len(valid_sharpes) > 0:
                        mean_sharpe = valid_sharpes.mean()
                        std_sharpe = valid_sharpes.std()
                        
                        if not (np.isnan(mean_sharpe) or np.isinf(mean_sharpe)):
                            results.append({
                                'factor': factor,
                                'sharpe': float(mean_sharpe),
                                'sharpe_std': float(std_sharpe) if not np.isnan(std_sharpe) else 0.0,
                                'asset_count': len(valid_sharpes),
                                'annual_factor': float(annual_factor)
                            })
            
            # æ¸…ç†å¤§å¯¹è±¡
            del price_matrix_df, entries_df, exits_df, pf
            self.force_gc("æœ€ç»ˆæ¸…ç†")
            
            # è®°å½•ç»“æŸ
            end_memory = self.log_memory("ç»“æŸ")
            total_time = time.time() - total_start
            
            print(f"âœ… Phase 3æè‡´ä¼˜åŒ–å®Œæˆ")
            print(f"TotalTime {total_time:.1f} s  PeakRAM {max(start_memory, end_memory):.1f} MB")
            
            return pd.DataFrame(results)
            
        except Exception as e:
            print(f"âŒ Phase 3æè‡´ä¼˜åŒ–å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            return pd.DataFrame()


def main():
    """Phase 3éªŒè¯ä¸»å‡½æ•°"""
    import argparse
    
    parser = argparse.ArgumentParser(description='Phase 3 æè‡´ä¼˜åŒ–éªŒè¯')
    parser.add_argument('--mini', nargs=2, help='è¿·ä½ æµ‹è¯•æ¨¡å¼: stock_count factor_count')
    args = parser.parse_args()
    
    print("ğŸš€ Phase 3 - å†…å­˜ä¸ç¼“å­˜æè‡´ä¼˜åŒ–éªŒè¯")
    print("=" * 60)
    
    # åˆå§‹åŒ–è¯„ä¼°å™¨
    evaluator = CTAEvaluatorOptimized()
    
    if args.mini:
        stock_count, factor_count = map(int, args.mini)
        print(f"ğŸ§ª è¿·ä½ æµ‹è¯•æ¨¡å¼: {stock_count}åªè‚¡ç¥¨ Ã— {factor_count}ä¸ªå› å­")
        
        # æµ‹è¯•è‚¡ç¥¨åˆ—è¡¨
        all_symbols = ['0005.HK', '0020.HK', '0175.HK', '0291.HK', '0340.HK']
        test_symbols = all_symbols[:stock_count]
    else:
        # å®Œæ•´æµ‹è¯•
        test_symbols = ['0005.HK', '0020.HK', '0175.HK', '0291.HK', '0340.HK']
        factor_count = 56
    
    try:
        # é¢„åŠ è½½ç¼“å­˜æ•°æ®
        symbols_tuple = tuple(test_symbols)
        data_dir = "../vectorbt_workspace/data"
        timeframe = "5m"
        
        price_df = evaluator.load_cached_price_data(symbols_tuple, data_dir, timeframe)
        factor_info = evaluator.calculate_cached_factors(symbols_tuple, data_dir, timeframe)
        
        # è·å–å› å­åç§°
        all_factors = factor_info['factor_names']
        factor_names = all_factors[:factor_count] if args.mini else all_factors
        
        print(f"ğŸ“Š æµ‹è¯•é…ç½®: {len(test_symbols)}åªè‚¡ç¥¨ Ã— {len(factor_names)}ä¸ªå› å­")
        
        # æ„å»ºæ¨¡æ‹Ÿè¾“å…¥ï¼ˆå…¼å®¹åŸæ¥å£ï¼‰
        price_data = {symbol: pd.DataFrame({'close': price_df[symbol]}) for symbol in test_symbols}
        factor_data = {}
        
        for symbol in test_symbols:
            symbol_factors = factor_info['data'][symbol]
            available_factors = [f for f in factor_names if f in symbol_factors.columns]
            factor_data[symbol] = symbol_factors[available_factors]
        
        factor_names = available_factors
        
        # Phase 2åŸºå‡†æµ‹è¯• (å¯¹æ¯”ç”¨)
        print(f"\nğŸ” Phase 2åŸºå‡†æµ‹è¯•...")
        from core.cta_eval_vectorized import CTAEvaluatorVectorized
        phase2_evaluator = CTAEvaluatorVectorized()
        
        phase2_start = time.time()
        phase2_results = phase2_evaluator.batch_evaluate(
            symbols=test_symbols,
            factor_data=factor_data,
            price_data=price_data,
            factor_names=factor_names,
            timeframe=timeframe
        )
        phase2_time = time.time() - phase2_start
        
        print(f"Phase 2åŸºå‡†: {phase2_time:.1f}s, {len(phase2_results)}ä¸ªå› å­")
        
        # Phase 3ä¼˜åŒ–æµ‹è¯•
        print(f"\nğŸš€ Phase 3ä¼˜åŒ–æµ‹è¯•...")
        phase3_results = evaluator.batch_evaluate(
            symbols=test_symbols,
            factor_data=factor_data,
            price_data=price_data,
            factor_names=factor_names,
            timeframe=timeframe
        )
        
        # éªŒè¯ç»“æœ
        if not phase3_results.empty:
            print(f"âœ… Phase 3ç”Ÿæˆ {len(phase3_results)} ä¸ªå› å­ç»“æœ")
            print(f"ğŸ“ˆ æœ€ä½³å¤æ™®ç‡: {phase3_results['sharpe'].max():.4f}")
            print(f"ğŸ“Š å¹³å‡å¤æ™®ç‡: {phase3_results['sharpe'].mean():.4f}")
            
            # æ€§èƒ½å¯¹æ¯”
            if not phase2_results.empty:
                print(f"\nğŸ” Phase 2 vs Phase 3 å¯¹æ¯”:")
                print(f"   å› å­æ•°é‡: {len(phase2_results)} vs {len(phase3_results)}")
                
                # è®¡ç®—å¤æ™®å·®å¼‚
                if len(phase2_results) == len(phase3_results):
                    phase2_sharpes = phase2_results.set_index('factor')['sharpe']
                    phase3_sharpes = phase3_results.set_index('factor')['sharpe']
                    
                    common_factors = phase2_sharpes.index.intersection(phase3_sharpes.index)
                    if len(common_factors) > 0:
                        sharpe_diff = (phase2_sharpes[common_factors] - phase3_sharpes[common_factors]).abs()
                        max_sharpe_err = sharpe_diff.max()
                        print(f"   MaxSharpeErr: {max_sharpe_err:.6f}")
        else:
            print("âŒ Phase 3è¯„ä¼°ç»“æœä¸ºç©º")
            
    except Exception as e:
        print(f"âŒ æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    main()
