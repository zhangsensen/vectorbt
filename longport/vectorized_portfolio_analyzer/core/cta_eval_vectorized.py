#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ğŸš€ Phase 2 - VectorBTåŸç”Ÿæ‰¹é‡å›æµ‹
================================

é©å‘½æ€§çš„å•æ¬¡æ‰¹é‡å›æµ‹ï¼Œé¢„æœŸæ€§èƒ½ï¼š8.4s â†’ 0.4s (20xåŠ é€Ÿ)
æ ¸å¿ƒï¼šæ„å»ºä¸‰ç»´æ•°æ®ï¼Œå•æ¬¡Portfolio.from_signalsè°ƒç”¨
"""

import time
import os
import sys
import numpy as np
import pandas as pd
import vectorbt as vbt
# import xarray as xr  # æ”¹ç”¨pandaså®ç°
from typing import Dict, List, Any, Tuple
import psutil
import warnings
warnings.filterwarnings('ignore')

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
from factors.factor_pool import AdvancedFactorPool
from utils.dtype_fixer import CategoricalDtypeFixer

class CTAEvaluatorVectorized:
    """ğŸš€ Phase 2: VectorBTåŸç”Ÿæ‰¹é‡è¯„ä¼°å™¨"""
    
    def __init__(self, 
                 look_ahead: int = 6,
                 entry_percentile: float = 0.90,
                 exit_percentile: float = 0.10,
                 sl_stop: float = 0.02,
                 tp_stop: float = 0.03,
                 direction: str = 'both',
                 slippage: float = 0.001,
                 fees: float = 0.0005,
                 min_trades: int = 30):
        """åˆå§‹åŒ–å‘é‡åŒ–è¯„ä¼°å™¨"""
        self.look_ahead = look_ahead
        self.entry_percentile = entry_percentile
        self.exit_percentile = exit_percentile
        self.sl_stop = sl_stop
        self.tp_stop = tp_stop
        self.direction = direction
        self.slippage = slippage
        self.fees = fees
        self.min_trades = min_trades
        
        # åˆå§‹åŒ–ç»„ä»¶
        self.factor_pool = AdvancedFactorPool()
        self.dtype_fixer = CategoricalDtypeFixer()
        
    def log_memory(self, stage: str):
        """å†…å­˜ç›‘æ§"""
        try:
            process = psutil.Process(os.getpid())
            memory_mb = process.memory_info().rss / 1024 / 1024
            print(f"PeakRAM {memory_mb:.1f} MB ({stage})")
            return memory_mb
        except:
            return 0.0
    
    def get_annual_factor(self, timeframe: str = '5m') -> float:
        """è®¡ç®—å¹´åŒ–å› å­ - æŒ‰æŒä»“å‘¨æœŸè°ƒæ•´"""
        periods_per_year = {
            '1m': 252 * 240,
            '5m': 252 * 48,
            '15m': 252 * 16,
            '30m': 252 * 8,
            '1h': 252 * 4,
            '4h': 252,
            '1d': 252
        }
        
        base_periods = periods_per_year.get(timeframe, 252 * 48)
        holding_periods = self.look_ahead
        adjusted_periods = base_periods / holding_periods
        
        return np.sqrt(adjusted_periods)
    
    def preload_vectorized_data(self, symbols: List[str], data_dir: str = "../vectorbt_workspace/data", 
                               timeframe: str = "5m") -> Tuple[pd.DataFrame, Dict[str, Any]]:
        """ğŸ”¥ Phase 2æ ¸å¿ƒ: é¢„åŠ è½½å‘é‡åŒ–æ•°æ®ç»“æ„ (pandasç‰ˆæœ¬)"""
        print(f"ğŸ“‚ Phase 2é¢„åŠ è½½: æ„å»ºå‘é‡åŒ–æ•°æ®ç»“æ„...")
        start_time = time.time()
        
        timeframe_dir = f"{data_dir}/{timeframe}"
        
        # Step 1: æ„å»ºä»·æ ¼çŸ©é˜µ (time Ã— asset)
        price_dfs = []
        factor_data = {}
        
        for symbol in symbols:
            try:
                file_path = f"{timeframe_dir}/{symbol}.parquet"
                if os.path.exists(file_path):
                    df = pd.read_parquet(file_path)
                    if not df.empty and 'close' in df.columns:
                        # è®¡ç®—å› å­
                        factors_df = self.factor_pool.calculate_all_factors(df)
                        factors_df = self.dtype_fixer.fix_categorical_dataframe(factors_df)
                        
                        # æ•°æ®ç±»å‹ä¼˜åŒ–
                        numeric_cols = factors_df.select_dtypes(include=[np.number]).columns
                        factors_df[numeric_cols] = factors_df[numeric_cols].astype('float32')
                        
                        # å»é™¤NaNå’Œå¸¸æ•°åˆ—
                        factors_df = factors_df.dropna(axis=1, how='all')
                        for col in factors_df.columns:
                            if factors_df[col].nunique() <= 1:
                                factors_df = factors_df.drop(columns=[col])
                        
                        # ä¿å­˜ä»·æ ¼æ•°æ®
                        price_series = df['close'].astype('float32')
                        price_series.name = symbol
                        price_dfs.append(price_series)
                        
                        # ä¿å­˜å› å­æ•°æ®
                        factor_data[symbol] = factors_df
                        
            except Exception as e:
                print(f"âš ï¸ åŠ è½½ {symbol} å¤±è´¥: {e}")
                continue
        
        if not price_dfs:
            raise ValueError("æ²¡æœ‰æˆåŠŸåŠ è½½ä»»ä½•æ•°æ®")
        
        # Step 2: æ„å»ºä»·æ ¼DataFrame (time Ã— asset)
        price_df = pd.concat(price_dfs, axis=1, sort=True).dropna()
        price_df = price_df.astype('float32')
        
        print(f"âœ… ä»·æ ¼çŸ©é˜µ: {price_df.shape} (time Ã— asset)")
        
        # Step 3: æ„å»ºå› å­æ•°æ®ç»“æ„ (pandasç‰ˆæœ¬)
        all_factor_names = set()
        
        # æ”¶é›†æ‰€æœ‰å› å­åç§°
        for factors_df in factor_data.values():
            all_factor_names.update(factors_df.columns)
        
        all_factor_names = sorted(list(all_factor_names))
        
        # æ„å»ºç»Ÿä¸€çš„å› å­DataFrameå­—å…¸
        aligned_factor_data = {}
        for symbol in price_df.columns:
            if symbol in factor_data:
                symbol_factors = factor_data[symbol].reindex(price_df.index)
                
                # ç¡®ä¿æ‰€æœ‰å› å­éƒ½å­˜åœ¨ï¼Œç¼ºå¤±çš„ç”¨NaNå¡«å……
                for factor_name in all_factor_names:
                    if factor_name not in symbol_factors.columns:
                        symbol_factors[factor_name] = np.nan
                
                # é‡æ–°æ’åºåˆ—
                symbol_factors = symbol_factors.reindex(columns=all_factor_names)
                symbol_factors = symbol_factors.astype('float32')
                
                aligned_factor_data[symbol] = symbol_factors
        
        # æ„å»ºå› å­ä¿¡æ¯
        factor_info = {
            'data': aligned_factor_data,
            'factor_names': all_factor_names,
            'shape': (len(price_df), len(price_df.columns), len(all_factor_names))
        }
        
        elapsed = time.time() - start_time
        print(f"âœ… å› å­æ•°æ®: {factor_info['shape']} (time Ã— asset Ã— factor)")
        print(f"âœ… å‘é‡åŒ–é¢„åŠ è½½å®Œæˆ: è€—æ—¶ {elapsed:.1f}s")
        
        return price_df, factor_info
    
    def generate_vectorized_signals(self, factor_info: Dict[str, Any], price_df: pd.DataFrame) -> Tuple[pd.DataFrame, pd.DataFrame]:
        """ğŸ”¥ ç”Ÿæˆå‘é‡åŒ–ä¿¡å· (pandasç‰ˆæœ¬)"""
        print(f"âš¡ ç”Ÿæˆå‘é‡åŒ–ä¿¡å·...")
        
        # åŠ¨æ€çª—å£å¤§å°
        time_len = len(price_df)
        window = min(288, time_len // 4) if time_len > 100 else time_len
        min_periods = min(20, window // 2)
        
        print(f"   ä¿¡å·çª—å£: {window}, æœ€å°å‘¨æœŸ: {min_periods}")
        
        # ä¸ºæ‰€æœ‰ asset-factor ç»„åˆç”Ÿæˆä¿¡å·
        all_entries = []
        all_exits = []
        multi_columns = []
        
        for asset in price_df.columns:
            asset_factors = factor_info['data'][asset]
            
            for factor_name in factor_info['factor_names']:
                factor_series = asset_factors[factor_name]
                
                # è®¡ç®—æ»šåŠ¨åˆ†ä½æ•°
                entry_threshold = factor_series.rolling(window=window, min_periods=min_periods).quantile(self.entry_percentile)
                exit_threshold = factor_series.rolling(window=window, min_periods=min_periods).quantile(self.exit_percentile)
                
                # ç”Ÿæˆä¿¡å·
                entries = (factor_series > entry_threshold).astype('int8')
                exits = (factor_series < exit_threshold).astype('int8')
                
                all_entries.append(entries)
                all_exits.append(exits)
                multi_columns.append((asset, factor_name))
        
        # æ„å»ºMultiIndex DataFrame
        entries_df = pd.concat(all_entries, axis=1)
        exits_df = pd.concat(all_exits, axis=1)
        
        entries_df.columns = pd.MultiIndex.from_tuples(multi_columns, names=['asset', 'factor'])
        exits_df.columns = pd.MultiIndex.from_tuples(multi_columns, names=['asset', 'factor'])
        
        print(f"âœ… ä¿¡å·ç”Ÿæˆå®Œæˆ: entries {entries_df.shape}, exits {exits_df.shape}")
        
        return entries_df, exits_df
    
    def batch_evaluate(self, symbols: List[str], factor_data: Dict[str, pd.DataFrame],
                      price_data: Dict[str, pd.DataFrame], factor_names: List[str],
                      timeframe: str = '5m') -> pd.DataFrame:
        """ğŸš€ Phase 2æ ¸å¿ƒ: VectorBTåŸç”Ÿæ‰¹é‡è¯„ä¼°"""
        
        print(f"ğŸš€ Phase 2 VectorBTåŸç”Ÿæ‰¹é‡å›æµ‹å¯åŠ¨...")
        total_start = time.time()
        
        # è®°å½•åˆå§‹å†…å­˜
        start_memory = self.log_memory("å¼€å§‹")
        
        try:
            # Step 1: é¢„åŠ è½½å‘é‡åŒ–æ•°æ®
            price_df, factor_info = self.preload_vectorized_data(symbols, timeframe=timeframe)
            
            # Step 2: ç”Ÿæˆå‘é‡åŒ–ä¿¡å·
            entries_df, exits_df = self.generate_vectorized_signals(factor_info, price_df)
            
            # Step 3: æ„å»ºä»·æ ¼çŸ©é˜µ (time Ã— [asset_factor])
            print(f"ğŸ”§ æ„å»ºä»·æ ¼çŸ©é˜µ...")
            
            # ä¸ºæ¯ä¸ªasset-factorç»„åˆå¤åˆ¶ä»·æ ¼æ•°æ®
            price_matrix = []
            for asset in price_df.columns:
                for factor_name in factor_info['factor_names']:
                    price_matrix.append(price_df[asset])
            
            price_matrix_df = pd.concat(price_matrix, axis=1)
            price_matrix_df.columns = entries_df.columns  # ä½¿ç”¨ç›¸åŒçš„MultiIndex
            
            print(f"âœ… ä»·æ ¼çŸ©é˜µå®Œæˆ: {price_matrix_df.shape} (time Ã— [asset_factor])")
            
            # Step 4: ğŸ”¥ å•æ¬¡VectorBTæ‰¹é‡å›æµ‹
            print(f"ğŸš€ æ‰§è¡Œå•æ¬¡VectorBTæ‰¹é‡å›æµ‹...")
            
            pf = vbt.Portfolio.from_signals(
                close=price_matrix_df,
                entries=entries_df,
                exits=exits_df,
                sl_stop=self.sl_stop if self.sl_stop > 0 else None,
                tp_stop=self.tp_stop if self.tp_stop > 0 else None,
                direction=self.direction,
                init_cash=100000,
                fees=self.fees,
                slippage=self.slippage,
                freq='5min'  # ä¿®å¤é¢‘ç‡è­¦å‘Š
                # æ³¨æ„ï¼šç§»é™¤broadcastå‚æ•°ï¼Œè®©VectorBTè‡ªåŠ¨å¤„ç†
            )
            
            print(f"âœ… VectorBTæ‰¹é‡å›æµ‹å®Œæˆ")
            
            # Step 5: æå–æ‰¹é‡ç»“æœ
            print(f"ğŸ“Š æå–æ‰¹é‡ç»“æœ...")
            
            # è·å–æ‰€æœ‰æŒ‡æ ‡
            total_returns = pf.total_return()
            sharpe_ratios = pf.sharpe_ratio()
            
            # å¹´åŒ–è°ƒæ•´
            annual_factor = self.get_annual_factor(timeframe)
            adjusted_sharpe = sharpe_ratios / annual_factor
            
            # å¤„ç†æ— æ•ˆå€¼
            adjusted_sharpe = adjusted_sharpe.replace([np.inf, -np.inf], np.nan).fillna(0)
            
            # æŒ‰å› å­èšåˆ
            results = []
            for factor in factor_info['factor_names']:
                # è·å–è¯¥å› å­åœ¨æ‰€æœ‰èµ„äº§ä¸Šçš„è¡¨ç°
                factor_mask = adjusted_sharpe.index.get_level_values('factor') == factor
                factor_sharpes = adjusted_sharpe[factor_mask]
                
                if len(factor_sharpes) > 0:
                    # è¿‡æ»¤æœ‰æ•ˆå€¼
                    valid_sharpes = factor_sharpes[~factor_sharpes.isna()]
                    
                    if len(valid_sharpes) > 0:
                        mean_sharpe = valid_sharpes.mean()
                        std_sharpe = valid_sharpes.std()
                        
                        # æ£€æŸ¥æ˜¯å¦ä¸ºæœ‰æ•ˆæ•°å€¼
                        if not (np.isnan(mean_sharpe) or np.isinf(mean_sharpe)):
                            results.append({
                                'factor': factor,
                                'sharpe': float(mean_sharpe),
                                'sharpe_std': float(std_sharpe) if not np.isnan(std_sharpe) else 0.0,
                                'asset_count': len(valid_sharpes),
                                'annual_factor': float(annual_factor)
                            })
            
            # è®°å½•ç»“æŸå†…å­˜
            end_memory = self.log_memory("ç»“æŸ")
            
            total_time = time.time() - total_start
            print(f"âœ… Phase 2æ‰¹é‡è¯„ä¼°å®Œæˆ")
            print(f"TotalTime {total_time:.1f} s  PeakRAM {max(start_memory, end_memory):.1f} MB")
            
            return pd.DataFrame(results)
            
        except Exception as e:
            print(f"âŒ Phase 2æ‰¹é‡å›æµ‹å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            return pd.DataFrame()


def main():
    """Phase 2éªŒè¯ä¸»å‡½æ•°"""
    import argparse
    
    parser = argparse.ArgumentParser(description='Phase 2 VectorBTåŸç”Ÿæ‰¹é‡å›æµ‹éªŒè¯')
    parser.add_argument('--mini', nargs=2, help='è¿·ä½ æµ‹è¯•æ¨¡å¼: stock_count factor_count')
    args = parser.parse_args()
    
    print("ğŸš€ Phase 2 - VectorBTåŸç”Ÿæ‰¹é‡å›æµ‹éªŒè¯")
    print("=" * 60)
    
    # åˆå§‹åŒ–è¯„ä¼°å™¨
    evaluator = CTAEvaluatorVectorized()
    
    if args.mini:
        stock_count, factor_count = map(int, args.mini)
        print(f"ğŸ§ª è¿·ä½ æµ‹è¯•æ¨¡å¼: {stock_count}åªè‚¡ç¥¨ Ã— {factor_count}ä¸ªå› å­")
        
        # æµ‹è¯•è‚¡ç¥¨åˆ—è¡¨
        all_symbols = ['0005.HK', '0020.HK', '0175.HK', '0291.HK', '0340.HK']
        test_symbols = all_symbols[:stock_count]
    else:
        # å®Œæ•´æµ‹è¯•
        test_symbols = ['0005.HK', '0020.HK', '0175.HK', '0291.HK', '0340.HK']
        factor_count = 10
    
    try:
        # é¢„åŠ è½½æ•°æ®
        price_df, factor_info = evaluator.preload_vectorized_data(test_symbols)
        
        # è·å–å› å­åç§°
        all_factors = factor_info['factor_names']
        factor_names = all_factors[:factor_count] if args.mini else all_factors[:10]
        
        print(f"ğŸ“Š æµ‹è¯•é…ç½®: {len(test_symbols)}åªè‚¡ç¥¨ Ã— {len(factor_names)}ä¸ªå› å­")
        
        # æ„å»ºæ¨¡æ‹Ÿè¾“å…¥ï¼ˆå…¼å®¹åŸæ¥å£ï¼‰
        price_data = {symbol: pd.DataFrame({'close': price_df[symbol]}) for symbol in test_symbols}
        factor_data = {}
        
        for symbol in test_symbols:
            symbol_factors = factor_info['data'][symbol]
            # ç¡®ä¿å› å­åç§°åœ¨æ•°æ®ä¸­å­˜åœ¨
            available_factors = [f for f in factor_names if f in symbol_factors.columns]
            factor_data[symbol] = symbol_factors[available_factors]
        
        # æ›´æ–°factor_namesä¸ºå®é™…å¯ç”¨çš„å› å­
        factor_names = available_factors
        
        # æ‰§è¡ŒPhase 2è¯„ä¼°
        results = evaluator.batch_evaluate(
            symbols=test_symbols,
            factor_data=factor_data,
            price_data=price_data,
            factor_names=factor_names,
            timeframe='5m'
        )
        
        # éªŒè¯ç»“æœ
        if not results.empty:
            print(f"âœ… ç”Ÿæˆ {len(results)} ä¸ªå› å­ç»“æœ")
            print(f"ğŸ“ˆ æœ€ä½³å¤æ™®ç‡: {results['sharpe'].max():.4f}")
            print(f"ğŸ“Š å¹³å‡å¤æ™®ç‡: {results['sharpe'].mean():.4f}")
            
            # å¯¹æ¯”Phase 1 (å¦‚æœéœ€è¦)
            if args.mini:
                print(f"\nğŸ” Phase 2 vs Phase 1 å¯¹æ¯”:")
                print(f"   å› å­æ•°é‡: {len(results)} vs é¢„æœŸ{factor_count}")
                print(f"   å¹³å‡å¤æ™®: {results['sharpe'].mean():.4f}")
        else:
            print("âŒ è¯„ä¼°ç»“æœä¸ºç©º")
            
    except Exception as e:
        print(f"âŒ æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    main()
