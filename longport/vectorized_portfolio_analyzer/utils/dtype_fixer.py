#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Categoricalæ•°æ®ç±»å‹ä¿®å¤å™¨ - ä¸“é—¨è§£å†³'Categorical' with dtype categoryé—®é¢˜
"""

import numpy as np
import pandas as pd
from typing import Dict, List, Optional, Tuple
import warnings
warnings.filterwarnings('ignore')

class CategoricalDtypeFixer:
    """ä¸“é—¨ä¿®å¤Categoricalæ•°æ®ç±»å‹é—®é¢˜"""
    
    def __init__(self):
        """åˆå§‹åŒ–ä¿®å¤å™¨"""
        self.logger = self._setup_logger()
        
    def _setup_logger(self):
        """è®¾ç½®æ—¥å¿—"""
        import logging
        logger = logging.getLogger(f"{__name__}.CategoricalFixer")
        logger.setLevel(logging.INFO)
        return logger
    
    def fix_categorical_dataframe(self, df: pd.DataFrame) -> pd.DataFrame:
        """
        ä¿®å¤DataFrameä¸­çš„æ‰€æœ‰Categoricalåˆ—
        
        Args:
            df: åŒ…å«å¯èƒ½Categoricalåˆ—çš„DataFrame
            
        Returns:
            ä¿®å¤åçš„DataFrame
        """
        print(f"ğŸ”§ å¼€å§‹ä¿®å¤Categoricalæ•°æ®ç±»å‹...")
        
        if df.empty:
            return df
            
        fixed_df = df.copy()
        categorical_columns = []
        conversion_errors = []
        
        for col in fixed_df.columns:
            try:
                col_data = fixed_df[col]
                
                # æ£€æŸ¥æ˜¯å¦ä¸ºCategoricalç±»å‹
                if hasattr(col_data, 'dtype') and col_data.dtype.name == 'category':
                    print(f"   å‘ç°Categoricalåˆ—: {col}")
                    categorical_columns.append(col)
                    
                    # å°è¯•è½¬æ¢ä¸ºæ•°å€¼
                    try:
                        # æ–¹æ³•1: ç›´æ¥è½¬æ¢category codesä¸ºæ•°å€¼
                        if hasattr(col_data, 'cat'):
                            # è·å–category codes
                            numeric_data = col_data.cat.codes.astype(float)
                            # å°†-1ï¼ˆNaNçš„codeï¼‰è½¬æ¢ä¸ºçœŸæ­£çš„NaN
                            numeric_data = numeric_data.replace(-1, np.nan)
                            fixed_df[col] = numeric_data
                            print(f"   âœ… {col}: æˆåŠŸè½¬æ¢ä¸ºæ•°å€¼ (ä½¿ç”¨category codes)")
                            
                        else:
                            # æ–¹æ³•2: å¼ºåˆ¶è½¬æ¢ä¸ºæ•°å€¼
                            fixed_df[col] = pd.to_numeric(col_data, errors='coerce')
                            print(f"   âœ… {col}: æˆåŠŸè½¬æ¢ä¸ºæ•°å€¼ (å¼ºåˆ¶è½¬æ¢)")
                            
                    except Exception as convert_error:
                        print(f"   âš ï¸ {col}: è½¬æ¢å¤±è´¥ï¼Œå°è¯•å¤‡ç”¨æ–¹æ³•")
                        
                        # æ–¹æ³•3: è½¬æ¢ä¸ºå­—ç¬¦ä¸²å†è½¬æ•°å€¼
                        try:
                            str_data = col_data.astype(str)
                            numeric_data = pd.to_numeric(str_data, errors='coerce')
                            fixed_df[col] = numeric_data
                            print(f"   âœ… {col}: å¤‡ç”¨æ–¹æ³•æˆåŠŸ")
                        except Exception as backup_error:
                            print(f"   âŒ {col}: æ‰€æœ‰è½¬æ¢æ–¹æ³•å‡å¤±è´¥ - {backup_error}")
                            conversion_errors.append(col)
                            # åˆ é™¤æ— æ³•è½¬æ¢çš„åˆ—
                            fixed_df = fixed_df.drop(columns=[col])
                
                # ç¡®ä¿æ‰€æœ‰åˆ—éƒ½æ˜¯æ•°å€¼ç±»å‹
                elif not pd.api.types.is_numeric_dtype(fixed_df[col]):
                    print(f"   å‘ç°éæ•°å€¼åˆ—: {col}, å°è¯•è½¬æ¢")
                    try:
                        fixed_df[col] = pd.to_numeric(fixed_df[col], errors='coerce')
                        print(f"   âœ… {col}: éæ•°å€¼åˆ—è½¬æ¢æˆåŠŸ")
                    except Exception as e:
                        print(f"   âŒ {col}: éæ•°å€¼åˆ—è½¬æ¢å¤±è´¥ - {e}")
                        conversion_errors.append(col)
                        fixed_df = fixed_df.drop(columns=[col])
                        
            except Exception as e:
                print(f"   âŒ å¤„ç†åˆ— {col} æ—¶å‡ºé”™: {e}")
                conversion_errors.append(col)
                continue
        
        print(f"   ä¿®å¤ç»“æœ:")
        print(f"   - å‘ç°Categoricalåˆ—: {len(categorical_columns)}ä¸ª")
        print(f"   - è½¬æ¢å¤±è´¥åˆ—: {len(conversion_errors)}ä¸ª")
        print(f"   - æœ€ç»ˆæœ‰æ•ˆåˆ—: {len(fixed_df.columns)}ä¸ª")
        
        if conversion_errors:
            print(f"   è½¬æ¢å¤±è´¥çš„åˆ—: {conversion_errors}")
            
        return fixed_df
    
    def validate_numeric_dataframe(self, df: pd.DataFrame) -> Tuple[pd.DataFrame, Dict]:
        """
        éªŒè¯DataFrameæ‰€æœ‰åˆ—éƒ½æ˜¯æ•°å€¼ç±»å‹ï¼Œå¹¶è¿›è¡ŒåŸºç¡€æ¸…æ´—
        
        Args:
            df: å¾…éªŒè¯çš„DataFrame
            
        Returns:
            (validated_df, validation_report)
        """
        print(f"ğŸ” å¼€å§‹æ•°å€¼ç±»å‹éªŒè¯...")
        
        if df.empty:
            return df, {'status': 'empty', 'issues': []}
        
        issues = []
        validated_df = df.copy()
        
        # åŸºç¡€åˆ—ï¼ˆä¿ç•™ï¼‰
        base_columns = ['open', 'high', 'low', 'close', 'volume', 'turnover']
        existing_base_columns = [col for col in base_columns if col in df.columns]
        factor_columns = [col for col in df.columns if col not in base_columns]
        
        valid_factors = []
        problematic_factors = []
        
        for col in factor_columns:
            try:
                col_data = validated_df[col]
                
                # æ£€æŸ¥æ•°æ®ç±»å‹
                if not pd.api.types.is_numeric_dtype(col_data):
                    issues.append(f"åˆ— {col} ä¸æ˜¯æ•°å€¼ç±»å‹: {col_data.dtype}")
                    problematic_factors.append(col)
                    continue
                
                # æ£€æŸ¥æ˜¯å¦å…¨ä¸ºNaN
                if col_data.dropna().empty:
                    issues.append(f"åˆ— {col} å…¨ä¸ºNaN")
                    problematic_factors.append(col)
                    continue
                
                # æ£€æŸ¥å¸¸é‡åˆ—
                unique_count = col_data.dropna().nunique()
                if unique_count <= 1:
                    issues.append(f"åˆ— {col} ä¸ºå¸¸é‡ (unique={unique_count})")
                    problematic_factors.append(col)
                    continue
                
                # æ£€æŸ¥å˜å¼‚æ€§
                try:
                    col_std = col_data.dropna().std()
                    if pd.isna(col_std) or col_std < 1e-8:
                        issues.append(f"åˆ— {col} å˜å¼‚æ€§è¿‡ä½ (std={col_std})")
                        problematic_factors.append(col)
                        continue
                except Exception as std_error:
                    issues.append(f"åˆ— {col} stdè®¡ç®—å¤±è´¥: {std_error}")
                    problematic_factors.append(col)
                    continue
                
                valid_factors.append(col)
                
            except Exception as e:
                issues.append(f"åˆ— {col} éªŒè¯å¤±è´¥: {e}")
                problematic_factors.append(col)
                continue
        
        # æ„å»ºæœ€ç»ˆçš„éªŒè¯DataFrame
        final_columns = existing_base_columns + valid_factors
        final_df = validated_df[final_columns].copy()
        
        validation_report = {
            'status': 'completed',
            'original_columns': len(df.columns),
            'final_columns': len(final_df.columns),
            'valid_factors': valid_factors,
            'problematic_factors': problematic_factors,
            'issues': issues,
            'success_rate': len(valid_factors) / len(factor_columns) if factor_columns else 1.0
        }
        
        print(f"   éªŒè¯ç»“æœ:")
        print(f"   - åŸå§‹åˆ—æ•°: {validation_report['original_columns']}")
        print(f"   - æœ‰æ•ˆåˆ—æ•°: {validation_report['final_columns']}")
        print(f"   - æˆåŠŸç‡: {validation_report['success_rate']:.1%}")
        
        if issues:
            print(f"   - å‘ç°é—®é¢˜: {len(issues)}ä¸ª")
            for issue in issues[:5]:  # åªæ˜¾ç¤ºå‰5ä¸ªé—®é¢˜
                print(f"     â€¢ {issue}")
            if len(issues) > 5:
                print(f"     â€¢ ... è¿˜æœ‰{len(issues)-5}ä¸ªé—®é¢˜")
        
        return final_df, validation_report
    
    def comprehensive_fix(self, df: pd.DataFrame) -> Tuple[pd.DataFrame, Dict]:
        """
        ç»¼åˆä¿®å¤ï¼šCategoricalç±»å‹ + æ•°æ®éªŒè¯
        
        Args:
            df: åŸå§‹DataFrame
            
        Returns:
            (fixed_df, fix_report)
        """
        print(f"ğŸ› ï¸ å¼€å§‹ç»¼åˆä¿®å¤...")
        
        if df.empty:
            return df, {'status': 'empty'}
        
        # é˜¶æ®µ1: ä¿®å¤Categoricalç±»å‹
        fixed_df = self.fix_categorical_dataframe(df)
        
        # é˜¶æ®µ2: æ•°å€¼éªŒè¯å’Œæ¸…æ´—
        validated_df, validation_report = self.validate_numeric_dataframe(fixed_df)
        
        # ç”Ÿæˆç»¼åˆæŠ¥å‘Š
        comprehensive_report = {
            'status': 'completed',
            'original_shape': df.shape,
            'final_shape': validated_df.shape,
            'categorical_fix': {
                'found_categorical': len([col for col in df.columns 
                                        if hasattr(df[col], 'dtype') and df[col].dtype.name == 'category']),
                'conversion_attempted': True
            },
            'validation': validation_report,
            'data_quality': {
                'columns_retained': len(validated_df.columns),
                'columns_removed': len(df.columns) - len(validated_df.columns),
                'removal_rate': (len(df.columns) - len(validated_df.columns)) / len(df.columns),
                'final_usable': not validated_df.empty and len(validated_df.columns) > 5
            }
        }
        
        print(f"ğŸ¯ ç»¼åˆä¿®å¤å®Œæˆ:")
        print(f"   åŸå§‹: {comprehensive_report['original_shape']}")
        print(f"   æœ€ç»ˆ: {comprehensive_report['final_shape']}")
        print(f"   ç§»é™¤ç‡: {comprehensive_report['data_quality']['removal_rate']:.1%}")
        print(f"   å¯ç”¨æ€§: {'âœ…' if comprehensive_report['data_quality']['final_usable'] else 'âŒ'}")
        
        return validated_df, comprehensive_report


def test_categorical_fixer():
    """æµ‹è¯•Categoricalä¿®å¤å™¨"""
    print("ğŸ§ª æµ‹è¯•Categoricalä¿®å¤å™¨...")
    
    # åˆ›å»ºæµ‹è¯•æ•°æ®
    test_data = pd.DataFrame({
        'close': [100, 101, 102, 103, 104],
        'volume': [1000, 1100, 1200, 1300, 1400],
        'categorical_factor': pd.Categorical(['A', 'B', 'A', 'C', 'B']),
        'numeric_factor': [1.1, 2.2, 3.3, 4.4, 5.5],
        'constant_factor': [1, 1, 1, 1, 1],
        'nan_factor': [np.nan, np.nan, np.nan, np.nan, np.nan]
    })
    
    print(f"æµ‹è¯•æ•°æ®ç±»å‹:")
    print(test_data.dtypes)
    
    fixer = CategoricalDtypeFixer()
    fixed_data, report = fixer.comprehensive_fix(test_data)
    
    print(f"\nä¿®å¤åæ•°æ®ç±»å‹:")
    print(fixed_data.dtypes)
    
    print(f"\nä¿®å¤æŠ¥å‘Š:")
    for key, value in report.items():
        print(f"  {key}: {value}")
    
    return fixed_data, report


if __name__ == "__main__":
    test_categorical_fixer()
