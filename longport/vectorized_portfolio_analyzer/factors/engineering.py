#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å› å­å·¥ç¨‹æ¨¡å— - æŠŠä¿¡å·åšåšã€æŠŠå™ªéŸ³åšè–„
å®ç°5ä¸ªæ ¸å¿ƒæ–¹å‘çš„å› å­åŠ å·¥ï¼Œæå‡ICè´¨é‡å’Œç¨³å®šæ€§
"""

import numpy as np
import pandas as pd
from typing import Dict, List, Optional, Tuple
from scipy import stats
import warnings
warnings.filterwarnings('ignore')

class FactorEngineer:
    """å› å­å·¥ç¨‹å¸ˆ - ä¸“ä¸šåŒ–å› å­åŠ å·¥"""
    
    def __init__(self):
        """åˆå§‹åŒ–å› å­å·¥ç¨‹å¸ˆ"""
        self.engineering_methods = {
            'time_scale': self._time_scale_fusion,
            'cross_sectional': self._cross_sectional_normalize,
            'nonlinear': self._nonlinear_transform,
            'regime_based': self._regime_based_signal,
            'interaction': self._interaction_terms
        }
        
    def process_factors(self, 
                       factor_data: pd.DataFrame, 
                       methods: List[str] = None,
                       config: Dict = None) -> pd.DataFrame:
        """
        å› å­å·¥ç¨‹ä¸»å‡½æ•°
        
        Args:
            factor_data: åŒ…å«åŸå§‹å› å­çš„DataFrame (MultiIndex: symbol, timestamp)
            methods: è¦åº”ç”¨çš„å·¥ç¨‹æ–¹æ³•åˆ—è¡¨
            config: é…ç½®å‚æ•°
            
        Returns:
            å·¥ç¨‹åŒ–åçš„å› å­DataFrame
        """
        if methods is None:
            methods = ['cross_sectional', 'nonlinear', 'regime_based']
            
        if config is None:
            config = self._get_default_config()
            
        print(f"ğŸ”§ å¼€å§‹å› å­å·¥ç¨‹ï¼Œåº”ç”¨æ–¹æ³•: {methods}")
        
        result_df = factor_data.copy()
        
        for method in methods:
            if method in self.engineering_methods:
                print(f"   å¤„ç†: {method}")
                try:
                    result_df = self.engineering_methods[method](result_df, config)
                except Exception as e:
                    print(f"   âš ï¸ {method} å¤„ç†å¤±è´¥: {e}")
                    
        # ç»Ÿè®¡æ–°å¢å› å­
        original_factors = set(factor_data.columns)
        new_factors = [col for col in result_df.columns if col not in original_factors]
        
        print(f"âœ… å› å­å·¥ç¨‹å®Œæˆï¼Œæ–°å¢ {len(new_factors)} ä¸ªå·¥ç¨‹åŒ–å› å­")
        
        return result_df
    
    def _get_default_config(self) -> Dict:
        """è·å–é»˜è®¤é…ç½®"""
        return {
            'rolling_window': 252,  # æ¨ªæˆªé¢æ ‡å‡†åŒ–çª—å£
            'rank_transform': True,  # æ˜¯å¦è¿›è¡Œæ’åºå˜æ¢
            'winsorize_pct': 0.05,  # æå€¼å¤„ç†ç™¾åˆ†æ¯”
            'regime_thresholds': {'low': 0.3, 'high': 0.7},  # çŠ¶æ€åˆ†å±‚é˜ˆå€¼
            'interaction_top_factors': 5  # äº¤äº’é¡¹ä½¿ç”¨çš„é¡¶çº§å› å­æ•°
        }
    
    def _time_scale_fusion(self, df: pd.DataFrame, config: Dict) -> pd.DataFrame:
        """æ—¶é—´å°ºåº¦æ‹¼æ¥ - å¤šå‘¨æœŸä¿¡å·èåˆ"""
        try:
            # è¿™é‡Œéœ€è¦å¤šæ—¶é—´æ¡†æ¶æ•°æ®ï¼Œæš‚æ—¶å®ç°å•æ—¶é—´æ¡†æ¶å†…çš„æ—¶é—´èåˆ
            for col in df.select_dtypes(include=[np.number]).columns:
                if 'rsi' in col.lower():
                    # RSIçŸ­æœŸ/é•¿æœŸæ¯”å€¼
                    rsi_short = df[col].rolling(5).mean()
                    rsi_long = df[col].rolling(20).mean()
                    df[f'{col}_ratio_short_long'] = rsi_short / (rsi_long + 1e-8)
                    
                elif 'macd' in col.lower():
                    # MACDåŠ¨é‡å¼ºåº¦
                    macd_momentum = df[col].rolling(10).std()
                    df[f'{col}_momentum_strength'] = macd_momentum
                    
                elif 'atr' in col.lower():
                    # ATRæ³¢åŠ¨ç‡çŠ¶æ€
                    atr_ma = df[col].rolling(20).mean()
                    df[f'{col}_relative_to_ma'] = df[col] / (atr_ma + 1e-8)
                    
        except Exception as e:
            print(f"æ—¶é—´å°ºåº¦èåˆå¤±è´¥: {e}")
            
        return df
    
    def _cross_sectional_normalize(self, df: pd.DataFrame, config: Dict) -> pd.DataFrame:
        """æ¨ªæˆªé¢æ ‡å‡†åŒ– - æ¯æœŸåªé€‰ç›¸å¯¹æœ€å¼º"""
        try:
            # ç¡®ä¿æ˜¯MultiIndex (symbol, timestamp)
            if not isinstance(df.index, pd.MultiIndex):
                return df
                
            # è·å–æ•°å€¼å‹åˆ—
            numeric_cols = df.select_dtypes(include=[np.number]).columns
            
            for col in numeric_cols:
                # æŒ‰æ—¶é—´æˆªé¢æ ‡å‡†åŒ–
                def cross_sectional_zscore(group):
                    return (group - group.mean()) / (group.std() + 1e-8)
                
                # æŒ‰timestampåˆ†ç»„ï¼Œå¯¹æ¯ä¸ªæˆªé¢è¿›è¡Œæ ‡å‡†åŒ–
                df[f'{col}_cs_zscore'] = df.groupby(level='timestamp')[col].transform(cross_sectional_zscore)
                
                # æˆªé¢æ’åº
                df[f'{col}_cs_rank'] = df.groupby(level='timestamp')[col].rank(pct=True)
                
        except Exception as e:
            print(f"æ¨ªæˆªé¢æ ‡å‡†åŒ–å¤±è´¥: {e}")
            
        return df
    
    def _nonlinear_transform(self, df: pd.DataFrame, config: Dict) -> pd.DataFrame:
        """éçº¿æ€§å˜æ¢ - å‹ç¼©æç«¯å€¼ï¼Œé™ä½å™ªéŸ³"""
        try:
            numeric_cols = df.select_dtypes(include=[np.number]).columns
            
            for col in numeric_cols:
                # è·³è¿‡å·²ç»å¤„ç†è¿‡çš„åˆ—
                if any(suffix in col for suffix in ['_rank', '_zscore', '_tanh', '_squared']):
                    continue
                    
                values = df[col].dropna()
                if len(values) == 0:
                    continue
                    
                # 1. Rankå˜æ¢ + å¹³æ–¹
                rank_values = values.rank(pct=True)
                df[f'{col}_rank_squared'] = rank_values ** 2
                
                # 2. tanhå˜æ¢ï¼ˆå‹ç¼©æç«¯å€¼ï¼‰
                normalized_values = (values - values.mean()) / (values.std() + 1e-8)
                df[f'{col}_tanh'] = np.tanh(normalized_values)
                
                # 3. åˆ†ä½æ•°æ˜ å°„
                df[f'{col}_quantile'] = pd.qcut(values, q=10, labels=False, duplicates='drop')
                
                # 4. Winsorizeå¤„ç†
                winsorize_pct = config.get('winsorize_pct', 0.05)
                lower_bound = values.quantile(winsorize_pct)
                upper_bound = values.quantile(1 - winsorize_pct)
                df[f'{col}_winsorized'] = values.clip(lower_bound, upper_bound)
                
        except Exception as e:
            print(f"éçº¿æ€§å˜æ¢å¤±è´¥: {e}")
            
        return df
    
    def _regime_based_signal(self, df: pd.DataFrame, config: Dict) -> pd.DataFrame:
        """çŠ¶æ€åˆ†å±‚ä¿¡å· - é™ä½æ¢æ‰‹ç‡"""
        try:
            thresholds = config.get('regime_thresholds', {'low': 0.3, 'high': 0.7})
            numeric_cols = df.select_dtypes(include=[np.number]).columns
            
            for col in numeric_cols:
                # è·³è¿‡å·²ç»å¤„ç†è¿‡çš„åˆ—
                if any(suffix in col for suffix in ['_regime', '_signal', '_threshold']):
                    continue
                    
                values = df[col].dropna()
                if len(values) == 0:
                    continue
                    
                # è®¡ç®—åˆ†ä½æ•°é˜ˆå€¼
                low_threshold = values.quantile(thresholds['low'])
                high_threshold = values.quantile(thresholds['high'])
                
                # ä¸‰å€¼ä¿¡å·ï¼š-1, 0, 1
                def regime_signal(x):
                    if pd.isna(x):
                        return 0
                    elif x >= high_threshold:
                        return 1
                    elif x <= low_threshold:
                        return -1
                    else:
                        return 0
                
                df[f'{col}_regime_signal'] = df[col].apply(regime_signal)
                
                # çŠ¶æ€æŒç»­æ€§ï¼ˆå‡å°‘é¢‘ç¹åˆ‡æ¢ï¼‰
                regime_signal_col = f'{col}_regime_signal'
                if regime_signal_col in df.columns:
                    # æ·»åŠ æ»åæ€§ï¼Œé¿å…é¢‘ç¹åˆ‡æ¢
                    df[f'{col}_regime_smooth'] = df[regime_signal_col].rolling(3, center=True).mean()
                
        except Exception as e:
            print(f"çŠ¶æ€åˆ†å±‚ä¿¡å·å¤±è´¥: {e}")
            
        return df
    
    def _interaction_terms(self, df: pd.DataFrame, config: Dict) -> pd.DataFrame:
        """äº¤äº’é¡¹ - å¤šå› å­ç»„åˆä¿¡å·"""
        try:
            # è·å–ä¸»è¦å› å­
            main_factors = []
            for col in df.columns:
                if any(factor in col.lower() for factor in ['rsi', 'macd', 'atr', 'vwap']):
                    if not any(suffix in col for suffix in ['_cs_', '_rank', '_regime', '_tanh']):
                        main_factors.append(col)
            
            # é™åˆ¶äº¤äº’é¡¹æ•°é‡
            top_n = config.get('interaction_top_factors', 5)
            main_factors = main_factors[:top_n]
            
            # åˆ›å»ºäº¤äº’é¡¹
            for i, factor1 in enumerate(main_factors):
                for factor2 in main_factors[i+1:]:
                    try:
                        # ä¹˜ç§¯äº¤äº’
                        df[f'{factor1}_x_{factor2}'] = df[factor1] * df[factor2]
                        
                        # æ¯”å€¼äº¤äº’
                        df[f'{factor1}_div_{factor2}'] = df[factor1] / (df[factor2] + 1e-8)
                        
                        # æ¡ä»¶äº¤äº’ï¼ˆfactor1>0æ—¶çš„factor2ï¼‰
                        condition = df[factor1] > df[factor1].median()
                        df[f'{factor2}_when_{factor1}_high'] = df[factor2] * condition.astype(int)
                        
                    except Exception as e:
                        print(f"äº¤äº’é¡¹ {factor1} x {factor2} åˆ›å»ºå¤±è´¥: {e}")
            
        except Exception as e:
            print(f"äº¤äº’é¡¹è®¡ç®—å¤±è´¥: {e}")
            
        return df
    
    def calculate_factor_quality_score(self, 
                                     factor_data: pd.DataFrame,
                                     returns: pd.Series,
                                     factor_name: str) -> Dict:
        """è®¡ç®—å› å­è´¨é‡å¾—åˆ†"""
        try:
            factor_values = factor_data[factor_name].dropna()
            aligned_returns = returns.reindex(factor_values.index).dropna()
            
            # å¯¹é½æ•°æ®
            common_idx = factor_values.index.intersection(aligned_returns.index)
            if len(common_idx) < 30:
                return {'quality_score': 0, 'reason': 'insufficient_data'}
                
            factor_aligned = factor_values.loc[common_idx]
            returns_aligned = aligned_returns.loc[common_idx]
            
            # è®¡ç®—å„ç§è´¨é‡æŒ‡æ ‡
            ic = factor_aligned.corr(returns_aligned)
            ic_std = pd.Series([factor_aligned.corr(returns_aligned)]).rolling(20).std().iloc[-1]
            ir = ic / (ic_std + 1e-8)
            
            # å•è°ƒæ€§æ£€éªŒ
            factor_quantiles = pd.qcut(factor_aligned, q=5, labels=False, duplicates='drop')
            quantile_returns = returns_aligned.groupby(factor_quantiles).mean()
            monotonicity = stats.kendalltau(range(len(quantile_returns)), quantile_returns)[0]
            
            # ç¨³å®šæ€§æ£€éªŒï¼ˆæ»šåŠ¨ICæ ‡å‡†å·®ï¼‰
            rolling_ic = pd.Series(index=common_idx, dtype=float)
            for i in range(60, len(common_idx)):
                window_factor = factor_aligned.iloc[i-60:i]
                window_returns = returns_aligned.iloc[i-60:i]
                rolling_ic.iloc[i] = window_factor.corr(window_returns)
            
            stability = 1 - (rolling_ic.std() / (np.abs(rolling_ic.mean()) + 1e-8))
            
            # ç»¼åˆè´¨é‡å¾—åˆ†
            quality_score = (
                np.abs(ic) * 0.4 +  # ICé‡è¦æ€§
                np.abs(monotonicity) * 0.3 +  # å•è°ƒæ€§
                stability * 0.3  # ç¨³å®šæ€§
            )
            
            return {
                'quality_score': quality_score,
                'ic': ic,
                'ir': ir,
                'monotonicity': monotonicity,
                'stability': stability,
                'sample_size': len(common_idx)
            }
            
        except Exception as e:
            return {'quality_score': 0, 'reason': str(e)}


def test_factor_engineering():
    """æµ‹è¯•å› å­å·¥ç¨‹"""
    print("ğŸ§ª æµ‹è¯•å› å­å·¥ç¨‹...")
    
    # åˆ›å»ºæ¨¡æ‹Ÿæ•°æ®
    np.random.seed(42)
    symbols = ['A', 'B', 'C']
    dates = pd.date_range('2024-01-01', '2024-06-30', freq='D')
    
    # åˆ›å»ºMultiIndex DataFrame
    index = pd.MultiIndex.from_product([symbols, dates], names=['symbol', 'timestamp'])
    
    data = pd.DataFrame({
        'rsi_14': np.random.normal(50, 15, len(index)),
        'macd_enhanced': np.random.normal(0, 1, len(index)),
        'atrp': np.abs(np.random.normal(0.02, 0.01, len(index))),
        'vwap_deviation': np.random.normal(0, 0.005, len(index))
    }, index=index)
    
    # æ·»åŠ ä¸€äº›çœŸå®çš„æ¨¡å¼
    data['rsi_14'] = np.clip(data['rsi_14'], 0, 100)
    
    # åº”ç”¨å› å­å·¥ç¨‹
    engineer = FactorEngineer()
    result = engineer.process_factors(data)
    
    print(f"âœ… æµ‹è¯•å®Œæˆ:")
    print(f"   è¾“å…¥å› å­: {len(data.columns)}ä¸ª")
    print(f"   è¾“å‡ºå› å­: {len(result.columns)}ä¸ª")
    print(f"   æ–°å¢å› å­: {len(result.columns) - len(data.columns)}ä¸ª")
    
    return result


if __name__ == "__main__":
    test_factor_engineering()
