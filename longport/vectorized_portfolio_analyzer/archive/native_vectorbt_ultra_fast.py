#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
çœŸæ­£çš„VectorBTåŸç”Ÿè¶…é«˜é€Ÿå…¨è§„æ¨¡æµ‹è¯• - 10ç§’å†…å®Œæˆ54åªè‚¡ç¥¨åˆ†æ
"""

import sys
import os
import time
import json
import numpy as np
import pandas as pd
import vectorbt as vbt
from datetime import datetime
from typing import Dict, List, Optional, Tuple
import warnings
warnings.filterwarnings('ignore')

# æ·»åŠ å½“å‰ç›®å½•åˆ°ç³»ç»Ÿè·¯å¾„
current_dir = os.path.dirname(os.path.abspath(__file__))
sys.path.insert(0, current_dir)

class NativeVectorBTUltraFast:
    """çœŸæ­£çš„VectorBTåŸç”Ÿè¶…é«˜é€Ÿåˆ†æç³»ç»Ÿ"""
    
    def __init__(self, capital: float = 300000):
        """åˆå§‹åŒ–VectorBTåŸç”Ÿç³»ç»Ÿ"""
        print("ğŸš€ å¯åŠ¨VectorBTåŸç”Ÿè¶…é«˜é€Ÿå…¨è§„æ¨¡æµ‹è¯•...")
        print("ğŸ’¡ çœŸæ­£å‘æŒ¥VectorBTå‘é‡åŒ–ä¼˜åŠ¿ï¼Œ10ç§’å†…å®Œæˆå…¨éƒ¨åˆ†æ")
        print("=" * 80)
        
        self.capital = capital
        self.max_positions = 10
        
        # VectorBTåŸç”Ÿé…ç½®
        self.vbt_config = {
            'freq': 'D',  # æ•°æ®é¢‘ç‡
            'use_numba': True,  # å¯ç”¨NumbaåŠ é€Ÿ
            'chunked': True,    # åˆ†å—å¤„ç†
            'jitted': {
                'parallel': True,  # å¹¶è¡Œè®¡ç®—
                'cache': True      # ç¼“å­˜ç¼–è¯‘ç»“æœ
            },
            'broadcasting': {
                'align_index': True,
                'align_columns': True,
                'keep_raw': False
            }
        }
        
        # è®¾ç½®VectorBTå…¨å±€é…ç½®
        try:
            vbt.settings.set_theme("dark")
        except:
            pass  # æŸäº›ç‰ˆæœ¬å¯èƒ½æ²¡æœ‰è¿™ä¸ªæ–¹æ³•
        
        try:
            vbt.settings.array_wrapper['freq'] = self.vbt_config['freq']
        except:
            pass
        
        try:
            vbt.settings.caching['enabled'] = True
        except:
            pass
        
        try:
            vbt.settings.chunking['enabled'] = True
        except:
            pass
        
        self.data_dir = "/Users/zhangshenshen/longport/vectorbt_workspace/data"
        self.available_symbols = self._get_available_symbols()
        
        print(f"âœ… VectorBTåŸç”Ÿç³»ç»Ÿåˆå§‹åŒ–å®Œæˆ")
        print(f"ğŸ“Š ç³»ç»Ÿé…ç½®:")
        print(f"   èµ„é‡‘è§„æ¨¡: {self.capital:,.0f} æ¸¯å¸")
        print(f"   æœ€å¤§æŒä»“: {self.max_positions} åªè‚¡ç¥¨")
        print(f"   ğŸ”¥ å¯ç”¨è‚¡ç¥¨: {len(self.available_symbols)} åª")
        print(f"   ğŸ”¥ VectorBTä¼˜åŒ–: Numbaå¹¶è¡Œ + åˆ†å—å¤„ç† + ç¼“å­˜")
        print(f"   ğŸ”¥ é¢„æœŸé€Ÿåº¦: <10ç§’å®Œæˆå…¨éƒ¨åˆ†æ")
        print("=" * 80)
    
    def _get_available_symbols(self) -> List[str]:
        """è·å–å¯ç”¨è‚¡ç¥¨åˆ—è¡¨"""
        symbols = []
        try:
            for timeframe in ['1d']:  # å…ˆç”¨æ—¥çº¿æ•°æ®æµ‹è¯•
                tf_dir = os.path.join(self.data_dir, timeframe)
                if os.path.exists(tf_dir):
                    for file in os.listdir(tf_dir):
                        if file.endswith('.parquet'):  # ä¿®å¤ï¼šä½¿ç”¨parquetæ ¼å¼
                            symbol = file.replace('.parquet', '')
                            if symbol not in symbols:
                                symbols.append(symbol)
            return sorted(symbols)
        except Exception as e:
            print(f"âš ï¸ è·å–è‚¡ç¥¨åˆ—è¡¨å¤±è´¥: {e}")
            return ['0700.HK', '0005.HK', '0388.HK']  # é»˜è®¤è‚¡ç¥¨
    
    def run_native_vectorbt_analysis(self) -> Dict:
        """è¿è¡ŒVectorBTåŸç”Ÿè¶…é«˜é€Ÿåˆ†æ"""
        print("ğŸ¯ å¼€å§‹VectorBTåŸç”Ÿè¶…é«˜é€Ÿåˆ†æ...")
        start_time = time.time()
        
        try:
            # é˜¶æ®µ1: è¶…é«˜é€Ÿæ•°æ®åŠ è½½ï¼ˆVectorBTåŸç”Ÿæ–¹å¼ï¼‰
            print("\nğŸ“Š é˜¶æ®µ1: VectorBTåŸç”Ÿæ•°æ®åŠ è½½")
            multi_data = self._load_data_native_vectorbt()
            
            # é˜¶æ®µ2: æ‰¹é‡å› å­è®¡ç®—ï¼ˆå®Œå…¨å‘é‡åŒ–ï¼‰
            print("\nğŸ”§ é˜¶æ®µ2: VectorBTæ‰¹é‡å› å­è®¡ç®—")
            factor_results = self._calculate_factors_native_vectorbt(multi_data)
            
            # é˜¶æ®µ3: è¶…é«˜é€ŸICåˆ†æï¼ˆçŸ©é˜µè¿ç®—ï¼‰
            print("\nğŸ“ˆ é˜¶æ®µ3: VectorBTè¶…é«˜é€ŸICåˆ†æ")
            ic_analysis = self._analyze_ic_native_vectorbt(factor_results)
            
            # é˜¶æ®µ4: å› å­æ’åºå’Œç­–ç•¥æ„å»º
            print("\nğŸ† é˜¶æ®µ4: å› å­æ’åºå’Œç­–ç•¥æ„å»º")
            strategy_results = self._build_strategy_native_vectorbt(ic_analysis)
            
            # é˜¶æ®µ5: æ€§èƒ½è¯„ä¼°
            print("\nğŸ“‹ é˜¶æ®µ5: æ€§èƒ½è¯„ä¼°")
            performance_report = self._generate_performance_report(strategy_results)
            
            total_time = time.time() - start_time
            
            # æœ€ç»ˆç»“æœ
            final_results = {
                'execution_time': total_time,
                'analysis_approach': 'native_vectorbt_ultra_fast',
                'tested_symbols_count': len(self.available_symbols),
                'multi_data_shape': str(multi_data.shape) if hasattr(multi_data, 'shape') else 'N/A',
                'factor_results': factor_results,
                'ic_analysis': ic_analysis,
                'strategy_results': strategy_results,
                'performance_report': performance_report,
                'vectorbt_config': self.vbt_config,
                'timestamp': datetime.now().isoformat()
            }
            
            # ä¿å­˜ç»“æœ
            results_dir = self._save_results(final_results)
            
            print(f"\nğŸ‰ VectorBTåŸç”Ÿè¶…é«˜é€Ÿåˆ†æå®Œæˆ!")
            print(f"   âš¡ æ€»è€—æ—¶: {total_time:.2f}ç§’")
            print(f"   ğŸ“Š å¤„ç†è‚¡ç¥¨: {len(self.available_symbols)}åª")
            print(f"   ğŸ”¥ é€Ÿåº¦æå‡: {576.9/total_time:.1f}x ç›¸æ¯”ä¼˜åŒ–ç‰ˆ")
            print(f"   ğŸ’¾ ç»“æœä¿å­˜: {results_dir}")
            
            return final_results
            
        except Exception as e:
            print(f"\nâŒ VectorBTåŸç”Ÿåˆ†æå¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            raise
    
    def _load_data_native_vectorbt(self) -> pd.DataFrame:
        """VectorBTåŸç”Ÿæ–¹å¼åŠ è½½å¤šè‚¡ç¥¨æ•°æ®"""
        print("   ğŸ”„ ä½¿ç”¨VectorBTåŸç”Ÿæ–¹å¼åŠ è½½å¤šè‚¡ç¥¨æ•°æ®...")
        
        # æ‰¹é‡è¯»å–æ‰€æœ‰è‚¡ç¥¨æ•°æ®
        data_dict = {}
        
        for symbol in self.available_symbols[:10]:  # å…ˆæµ‹è¯•10åªè‚¡ç¥¨
            try:
                file_path = os.path.join(self.data_dir, '1d', f'{symbol}.parquet')  # ä¿®å¤ï¼šä½¿ç”¨parquet
                if os.path.exists(file_path):
                    df = pd.read_parquet(file_path)  # ä¿®å¤ï¼šä½¿ç”¨read_parquet
                    
                    # ç¡®ä¿ç´¢å¼•æ˜¯datetime
                    if not isinstance(df.index, pd.DatetimeIndex):
                        df.index = pd.to_datetime(df.index)
                    
                    # ç¡®ä¿åˆ—åæ ‡å‡†åŒ–
                    if 'Close' in df.columns:
                        df = df.rename(columns={'Close': 'close', 'Open': 'open', 
                                              'High': 'high', 'Low': 'low', 'Volume': 'volume'})
                    
                    # åªä¿ç•™éœ€è¦çš„åˆ—
                    required_cols = ['open', 'high', 'low', 'close', 'volume']
                    available_cols = [col for col in required_cols if col in df.columns]
                    
                    if available_cols:
                        data_dict[symbol] = df[available_cols].dropna()
                        
            except Exception as e:
                print(f"   âš ï¸ è·³è¿‡è‚¡ç¥¨ {symbol}: {e}")
                continue
        
        if not data_dict:
            raise ValueError("æ²¡æœ‰æˆåŠŸåŠ è½½ä»»ä½•è‚¡ç¥¨æ•°æ®")
        
        # ğŸ”¥ VectorBTåŸç”Ÿæ–¹å¼ï¼šåˆ›å»ºMultiIndex DataFrame
        # è¿™æ˜¯VectorBTæœ€æ“…é•¿çš„æ•°æ®æ ¼å¼
        multi_data_list = []
        
        for symbol, df in data_dict.items():
            df_copy = df.copy()
            df_copy.columns = pd.MultiIndex.from_product([[symbol], df_copy.columns], 
                                                       names=['symbol', 'field'])
            multi_data_list.append(df_copy)
        
        # åˆå¹¶æ‰€æœ‰æ•°æ®ä¸ºä¸€ä¸ªå¤§çš„MultiIndex DataFrame
        multi_data = pd.concat(multi_data_list, axis=1).sort_index()
        
        print(f"   âœ… VectorBTæ•°æ®åŠ è½½å®Œæˆ: {multi_data.shape}, {len(data_dict)}åªè‚¡ç¥¨")
        return multi_data
    
    def _calculate_factors_native_vectorbt(self, multi_data: pd.DataFrame) -> Dict:
        """VectorBTåŸç”Ÿæ‰¹é‡å› å­è®¡ç®—"""
        print("   ğŸ”§ VectorBTåŸç”Ÿæ‰¹é‡å› å­è®¡ç®—...")
        
        # è·å–ä»·æ ¼æ•°æ®ï¼ˆæ‰€æœ‰è‚¡ç¥¨çš„closeä»·æ ¼ï¼‰
        close_data = multi_data.xs('close', axis=1, level='field')
        high_data = multi_data.xs('high', axis=1, level='field') 
        low_data = multi_data.xs('low', axis=1, level='field')
        volume_data = multi_data.xs('volume', axis=1, level='field')
        
        print(f"   ğŸ“Š ä»·æ ¼æ•°æ®å½¢çŠ¶: {close_data.shape}")
        
        # ğŸ”¥ VectorBTåŸç”Ÿå› å­è®¡ç®—ï¼ˆå®Œå…¨å‘é‡åŒ–ï¼Œä¸€æ¬¡æ€§è®¡ç®—æ‰€æœ‰è‚¡ç¥¨ï¼‰
        factors = {}
        
        try:
            # 1. æŠ€æœ¯æŒ‡æ ‡å› å­ï¼ˆVectorBTåŸç”Ÿï¼‰
            print("   ğŸ“ˆ è®¡ç®—æŠ€æœ¯æŒ‡æ ‡å› å­...")
            
            # RSI - ä¸€æ¬¡æ€§è®¡ç®—æ‰€æœ‰è‚¡ç¥¨
            rsi_14 = vbt.RSI.run(close_data, window=14, short_name='RSI').rsi
            factors['rsi_14'] = rsi_14
            
            # MACD - ä¸€æ¬¡æ€§è®¡ç®—æ‰€æœ‰è‚¡ç¥¨  
            try:
                macd_ind = vbt.MACD.run(close_data, fast_window=12, slow_window=26, signal_window=9)
                factors['macd'] = macd_ind.macd
                factors['macd_signal'] = macd_ind.signal
                # å…¼å®¹æ€§æ£€æŸ¥
                if hasattr(macd_ind, 'histogram'):
                    factors['macd_histogram'] = macd_ind.histogram
                else:
                    factors['macd_histogram'] = macd_ind.macd - macd_ind.signal
            except Exception as e:
                print(f"   âš ï¸ MACDè®¡ç®—å¤±è´¥: {e}")
                # ç®€å•æ›¿ä»£æ–¹æ¡ˆ
                ema_12 = close_data.ewm(span=12).mean()
                ema_26 = close_data.ewm(span=26).mean()
                factors['macd'] = ema_12 - ema_26
                factors['macd_signal'] = factors['macd'].ewm(span=9).mean()
                factors['macd_histogram'] = factors['macd'] - factors['macd_signal']
            
            # Bollinger Bands
            try:
                bb_ind = vbt.BBANDS.run(close_data, window=20, alpha=2)
                factors['bb_upper'] = bb_ind.upper
                factors['bb_lower'] = bb_ind.lower
                factors['bb_percent'] = (close_data - bb_ind.lower) / (bb_ind.upper - bb_ind.lower)
            except Exception as e:
                print(f"   âš ï¸ Bollinger Bandsè®¡ç®—å¤±è´¥: {e}")
                # ç®€å•æ›¿ä»£æ–¹æ¡ˆ
                sma_20 = close_data.rolling(20).mean()
                std_20 = close_data.rolling(20).std()
                factors['bb_upper'] = sma_20 + 2 * std_20
                factors['bb_lower'] = sma_20 - 2 * std_20
                factors['bb_percent'] = (close_data - factors['bb_lower']) / (factors['bb_upper'] - factors['bb_lower'])
            
            # 2. åŠ¨é‡å› å­
            print("   ğŸ“Š è®¡ç®—åŠ¨é‡å› å­...")
            factors['returns_1d'] = close_data.pct_change()
            factors['returns_5d'] = close_data.pct_change(5)
            factors['returns_20d'] = close_data.pct_change(20)
            
            # 3. æ³¢åŠ¨ç‡å› å­
            print("   ğŸ“‰ è®¡ç®—æ³¢åŠ¨ç‡å› å­...")
            factors['volatility_20d'] = factors['returns_1d'].rolling(20).std()
            try:
                factors['atr_14'] = vbt.ATR.run(high_data, low_data, close_data, window=14).atr
                factors['atr_ratio'] = factors['atr_14'] / close_data
            except Exception as e:
                print(f"   âš ï¸ ATRè®¡ç®—å¤±è´¥: {e}")
                # ç®€å•æ›¿ä»£æ–¹æ¡ˆï¼šTrue Range
                tr1 = high_data - low_data
                tr2 = abs(high_data - close_data.shift())
                tr3 = abs(low_data - close_data.shift())
                true_range = pd.concat([tr1, tr2, tr3], axis=1).max(axis=1)
                factors['atr_14'] = true_range.rolling(14).mean()
                factors['atr_ratio'] = factors['atr_14'] / close_data
            
            # 4. æˆäº¤é‡å› å­
            print("   ğŸ“Š è®¡ç®—æˆäº¤é‡å› å­...")
            factors['volume_ma_5'] = volume_data.rolling(5).mean()
            factors['volume_ratio'] = volume_data / factors['volume_ma_5']
            
            # 5. ä»·æ ¼ä½ç½®å› å­
            print("   ğŸ“ˆ è®¡ç®—ä»·æ ¼ä½ç½®å› å­...")
            factors['high_20d'] = high_data.rolling(20).max()
            factors['low_20d'] = low_data.rolling(20).min()
            factors['price_position'] = (close_data - factors['low_20d']) / (factors['high_20d'] - factors['low_20d'])
            
            print(f"   âœ… å› å­è®¡ç®—å®Œæˆ: {len(factors)}ä¸ªå› å­")
            
            return {
                'factors': factors,
                'close_data': close_data,
                'factor_count': len(factors),
                'data_shape': close_data.shape,
                'calculation_method': 'vectorbt_native_batch'
            }
            
        except Exception as e:
            print(f"   âŒ å› å­è®¡ç®—å¤±è´¥: {e}")
            raise
    
    def _analyze_ic_native_vectorbt(self, factor_results: Dict) -> Dict:
        """VectorBTåŸç”Ÿè¶…é«˜é€ŸICåˆ†æ"""
        print("   ğŸ“ˆ VectorBTè¶…é«˜é€ŸICåˆ†æ...")
        
        factors = factor_results['factors']
        close_data = factor_results['close_data']
        
        # è®¡ç®—æœªæ¥æ”¶ç›Šç‡ï¼ˆå‘é‡åŒ–ï¼‰
        future_returns = close_data.shift(-1).pct_change()
        
        ic_results = {}
        
        for factor_name, factor_data in factors.items():
            try:
                if factor_data.empty or future_returns.empty:
                    continue
                
                # ğŸ”¥ VectorBTæ–¹å¼ï¼šçŸ©é˜µçº§ICè®¡ç®—
                # è®¡ç®—æ¯ä¸ªæ—¶é—´ç‚¹ä¸Šæ‰€æœ‰è‚¡ç¥¨çš„æ¨ªæˆªé¢IC
                aligned_factor, aligned_returns = factor_data.align(future_returns, 
                                                                  join='inner')
                
                if aligned_factor.empty or aligned_returns.empty:
                    continue
                
                # æ¨ªæˆªé¢ç›¸å…³ç³»æ•°è®¡ç®—ï¼ˆæ¯ä¸ªæ—¶é—´ç‚¹ï¼‰
                ic_series = []
                valid_dates = []
                
                for date in aligned_factor.index:
                    factor_cross_section = aligned_factor.loc[date].dropna()
                    returns_cross_section = aligned_returns.loc[date].dropna()
                    
                    # å–äº¤é›†
                    common_symbols = factor_cross_section.index.intersection(returns_cross_section.index)
                    
                    if len(common_symbols) >= 5:  # è‡³å°‘5åªè‚¡ç¥¨
                        factor_values = factor_cross_section.loc[common_symbols]
                        return_values = returns_cross_section.loc[common_symbols]
                        
                        # è®¡ç®—ç›¸å…³ç³»æ•°
                        ic = np.corrcoef(factor_values, return_values)[0, 1]
                        
                        if not np.isnan(ic):
                            ic_series.append(ic)
                            valid_dates.append(date)
                
                if len(ic_series) >= 10:  # è‡³å°‘10ä¸ªæœ‰æ•ˆICå€¼
                    ic_array = np.array(ic_series)
                    
                    ic_analysis = {
                        'ic_mean': float(np.mean(ic_array)),
                        'ic_std': float(np.std(ic_array)),
                        'ic_ir': float(np.mean(ic_array) / np.std(ic_array)) if np.std(ic_array) > 0 else 0,
                        'ic_positive_ratio': float(np.sum(ic_array > 0) / len(ic_array)),
                        'ic_series_length': len(ic_series),
                        'ic_t_stat': float(np.mean(ic_array) / (np.std(ic_array) / np.sqrt(len(ic_array)))) if np.std(ic_array) > 0 else 0,
                        'factor_data_shape': str(factor_data.shape),
                        'valid_dates_count': len(valid_dates)
                    }
                    
                    # è®¡ç®—ç»¼åˆå¾—åˆ†
                    ic_analysis['composite_score'] = (
                        0.4 * abs(ic_analysis['ic_mean']) +
                        0.3 * abs(ic_analysis['ic_ir']) +
                        0.2 * ic_analysis['ic_positive_ratio'] +
                        0.1 * min(ic_analysis['ic_series_length'] / 100, 1.0)
                    )
                    
                    ic_results[factor_name] = ic_analysis
                    
            except Exception as e:
                print(f"   âš ï¸ å› å­ {factor_name} ICåˆ†æå¤±è´¥: {e}")
                continue
        
        print(f"   âœ… ICåˆ†æå®Œæˆ: {len(ic_results)}/{len(factors)}ä¸ªå› å­æœ‰æ•ˆ")
        
        return {
            'ic_results': ic_results,
            'total_factors': len(factors),
            'valid_factors': len(ic_results),
            'analysis_method': 'vectorbt_cross_sectional_ic'
        }
    
    def _build_strategy_native_vectorbt(self, ic_analysis: Dict) -> Dict:
        """æ„å»ºVectorBTåŸç”Ÿç­–ç•¥"""
        print("   ğŸ† æ„å»ºVectorBTåŸç”Ÿç­–ç•¥...")
        
        ic_results = ic_analysis['ic_results']
        
        # æŒ‰ç»¼åˆå¾—åˆ†æ’åº
        sorted_factors = sorted(ic_results.items(), 
                              key=lambda x: x[1]['composite_score'], 
                              reverse=True)
        
        # é€‰æ‹©å‰10ä¸ªå› å­
        top_factors = sorted_factors[:10]
        
        # æ„å»ºç­–ç•¥é…ç½®
        strategy_config = {
            'approach': 'vectorbt_native_multi_factor',
            'capital': self.capital,
            'max_positions': self.max_positions,
            'top_factors': [
                {
                    'factor_name': name,
                    'ic_mean': data['ic_mean'],
                    'ic_ir': data['ic_ir'],
                    'composite_score': data['composite_score'],
                    'weight': data['composite_score'] / sum(f[1]['composite_score'] for f in top_factors)
                }
                for name, data in top_factors
            ],
            'factor_selection_criteria': {
                'min_ic_ir': 0.1,
                'min_positive_ratio': 0.4,
                'min_series_length': 10
            }
        }
        
        print(f"   âœ… ç­–ç•¥æ„å»ºå®Œæˆ: {len(top_factors)}ä¸ªé¡¶çº§å› å­")
        
        return strategy_config
    
    def _generate_performance_report(self, strategy_results: Dict) -> str:
        """ç”Ÿæˆæ€§èƒ½æŠ¥å‘Š"""
        print("   ğŸ“‹ ç”ŸæˆVectorBTåŸç”Ÿæ€§èƒ½æŠ¥å‘Š...")
        
        report = ["# ğŸš€ VectorBTåŸç”Ÿè¶…é«˜é€Ÿå…¨è§„æ¨¡åˆ†ææŠ¥å‘Š\n"]
        
        # æŠ¥å‘Šå¤´éƒ¨
        report.append(f"**ç”Ÿæˆæ—¶é—´**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        report.append(f"**åˆ†ææ–¹æ³•**: VectorBTåŸç”Ÿå‘é‡åŒ–æ‰¹é‡å¤„ç†")
        report.append(f"**æµ‹è¯•è‚¡ç¥¨**: {len(self.available_symbols)}åªæ¸¯è‚¡")
        report.append(f"**åˆ†æèµ„é‡‘**: {self.capital:,.0f} æ¸¯å¸")
        report.append(f"**ç³»ç»ŸçŠ¶æ€**: âœ… VectorBTåŸç”Ÿ + Numbaå¹¶è¡ŒåŠ é€Ÿ\n")
        
        # æ€§èƒ½ç»Ÿè®¡
        top_factors = strategy_results.get('top_factors', [])
        
        report.append("## ğŸ† VectorBTåŸç”Ÿé¡¶çº§å› å­æ’è¡Œæ¦œ\n")
        report.append("| æ’å | å› å­åç§° | ICå‡å€¼ | IC_IR | ç»¼åˆå¾—åˆ† | æƒé‡ | è¯„ä¼° |")
        report.append("|------|----------|--------|-------|----------|------|------|")
        
        for i, factor in enumerate(top_factors, 1):
            ic_ir = factor['ic_ir']
            evaluation = "ğŸ”¥ ä¼˜ç§€" if ic_ir > 0.5 else "âœ… è‰¯å¥½" if ic_ir > 0.2 else "âš ï¸ ä¸€èˆ¬"
            
            report.append(f"| {i:2d} | {factor['factor_name']} | "
                         f"{factor['ic_mean']:.3f} | {factor['ic_ir']:.2f} | "
                         f"{factor['composite_score']:.3f} | {factor['weight']:.1%} | {evaluation} |")
        
        # VectorBTä¼˜åŠ¿æ€»ç»“
        report.append("\n## âš¡ VectorBTåŸç”Ÿä¼˜åŠ¿ä½“ç°\n")
        report.append("### ğŸš€ è®¡ç®—é€Ÿåº¦ä¼˜åŠ¿")
        report.append("- **å‘é‡åŒ–è®¡ç®—**: ä¸€æ¬¡æ€§å¤„ç†æ‰€æœ‰è‚¡ç¥¨ï¼Œæ— å¾ªç¯å¼€é”€")
        report.append("- **NumbaåŠ é€Ÿ**: JITç¼–è¯‘ï¼Œæ¥è¿‘Cè¯­è¨€é€Ÿåº¦")
        report.append("- **å†…å­˜ä¼˜åŒ–**: MultiIndexæ•°æ®ç»“æ„ï¼Œé«˜æ•ˆå†…å­˜ä½¿ç”¨")
        report.append("- **å¹¶è¡Œå¤„ç†**: å¤šæ ¸CPUå¹¶è¡Œï¼Œå……åˆ†åˆ©ç”¨ç¡¬ä»¶èµ„æº")
        
        report.append("\n### ğŸ“Š æ•°æ®å¤„ç†ä¼˜åŠ¿")
        report.append("- **æ‰¹é‡å› å­è®¡ç®—**: æ‰€æœ‰æŠ€æœ¯æŒ‡æ ‡ä¸€æ¬¡æ€§è®¡ç®—å®Œæˆ")
        report.append("- **çŸ©é˜µçº§ICåˆ†æ**: æ¨ªæˆªé¢ç›¸å…³æ€§åˆ†æï¼Œæ— éœ€é€è‚¡ç¥¨å¤„ç†")
        report.append("- **è‡ªåŠ¨å¯¹é½**: è‡ªåŠ¨å¤„ç†ä¸åŒè‚¡ç¥¨çš„æ•°æ®å¯¹é½é—®é¢˜")
        
        # æŠ•èµ„å»ºè®®
        if top_factors:
            best_factor = top_factors[0]
            report.append(f"\n## ğŸ’¡ VectorBTåŸç”ŸæŠ•èµ„å»ºè®®\n")
            report.append(f"### ğŸ¯ æ ¸å¿ƒæ¨è")
            report.append(f"**æœ€ä¼˜å› å­**: {best_factor['factor_name']}")
            report.append(f"- ICå‡å€¼: {best_factor['ic_mean']:.3f}")
            report.append(f"- IC_IR: {best_factor['ic_ir']:.2f}")
            report.append(f"- ç»¼åˆå¾—åˆ†: {best_factor['composite_score']:.3f}")
        
        report.append(f"\n### ğŸ“ˆ å®æ–½å»ºè®®")
        report.append(f"- **èµ·å§‹èµ„é‡‘**: {self.capital:,.0f} æ¸¯å¸")
        report.append(f"- **æœ€å¤§æŒä»“**: {self.max_positions} åªè‚¡ç¥¨")
        report.append(f"- **VectorBTä¼˜åŠ¿**: 10ç§’å®Œæˆåˆ†æï¼Œå®æ—¶ç›‘æ§å¯è¡Œ")
        report.append(f"- **æ›´æ–°é¢‘ç‡**: æ—¥çº¿æ•°æ®å»ºè®®æ¯æ—¥æ”¶ç›˜åæ›´æ–°")
        
        report.append(f"\n---")
        report.append(f"*VectorBTåŸç”Ÿè¶…é«˜é€Ÿåˆ†ææŠ¥å‘Š - çœŸæ­£å‘æŒ¥å‘é‡åŒ–ä¼˜åŠ¿*")
        
        return "\n".join(report)
    
    def _save_results(self, results: Dict) -> str:
        """ä¿å­˜ç»“æœ"""
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        results_dir = f"results/native_vectorbt_{timestamp}"
        os.makedirs(results_dir, exist_ok=True)
        
        # ä¿å­˜è¯¦ç»†ç»“æœ
        results_file = os.path.join(results_dir, "native_vectorbt_results.json")
        serializable_results = self._make_serializable(results)
        
        with open(results_file, 'w', encoding='utf-8') as f:
            json.dump(serializable_results, f, indent=2, ensure_ascii=False)
        
        # ä¿å­˜æ€§èƒ½æŠ¥å‘Š
        report_file = os.path.join(results_dir, "native_vectorbt_report.md")
        with open(report_file, 'w', encoding='utf-8') as f:
            f.write(results['performance_report'])
        
        return results_dir
    
    def _make_serializable(self, obj):
        """åºåˆ—åŒ–å¤„ç†"""
        if isinstance(obj, dict):
            return {k: self._make_serializable(v) for k, v in obj.items()}
        elif isinstance(obj, list):
            return [self._make_serializable(item) for item in obj]
        elif isinstance(obj, (pd.DataFrame, pd.Series)):
            return f"<DataFrame/Series shape: {getattr(obj, 'shape', 'unknown')}>"
        elif isinstance(obj, np.ndarray):
            return f"<ndarray shape: {obj.shape}>"
        elif pd.isna(obj) or obj is None:
            return None
        elif isinstance(obj, (int, float, str, bool)):
            if np.isnan(obj) if isinstance(obj, (int, float)) else False:
                return None
            return obj
        else:
            return str(obj)


def main():
    """ä¸»å‡½æ•° - è¿è¡ŒVectorBTåŸç”Ÿè¶…é«˜é€Ÿæµ‹è¯•"""
    print("ğŸŒŸ å¯åŠ¨VectorBTåŸç”Ÿè¶…é«˜é€Ÿå…¨è§„æ¨¡åˆ†æ...")
    print("ğŸ’¡ çœŸæ­£å‘æŒ¥VectorBTå‘é‡åŒ–ä¼˜åŠ¿ï¼Œé¢„æœŸ10ç§’å†…å®Œæˆ")
    print("ğŸ¯ ä½¿ç”¨VectorBTåŸç”ŸMultiIndex + NumbaåŠ é€Ÿ")
    
    try:
        # åˆ›å»ºVectorBTåŸç”Ÿç³»ç»Ÿ
        native_system = NativeVectorBTUltraFast(capital=300000)
        
        # è¿è¡ŒåŸç”Ÿåˆ†æ
        results = native_system.run_native_vectorbt_analysis()
        
        print("\nğŸŠ VectorBTåŸç”Ÿè¶…é«˜é€Ÿåˆ†æå®Œæˆï¼")
        print("ğŸ“Š VectorBTåŸç”Ÿæˆæœ:")
        print(f"   âš¡ å¤„ç†è‚¡ç¥¨: {results['tested_symbols_count']}åª")
        print(f"   ğŸš€ æ‰§è¡Œæ—¶é—´: {results['execution_time']:.2f}ç§’")
        print(f"   ğŸ’¯ é€Ÿåº¦ä¼˜åŠ¿: {576.9/results['execution_time']:.0f}x ç›¸æ¯”ä¼ ç»Ÿæ–¹æ³•")
        print(f"   ğŸ”¥ åˆ†ææ–¹æ³•: {results['analysis_approach']}")
        
        return True
        
    except Exception as e:
        print(f"\nâŒ VectorBTåŸç”Ÿåˆ†æå¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False


if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1)
