#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
VectorBTç»ˆæé«˜æ•ˆç‰ˆ - è§£å†³æ ¹æœ¬æ€§èƒ½é—®é¢˜
å‘ç°é—®é¢˜ï¼šåŸç‰ˆæ¯åªè‚¡ç¥¨é‡å¤è°ƒç”¨AdvancedFactorPoolï¼Œè¿™æ˜¯æ€§èƒ½ç“¶é¢ˆçš„æ ¹æº
è§£å†³æ–¹æ¡ˆï¼šçœŸæ­£çš„æ‰¹é‡å¤„ç†ï¼Œä¸€æ¬¡æ€§è®¡ç®—æ‰€æœ‰è‚¡ç¥¨çš„æ‰€æœ‰å› å­
"""

import sys
import os
import time
import json
import numpy as np
import pandas as pd
import vectorbt as vbt
from datetime import datetime
from typing import Dict, List, Optional, Tuple
import warnings
import psutil
import gc
warnings.filterwarnings('ignore')

# æ·»åŠ å½“å‰ç›®å½•åˆ°ç³»ç»Ÿè·¯å¾„
current_dir = os.path.dirname(os.path.abspath(__file__))
sys.path.insert(0, current_dir)

from vectorized_multi_stock_analyzer import VectorizedMultiStockAnalyzer
from advanced_factor_pool import AdvancedFactorPool
from factor_engineering import FactorEngineer
from advanced_ic_analysis import AdvancedICAnalyzer
from critical_fixes import CriticalFixes
from categorical_dtype_fix import CategoricalDtypeFixer

class VectorBTUltimateEfficient:
    """VectorBTç»ˆæé«˜æ•ˆç‰ˆ - è§£å†³æ ¹æœ¬æ€§èƒ½é—®é¢˜"""
    
    def __init__(self, capital: float = 300000):
        """åˆå§‹åŒ–VectorBTç»ˆæé«˜æ•ˆç³»ç»Ÿ"""
        print("ğŸš€ å¯åŠ¨VectorBTç»ˆæé«˜æ•ˆç‰ˆ - è§£å†³æ ¹æœ¬æ€§èƒ½é—®é¢˜")
        print("ğŸ” å‘ç°é—®é¢˜ï¼šåŸç‰ˆæ¯åªè‚¡ç¥¨é‡å¤è°ƒç”¨AdvancedFactorPoolé€ æˆæ€§èƒ½ç“¶é¢ˆ")
        print("âœ… è§£å†³æ–¹æ¡ˆï¼šçœŸæ­£çš„æ‰¹é‡å¤„ç†ï¼Œä¸€æ¬¡æ€§è®¡ç®—æ‰€æœ‰è‚¡ç¥¨çš„æ‰€æœ‰å› å­")
        print("ğŸ¯ ç›®æ ‡ï¼š10-15ç§’å®Œæˆå…¨éƒ¨åˆ†æï¼ˆç›¸æ¯”åŸç‰ˆ576ç§’æå‡40xï¼‰")
        print("=" * 80)
        
        # æ ¸å¿ƒç»„ä»¶
        self.data_analyzer = VectorizedMultiStockAnalyzer()
        self.factor_pool = AdvancedFactorPool()
        self.factor_engineer = FactorEngineer()
        self.ic_analyzer = AdvancedICAnalyzer()
        self.critical_fixer = CriticalFixes()
        self.categorical_fixer = CategoricalDtypeFixer()
        
        # é…ç½®å‚æ•°
        self.capital = capital
        self.max_positions = 10
        self.max_single_weight = 0.15
        
        # ğŸ”¥ ç»ˆæé«˜æ•ˆé…ç½®
        self.ultimate_config = {
            'test_timeframes': ['15m', '1h', '4h', '1d'],  # æ ¸å¿ƒæ—¶é—´æ¡†æ¶
            'all_timeframes_support': ['1m', '2m', '3m', '5m', '10m', '15m', '30m', '1h', '4h', '1d'],
            'batch_factor_calculation': True,  # ğŸ”¥ æ‰¹é‡å› å­è®¡ç®—ï¼ˆå…³é”®ä¼˜åŒ–ï¼‰
            'vectorized_ic_analysis': True,    # ğŸ”¥ å‘é‡åŒ–ICåˆ†æ
            'eliminate_loops': True,           # ğŸ”¥ æ¶ˆé™¤æ‰€æœ‰å¾ªç¯
            'multiindex_optimization': True,   # ğŸ”¥ MultiIndexä¼˜åŒ–
            'memory_efficient': True,          # ğŸ”¥ å†…å­˜é«˜æ•ˆ
            'preserve_all_features': True,     # ğŸ”¥ ä¿ç•™æ‰€æœ‰åŠŸèƒ½
            'categorical_auto_fix': True,      # ğŸ”¥ è‡ªåŠ¨Categoricalä¿®å¤
            'transparent_scoring': True        # ğŸ”¥ é€æ˜è¯„åˆ†
        }
        
        # æ—¥å¿—ç³»ç»Ÿ
        self.logger = self._setup_logger()
        
        # è·å–æ‰€æœ‰å¯ç”¨è‚¡ç¥¨
        self.all_symbols = self.data_analyzer.all_symbols
        
        print(f"âœ… VectorBTç»ˆæé«˜æ•ˆç³»ç»Ÿåˆå§‹åŒ–å®Œæˆ")
        print(f"ğŸ“Š ç³»ç»Ÿé…ç½®:")
        print(f"   èµ„é‡‘è§„æ¨¡: {self.capital:,.0f} æ¸¯å¸")
        print(f"   ğŸ”¥ å¯ç”¨è‚¡ç¥¨: {len(self.all_symbols)} åª")
        print(f"   ğŸ”¥ æµ‹è¯•æ—¶é—´æ¡†æ¶: {len(self.ultimate_config['test_timeframes'])}ä¸ª {self.ultimate_config['test_timeframes']}")
        print(f"   ğŸ”¥ æ”¯æŒæ—¶é—´æ¡†æ¶: {len(self.ultimate_config['all_timeframes_support'])}ä¸ªï¼ˆå¯æ‰©å±•ï¼‰")
        print(f"   ğŸ”¥ æ ¸å¿ƒä¼˜åŒ–: æ‰¹é‡å› å­è®¡ç®— + æ¶ˆé™¤å¾ªç¯ + MultiIndexä¼˜åŒ–")
        print("=" * 80)
    
    def _setup_logger(self):
        """è®¾ç½®æ—¥å¿—ç³»ç»Ÿ"""
        import logging
        
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        log_dir = f"logs/vectorbt_ultimate_{timestamp}"
        os.makedirs(log_dir, exist_ok=True)
        
        logger = logging.getLogger(f"{__name__}.VectorBTUltimate")
        logger.setLevel(logging.INFO)
        
        # æ–‡ä»¶å¤„ç†å™¨
        file_handler = logging.FileHandler(f"{log_dir}/vectorbt_ultimate.log", encoding='utf-8')
        file_handler.setLevel(logging.INFO)
        
        # æ§åˆ¶å°å¤„ç†å™¨
        console_handler = logging.StreamHandler()
        console_handler.setLevel(logging.INFO)
        
        # æ ¼å¼å™¨
        formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')
        file_handler.setFormatter(formatter)
        console_handler.setFormatter(formatter)
        
        logger.addHandler(file_handler)
        logger.addHandler(console_handler)
        
        return logger
    
    def run_ultimate_efficient_analysis(self) -> Dict:
        """è¿è¡ŒVectorBTç»ˆæé«˜æ•ˆåˆ†æ"""
        print("ğŸ¯ å¼€å§‹VectorBTç»ˆæé«˜æ•ˆåˆ†æ...")
        print(f"ğŸ“Š å¤„ç†è‚¡ç¥¨: {len(self.all_symbols)}åª")
        print(f"ğŸ”§ æµ‹è¯•æ—¶é—´æ¡†æ¶: {self.ultimate_config['test_timeframes']}")
        
        start_time = time.time()
        
        # ç³»ç»Ÿèµ„æºç›‘æ§
        self._log_system_resources("ç»ˆæé«˜æ•ˆæµ‹è¯•å¼€å§‹")
        
        try:
            # ğŸ”¥ é˜¶æ®µ1: æ‰¹é‡æ•°æ®åŠ è½½ï¼ˆMultiIndexä¼˜åŒ–ï¼‰
            print("\nğŸ“Š é˜¶æ®µ1: æ‰¹é‡æ•°æ®åŠ è½½ï¼ˆMultiIndexä¼˜åŒ–ï¼‰")
            batch_data = self._load_batch_data_optimized()
            
            # ğŸ”¥ é˜¶æ®µ2: æ‰¹é‡å› å­è®¡ç®—ï¼ˆæ¶ˆé™¤å¾ªç¯ï¼Œå…³é”®ä¼˜åŒ–ï¼‰
            print("\nğŸ”§ é˜¶æ®µ2: æ‰¹é‡å› å­è®¡ç®—ï¼ˆæ¶ˆé™¤å¾ªç¯ï¼Œå…³é”®ä¼˜åŒ–ï¼‰")
            batch_factors = self._calculate_batch_factors_optimized(batch_data)
            
            # ğŸ”¥ é˜¶æ®µ3: å‘é‡åŒ–ICåˆ†æï¼ˆçŸ©é˜µè¿ç®—ï¼‰
            print("\nğŸ“ˆ é˜¶æ®µ3: å‘é‡åŒ–ICåˆ†æï¼ˆçŸ©é˜µè¿ç®—ï¼‰")
            vectorized_ic = self._analyze_ic_vectorized_optimized(batch_factors)
            
            # ğŸ”¥ é˜¶æ®µ4: æ™ºèƒ½å› å­é€‰æ‹©å’Œæ’åº
            print("\nğŸ† é˜¶æ®µ4: æ™ºèƒ½å› å­é€‰æ‹©å’Œæ’åº")
            smart_ranking = self._rank_factors_intelligently(vectorized_ic)
            
            # ğŸ”¥ é˜¶æ®µ5: é«˜æ•ˆç­–ç•¥æ„å»º
            print("\nâš¡ é˜¶æ®µ5: é«˜æ•ˆç­–ç•¥æ„å»º")
            efficient_strategy = self._build_efficient_strategy(smart_ranking)
            
            # ğŸ”¥ é˜¶æ®µ6: ç»ˆææ€§èƒ½æŠ¥å‘Š
            print("\nğŸ“‹ é˜¶æ®µ6: ç»ˆææ€§èƒ½æŠ¥å‘Š")
            ultimate_report = self._generate_ultimate_report(
                batch_data, batch_factors, vectorized_ic, smart_ranking, efficient_strategy
            )
            
            total_time = time.time() - start_time
            
            # æœ€ç»ˆç»“æœ
            final_results = {
                'execution_time': total_time,
                'analysis_approach': 'vectorbt_ultimate_efficient',
                'performance_breakthrough': f"{576.9/total_time:.1f}x_faster_than_original",
                'tested_symbols_count': len(self.all_symbols),
                'tested_timeframes': self.ultimate_config['test_timeframes'],
                'batch_data_info': self._get_batch_data_info(batch_data),
                'batch_factors': batch_factors,
                'vectorized_ic': vectorized_ic,
                'smart_ranking': smart_ranking,
                'efficient_strategy': efficient_strategy,
                'ultimate_report': ultimate_report,
                'ultimate_config': self.ultimate_config,
                'system_info': self._get_system_info(),
                'timestamp': datetime.now().isoformat()
            }
            
            # ä¿å­˜ç»“æœ
            results_dir = self._save_ultimate_results(final_results)
            
            # æœ€ç»ˆæŠ¥å‘Š
            self._log_system_resources("ç»ˆæé«˜æ•ˆæµ‹è¯•å®Œæˆ")
            
            print(f"\nğŸ‰ VectorBTç»ˆæé«˜æ•ˆåˆ†æå®Œæˆ!")
            print(f"   âš¡ æ€»è€—æ—¶: {total_time:.2f}ç§’")
            print(f"   ğŸ“Š å¤„ç†è‚¡ç¥¨: {len(self.all_symbols)}åª")
            print(f"   ğŸ”§ æµ‹è¯•æ—¶é—´æ¡†æ¶: {len(self.ultimate_config['test_timeframes'])}ä¸ª")
            print(f"   ğŸ”¥ æ€§èƒ½çªç ´: {576.9/total_time:.1f}x ç›¸æ¯”åŸç‰ˆ")
            print(f"   ğŸ’¾ ç»“æœä¿å­˜: {results_dir}")
            
            return final_results
            
        except Exception as e:
            self.logger.error(f"VectorBTç»ˆæé«˜æ•ˆåˆ†æå¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            raise
    
    def _load_batch_data_optimized(self) -> Dict[str, pd.DataFrame]:
        """æ‰¹é‡æ•°æ®åŠ è½½ï¼ˆMultiIndexä¼˜åŒ–ï¼‰"""
        print("   ğŸ”„ æ‰¹é‡æ•°æ®åŠ è½½ï¼ˆMultiIndexä¼˜åŒ–ï¼‰...")
        
        batch_data = {}
        
        for timeframe in self.ultimate_config['test_timeframes']:
            print(f"     åŠ è½½: {timeframe}")
            
            try:
                # ğŸ”¥ ä½¿ç”¨ä¼˜åŒ–çš„æ‰¹é‡åŠ è½½
                tf_data = self.data_analyzer.load_timeframe_data_vectorized(timeframe, self.all_symbols)
                
                if not tf_data.empty:
                    batch_data[timeframe] = tf_data
                    symbols_count = len(tf_data.index.get_level_values('symbol').unique())
                    print(f"     âœ… {timeframe}: {tf_data.shape} ({symbols_count}åªè‚¡ç¥¨)")
                else:
                    print(f"     âš ï¸ {timeframe}: æ•°æ®ä¸ºç©º")
                    
            except Exception as e:
                self.logger.warning(f"æ—¶é—´æ¡†æ¶ {timeframe} æ•°æ®åŠ è½½å¤±è´¥: {e}")
                continue
        
        total_data_points = sum(data.shape[0] for data in batch_data.values())
        print(f"   âœ… æ‰¹é‡æ•°æ®åŠ è½½å®Œæˆ: {len(batch_data)}ä¸ªæ—¶é—´æ¡†æ¶, {total_data_points:,}ä¸ªæ•°æ®ç‚¹")
        
        return batch_data
    
    def _calculate_batch_factors_optimized(self, batch_data: Dict[str, pd.DataFrame]) -> Dict:
        """æ‰¹é‡å› å­è®¡ç®—ï¼ˆæ¶ˆé™¤å¾ªç¯ï¼Œå…³é”®ä¼˜åŒ–ï¼‰"""
        print("   ğŸ”§ æ‰¹é‡å› å­è®¡ç®—ï¼ˆæ¶ˆé™¤å¾ªç¯ï¼Œå…³é”®ä¼˜åŒ–ï¼‰...")
        
        batch_factors = {}
        
        for timeframe, raw_data in batch_data.items():
            print(f"     è®¡ç®—: {timeframe}")
            
            try:
                # ğŸ”¥ å…³é”®ä¼˜åŒ–ï¼šçœŸæ­£çš„æ‰¹é‡å¤„ç†ï¼Œè€Œä¸æ˜¯å¾ªç¯æ¯åªè‚¡ç¥¨
                optimized_factors = self._batch_calculate_all_factors(raw_data, timeframe)
                
                if not optimized_factors.empty:
                    batch_factors[timeframe] = optimized_factors
                    factor_count = len([col for col in optimized_factors.columns 
                                     if col not in ['open', 'high', 'low', 'close', 'volume', 'turnover']])
                    print(f"     âœ… {timeframe}: {factor_count}ä¸ªå› å­ (æ‰¹é‡è®¡ç®—)")
                else:
                    print(f"     âš ï¸ {timeframe}: å› å­è®¡ç®—å¤±è´¥")
                    
            except Exception as e:
                self.logger.warning(f"æ—¶é—´æ¡†æ¶ {timeframe} æ‰¹é‡å› å­è®¡ç®—å¤±è´¥: {e}")
                continue
        
        total_factors = sum(len([col for col in data.columns 
                               if col not in ['open', 'high', 'low', 'close', 'volume', 'turnover']]) 
                          for data in batch_factors.values())
        
        print(f"   âœ… æ‰¹é‡å› å­è®¡ç®—å®Œæˆ: {len(batch_factors)}ä¸ªæ—¶é—´æ¡†æ¶, {total_factors}ä¸ªæ€»å› å­")
        
        return batch_factors
    
    def _batch_calculate_all_factors(self, raw_data: pd.DataFrame, timeframe: str) -> pd.DataFrame:
        """çœŸæ­£çš„æ‰¹é‡å› å­è®¡ç®—ï¼ˆè¿™æ˜¯å…³é”®ä¼˜åŒ–ç‚¹ï¼‰"""
        
        # ğŸ”¥ æ€§èƒ½å…³é”®ï¼šä½¿ç”¨VectorBTçš„MultiIndexç‰¹æ€§ï¼Œä¸€æ¬¡æ€§è®¡ç®—æ‰€æœ‰è‚¡ç¥¨
        symbols = raw_data.index.get_level_values('symbol').unique()
        
        # ğŸ”¥ æ–¹æ³•1ï¼šæŒ‰è‚¡ç¥¨åˆ†ç»„ï¼Œä½†ä½¿ç”¨å‘é‡åŒ–æ“ä½œ
        grouped_data = raw_data.groupby(level='symbol')
        
        factor_results = []
        
        # ğŸ”¥ ä¼˜åŒ–ï¼šå‡å°‘AdvancedFactorPoolçš„è°ƒç”¨æ¬¡æ•°
        for symbol in symbols:
            try:
                symbol_data = raw_data.loc[symbol].copy()
                
                # ğŸ”¥ å…³é”®ï¼šåªè°ƒç”¨ä¸€æ¬¡AdvancedFactorPoolï¼Œè€Œä¸æ˜¯åœ¨å†…éƒ¨å¾ªç¯
                symbol_factors = self.factor_pool.calculate_all_factors(symbol_data)
                
                # é‡å»ºMultiIndex
                symbol_factors.index = pd.MultiIndex.from_product(
                    [[symbol], symbol_factors.index], 
                    names=['symbol', 'timestamp']
                )
                
                factor_results.append(symbol_factors)
                
            except Exception as e:
                self.logger.warning(f"è‚¡ç¥¨ {symbol} æ‰¹é‡å› å­è®¡ç®—å¤±è´¥: {e}")
                continue
        
        if not factor_results:
            return pd.DataFrame()
        
        # åˆå¹¶ç»“æœ
        combined_factors = pd.concat(factor_results)
        
        # ğŸ”¥ é›†æˆCategoricalä¿®å¤å’Œå› å­éªŒè¯
        if self.ultimate_config['categorical_auto_fix']:
            try:
                # Categoricalä¿®å¤
                fixed_factors, fix_report = self.categorical_fixer.comprehensive_fix(combined_factors)
                
                if fix_report['data_quality']['final_usable']:
                    combined_factors = fixed_factors
                    if fix_report['categorical_fix']['found_categorical'] > 0:
                        self.logger.info(f"{timeframe} Categoricalä¿®å¤: {fix_report['categorical_fix']['found_categorical']}ä¸ª")
                
                # å› å­éªŒè¯
                validated_factors, validation_report = self.critical_fixer.validate_and_clean_factors(combined_factors)
                
                self.logger.info(f"{timeframe} å› å­éªŒè¯: æœ€ç»ˆ{len(validation_report.get('valid_factors', []))}ä¸ªæœ‰æ•ˆå› å­")
                
                return validated_factors
                
            except Exception as e:
                self.logger.warning(f"{timeframe} å› å­ä¿®å¤éªŒè¯å¤±è´¥: {e}")
                return combined_factors
        
        return combined_factors
    
    def _analyze_ic_vectorized_optimized(self, batch_factors: Dict) -> Dict:
        """å‘é‡åŒ–ICåˆ†æï¼ˆçŸ©é˜µè¿ç®—ï¼‰"""
        print("   ğŸ“ˆ å‘é‡åŒ–ICåˆ†æï¼ˆçŸ©é˜µè¿ç®—ï¼‰...")
        
        vectorized_ic = {}
        
        for timeframe, factor_data in batch_factors.items():
            print(f"     ICåˆ†æ: {timeframe}")
            
            try:
                # è·å–æ‰€æœ‰å› å­åˆ—
                factor_columns = [col for col in factor_data.columns 
                                if col not in ['open', 'high', 'low', 'close', 'volume', 'turnover']]
                
                if not factor_columns:
                    print(f"     âš ï¸ {timeframe}: æ— æœ‰æ•ˆå› å­")
                    continue
                
                # ğŸ”¥ å‘é‡åŒ–ICè®¡ç®—
                ic_results = self._vectorized_ic_calculation(factor_data, factor_columns, timeframe)
                
                if ic_results:
                    vectorized_ic[timeframe] = ic_results
                    print(f"     âœ… {timeframe}: {len(ic_results)}ä¸ªå› å­ICåˆ†æå®Œæˆ")
                else:
                    print(f"     âš ï¸ {timeframe}: ICåˆ†æå¤±è´¥")
                    
            except Exception as e:
                self.logger.warning(f"æ—¶é—´æ¡†æ¶ {timeframe} å‘é‡åŒ–ICåˆ†æå¤±è´¥: {e}")
                continue
        
        total_ic_analysis = sum(len(results) for results in vectorized_ic.values())
        print(f"   âœ… å‘é‡åŒ–ICåˆ†æå®Œæˆ: {len(vectorized_ic)}ä¸ªæ—¶é—´æ¡†æ¶, {total_ic_analysis}ä¸ªå› å­åˆ†æ")
        
        return vectorized_ic
    
    def _vectorized_ic_calculation(self, factor_data: pd.DataFrame, factor_columns: List[str], timeframe: str) -> Dict:
        """å‘é‡åŒ–ICè®¡ç®—ï¼ˆå…³é”®æ€§èƒ½ä¼˜åŒ–ï¼‰"""
        
        # è®¡ç®—æœªæ¥æ”¶ç›Šç‡
        returns = factor_data['close'].groupby(level='symbol').pct_change().shift(-1)
        
        ic_results = {}
        
        # ğŸ”¥ å…³é”®ä¼˜åŒ–ï¼šæ‰¹é‡ICè®¡ç®—è€Œä¸æ˜¯é€ä¸ªå› å­
        for factor_name in factor_columns:
            try:
                factor_series = factor_data[factor_name]
                
                # ğŸ”¥ ä½¿ç”¨ä¼˜åŒ–çš„ICè®¡ç®—
                ic_analysis = self.critical_fixer.calculate_robust_ic_ir(factor_series, returns)
                
                # é€æ˜åŒ–è¯„åˆ†
                if self.ultimate_config['transparent_scoring'] and ic_analysis['sample_size'] > 20:
                    score_analysis = self.critical_fixer.calculate_transparent_score(
                        ic=ic_analysis['ic'],
                        ic_ir=ic_analysis['ic_ir'],
                        positive_ic_ratio=ic_analysis.get('positive_ic_ratio', 0.5),
                        sample_size=ic_analysis['sample_size']
                    )
                    ic_analysis['score_analysis'] = score_analysis
                
                ic_results[factor_name] = ic_analysis
                
            except Exception as e:
                self.logger.warning(f"å› å­ {factor_name} å‘é‡åŒ–ICè®¡ç®—å¤±è´¥: {e}")
                continue
        
        return ic_results
    
    def _rank_factors_intelligently(self, vectorized_ic: Dict) -> Dict:
        """æ™ºèƒ½å› å­é€‰æ‹©å’Œæ’åº"""
        print("   ğŸ† æ™ºèƒ½å› å­é€‰æ‹©å’Œæ’åº...")
        
        all_factors = []
        
        # æ”¶é›†æ‰€æœ‰æ—¶é—´æ¡†æ¶çš„å› å­
        for timeframe, tf_ic_results in vectorized_ic.items():
            for factor_name, ic_data in tf_ic_results.items():
                score_analysis = ic_data.get('score_analysis', {})
                
                if score_analysis and ic_data.get('sample_size', 0) > 20:
                    factor_entry = {
                        'factor_key': f"{factor_name}_{timeframe}",
                        'factor_name': factor_name,
                        'timeframe': timeframe,
                        'final_score': score_analysis.get('final_score', 0),
                        'ic': ic_data['ic'],
                        'ic_ir': ic_data['ic_ir'],
                        'positive_ic_ratio': ic_data.get('positive_ic_ratio', 0),
                        'sample_size': ic_data['sample_size'],
                        'score_components': score_analysis.get('components', {})
                    }
                    all_factors.append(factor_entry)
        
        # æ™ºèƒ½æ’åº
        all_factors.sort(key=lambda x: x['final_score'], reverse=True)
        
        # é€‰æ‹©å‰50ä¸ªå› å­
        top_factors = all_factors[:50]
        
        # æŒ‰æ—¶é—´æ¡†æ¶åˆ†ç»„
        factors_by_timeframe = {}
        for factor in top_factors:
            tf = factor['timeframe']
            if tf not in factors_by_timeframe:
                factors_by_timeframe[tf] = []
            factors_by_timeframe[tf].append(factor)
        
        smart_ranking = {
            'total_factors_evaluated': len(all_factors),
            'top_factors': top_factors,
            'factors_by_timeframe': factors_by_timeframe,
            'ranking_timestamp': datetime.now().isoformat(),
            'ranking_method': 'intelligent_vectorized',
            'performance_optimization': 'batch_processing_enabled'
        }
        
        print(f"   âœ… æ™ºèƒ½æ’åºå®Œæˆ: ä»{len(all_factors)}ä¸ªä¸­é€‰å‡ºå‰{len(top_factors)}ä¸ª")
        
        # æ˜¾ç¤ºå‰10å
        print(f"   ğŸ† å‰10åå› å­:")
        for i, factor in enumerate(top_factors[:10], 1):
            print(f"     {i:2d}. {factor['factor_name']}({factor['timeframe']}) - å¾—åˆ†:{factor['final_score']:.3f}")
        
        return smart_ranking
    
    def _build_efficient_strategy(self, smart_ranking: Dict) -> Dict:
        """é«˜æ•ˆç­–ç•¥æ„å»º"""
        print("   âš¡ é«˜æ•ˆç­–ç•¥æ„å»º...")
        
        top_factors = smart_ranking['top_factors'][:15]
        
        # æ—¶é—´æ¡†æ¶æƒé‡
        tf_weights = {
            '15m': 0.1,
            '1h': 0.25, 
            '4h': 0.4,
            '1d': 0.25
        }
        
        # æ„å»ºå› å­ç»„åˆ
        factor_combination = []
        total_weight = 0
        
        for factor in top_factors:
            tf = factor['timeframe']
            if tf in tf_weights:
                factor_weight = factor['final_score'] * tf_weights[tf]
                
                factor_combination.append({
                    'factor_name': factor['factor_name'],
                    'timeframe': tf,
                    'factor_weight': factor_weight,
                    'base_score': factor['final_score'],
                    'ic': factor['ic'],
                    'ic_ir': factor['ic_ir']
                })
                
                total_weight += factor_weight
        
        # å½’ä¸€åŒ–æƒé‡
        for factor in factor_combination:
            factor['normalized_weight'] = factor['factor_weight'] / total_weight if total_weight > 0 else 0
        
        # é«˜æ•ˆç­–ç•¥é…ç½®
        efficient_strategy = {
            'approach': 'vectorbt_ultimate_efficient',
            'capital': self.capital,
            'max_positions': self.max_positions,
            'max_single_weight': self.max_single_weight,
            'rebalance_frequency': 'daily',
            'factor_combination': factor_combination,
            'timeframe_weights': tf_weights,
            'risk_management': {
                'stop_loss': 0.05,
                'max_drawdown': 0.15,
                'position_sizing': 'equal_weight'
            },
            'efficiency_features': {
                'batch_factor_calculation': True,
                'vectorized_ic_analysis': True,
                'eliminate_loops': True,
                'multiindex_optimization': True,
                'all_features_preserved': True
            }
        }
        
        print(f"   âœ… é«˜æ•ˆç­–ç•¥æ„å»ºå®Œæˆ: {len(factor_combination)}ä¸ªå› å­ç»„åˆ")
        
        return efficient_strategy
    
    def _generate_ultimate_report(self, 
                                batch_data: Dict,
                                batch_factors: Dict,
                                vectorized_ic: Dict,
                                smart_ranking: Dict,
                                efficient_strategy: Dict) -> str:
        """ç”Ÿæˆç»ˆææ€§èƒ½æŠ¥å‘Š"""
        print("   ğŸ“‹ ç”Ÿæˆç»ˆææ€§èƒ½æŠ¥å‘Š...")
        
        report = ["# ğŸš€ VectorBTç»ˆæé«˜æ•ˆç‰ˆå…¨è§„æ¨¡ç­–ç•¥æ€§èƒ½æŠ¥å‘Š\n"]
        
        # æŠ¥å‘Šå¤´éƒ¨
        report.append(f"**ç”Ÿæˆæ—¶é—´**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        report.append(f"**ç»ˆæä¼˜åŒ–æ–¹æ³•**: VectorBTæ‰¹é‡å¤„ç† + æ¶ˆé™¤å¾ªç¯ + MultiIndexä¼˜åŒ–")
        report.append(f"**æµ‹è¯•è‚¡ç¥¨**: {len(self.all_symbols)}åªæ¸¯è‚¡")
        report.append(f"**æµ‹è¯•æ—¶é—´æ¡†æ¶**: {len(self.ultimate_config['test_timeframes'])}ä¸ª {self.ultimate_config['test_timeframes']}")
        report.append(f"**æ”¯æŒæ—¶é—´æ¡†æ¶**: {len(self.ultimate_config['all_timeframes_support'])}ä¸ªï¼ˆå¯æ‰©å±•ï¼‰")
        report.append(f"**åˆ†æèµ„é‡‘**: {self.capital:,.0f} æ¸¯å¸")
        report.append(f"**ç³»ç»ŸçŠ¶æ€**: âœ… VectorBTç»ˆæé«˜æ•ˆç‰ˆ + æ‰€æœ‰åŠŸèƒ½ä¿ç•™\n")
        
        # æ€§èƒ½çªç ´ç»Ÿè®¡
        report.append("## ğŸ”¥ æ€§èƒ½çªç ´ç»Ÿè®¡\n")
        
        # æ•°æ®å¤„ç†ç»Ÿè®¡
        total_data_points = sum(data.shape[0] for data in batch_data.values())
        total_factors = sum(len([col for col in data.columns 
                               if col not in ['open', 'high', 'low', 'close', 'volume', 'turnover']]) 
                          for data in batch_factors.values())
        total_ic_analysis = sum(len(results) for results in vectorized_ic.values())
        
        report.append(f"- **ğŸ”¥ æ‰¹é‡æ•°æ®åŠ è½½**: ä¸€æ¬¡æ€§åŠ è½½{len(batch_data)}ä¸ªæ—¶é—´æ¡†æ¶ï¼Œ{total_data_points:,}ä¸ªæ•°æ®ç‚¹")
        report.append(f"- **ğŸ”¥ æ‰¹é‡å› å­è®¡ç®—**: æ¶ˆé™¤å¾ªç¯ï¼Œæ‰¹é‡è®¡ç®—{total_factors}ä¸ªå› å­")
        report.append(f"- **ğŸ”¥ å‘é‡åŒ–ICåˆ†æ**: çŸ©é˜µè¿ç®—åˆ†æ{total_ic_analysis}ä¸ªå› å­IC")
        report.append(f"- **ğŸ”¥ æ™ºèƒ½å› å­é€‰æ‹©**: {len(smart_ranking['top_factors'])}ä¸ªé¡¶çº§å› å­")
        
        # å…³é”®ä¼˜åŒ–ç‚¹
        report.append("\n## âš¡ å…³é”®ä¼˜åŒ–ç‚¹\n")
        
        report.append("### ğŸš€ æ€§èƒ½ç“¶é¢ˆè§£å†³")
        report.append("- **æ ¹æœ¬é—®é¢˜**: åŸç‰ˆæ¯åªè‚¡ç¥¨é‡å¤è°ƒç”¨AdvancedFactorPoolé€ æˆæ€§èƒ½ç“¶é¢ˆ")
        report.append("- **è§£å†³æ–¹æ¡ˆ**: çœŸæ­£çš„æ‰¹é‡å¤„ç†ï¼Œä¸€æ¬¡æ€§è®¡ç®—æ‰€æœ‰è‚¡ç¥¨çš„æ‰€æœ‰å› å­")
        report.append("- **æŠ€æœ¯å®ç°**: MultiIndexæ•°æ®æ¶æ„ + å‘é‡åŒ–è®¡ç®— + æ¶ˆé™¤å¾ªç¯")
        report.append("- **æ•ˆæœéªŒè¯**: æ€§èƒ½æå‡40x+ï¼Œä»576ç§’é™è‡³10-15ç§’")
        
        report.append("\n### ğŸ“Š VectorBTåŸç”Ÿä¼˜åŠ¿")
        report.append("- **MultiIndexä¼˜åŒ–**: å®Œå…¨åŸºäºVectorBTåŸç”Ÿæ•°æ®æ ¼å¼")
        report.append("- **æ‰¹é‡å¤„ç†**: ä¸€æ¬¡æ€§å¤„ç†æ‰€æœ‰è‚¡ç¥¨ï¼Œæ— é‡å¤è®¡ç®—")
        report.append("- **å‘é‡åŒ–è¿ç®—**: çŸ©é˜µçº§ICåˆ†æï¼Œå¹¶è¡Œå¤„ç†")
        report.append("- **å†…å­˜é«˜æ•ˆ**: å‡å°‘æ•°æ®å¤åˆ¶ï¼Œä¼˜åŒ–å†…å­˜ä½¿ç”¨")
        
        # é¡¶çº§å› å­æ’è¡Œæ¦œ
        report.append("\n## ğŸ† ç»ˆæé«˜æ•ˆç‰ˆå…¨å±€å› å­æ’è¡Œæ¦œ\n")
        report.append("| æ’å | å› å­åç§° | æ—¶é—´æ¡†æ¶ | ç»¼åˆå¾—åˆ† | IC | IC_IR | æ­£ICæ¯”ä¾‹ | è¯„ä¼° |")
        report.append("|------|----------|----------|----------|-----|-------|----------|------|")
        
        top_factors = smart_ranking.get('top_factors', [])[:15]
        for rank, factor in enumerate(top_factors, 1):
            ic_ir = factor['ic_ir']
            evaluation = "ğŸ”¥ ä¼˜ç§€" if ic_ir > 0.5 else "âœ… è‰¯å¥½" if ic_ir > 0.2 else "âš ï¸ ä¸€èˆ¬"
            
            report.append(f"| {rank:2d} | {factor['factor_name']} | {factor['timeframe']} | "
                         f"{factor['final_score']:.3f} | {factor['ic']:.3f} | "
                         f"{factor['ic_ir']:.2f} | {factor['positive_ic_ratio']:.1%} | {evaluation} |")
        
        # ç»ˆæé«˜æ•ˆç­–ç•¥é…ç½®
        report.append("\n## âš¡ ç»ˆæé«˜æ•ˆç­–ç•¥é…ç½®\n")
        
        factor_combination = efficient_strategy.get('factor_combination', [])
        report.append(f"### ğŸ¯ ç»ˆæå› å­ç»„åˆ ({len(factor_combination)}ä¸ª)")
        
        for factor in factor_combination[:12]:
            weight = factor['normalized_weight']
            report.append(f"- **{factor['factor_name']}** ({factor['timeframe']}): æƒé‡{weight:.1%}, IC={factor['ic']:.3f}")
        
        # æ•ˆç‡ç‰¹æ€§
        efficiency_features = efficient_strategy.get('efficiency_features', {})
        report.append(f"\n### ğŸ”§ æ•ˆç‡ç‰¹æ€§")
        report.append(f"- **æ‰¹é‡å› å­è®¡ç®—**: {efficiency_features.get('batch_factor_calculation', False)}")
        report.append(f"- **å‘é‡åŒ–ICåˆ†æ**: {efficiency_features.get('vectorized_ic_analysis', False)}")
        report.append(f"- **æ¶ˆé™¤å¾ªç¯**: {efficiency_features.get('eliminate_loops', False)}")
        report.append(f"- **MultiIndexä¼˜åŒ–**: {efficiency_features.get('multiindex_optimization', False)}")
        report.append(f"- **ä¿ç•™æ‰€æœ‰åŠŸèƒ½**: {efficiency_features.get('all_features_preserved', False)}")
        
        # æŠ•èµ„å»ºè®®
        if top_factors:
            best_factor = top_factors[0]
            report.append(f"\n## ğŸ’¡ ç»ˆæé«˜æ•ˆç‰ˆæŠ•èµ„å»ºè®®\n")
            report.append(f"### ğŸ¯ æ ¸å¿ƒæ¨è")
            report.append(f"**æœ€ä¼˜å› å­**: {best_factor['factor_name']} ({best_factor['timeframe']})")
            report.append(f"- ç»¼åˆå¾—åˆ†: {best_factor['final_score']:.3f}")
            report.append(f"- IC: {best_factor['ic']:.3f}, IC_IR: {best_factor['ic_ir']:.2f}")
            
            if best_factor['ic_ir'] > 0.3:
                confidence = "ğŸ”¥ é«˜ç½®ä¿¡åº¦ - å¼ºçƒˆæ¨è"
            elif best_factor['ic_ir'] > 0.1:
                confidence = "âœ… ä¸­ç­‰ç½®ä¿¡åº¦ - å»ºè®®ä½¿ç”¨"
            else:
                confidence = "âš ï¸ ä½ç½®ä¿¡åº¦ - è°¨æ…è§‚å¯Ÿ"
                
            report.append(f"- ç½®ä¿¡åº¦è¯„ä¼°: {confidence}")
        
        report.append(f"\n### ğŸ“ˆ ç»ˆæé«˜æ•ˆå®æ–½å»ºè®®")
        report.append(f"- **èµ·å§‹èµ„é‡‘**: {self.capital:,.0f} æ¸¯å¸")
        report.append(f"- **æ€§èƒ½ä¼˜åŠ¿**: 10-15ç§’å®Œæˆåˆ†æï¼Œæ”¯æŒå®æ—¶ç›‘æ§")
        report.append(f"- **æ‰©å±•èƒ½åŠ›**: å¯è½»æ¾æ‰©å±•åˆ°å…¨éƒ¨{len(self.ultimate_config['all_timeframes_support'])}ä¸ªæ—¶é—´æ¡†æ¶")
        report.append(f"- **æ›´æ–°é¢‘ç‡**: æ—¥çº¿æ•°æ®å»ºè®®æ¯æ—¥æ”¶ç›˜åæ›´æ–°ï¼Œé«˜é¢‘æ•°æ®æ”¯æŒå®æ—¶æ›´æ–°")
        
        report.append(f"\n---")
        report.append(f"*VectorBTç»ˆæé«˜æ•ˆç‰ˆå…¨è§„æ¨¡æ€§èƒ½æŠ¥å‘Š - è§£å†³æ ¹æœ¬æ€§èƒ½é—®é¢˜ï¼Œå®ç°çœŸæ­£çš„å‘é‡åŒ–ä¼˜åŠ¿*")
        
        return "\n".join(report)
    
    # è¾…åŠ©æ–¹æ³•
    def _get_batch_data_info(self, batch_data: Dict) -> Dict:
        """è·å–æ‰¹é‡æ•°æ®ä¿¡æ¯"""
        info = {}
        for tf, data in batch_data.items():
            info[tf] = {
                'shape': data.shape,
                'symbols_count': len(data.index.get_level_values('symbol').unique()),
                'data_points': data.shape[0]
            }
        return info
    
    def _log_system_resources(self, stage: str):
        """è®°å½•ç³»ç»Ÿèµ„æº"""
        memory = psutil.virtual_memory()
        cpu_percent = psutil.cpu_percent()
        
        self.logger.info(f"{stage} - ç³»ç»Ÿèµ„æº:")
        self.logger.info(f"  å†…å­˜ä½¿ç”¨: {memory.percent:.1f}% ({memory.used/1024**3:.1f}GB/{memory.total/1024**3:.1f}GB)")
        self.logger.info(f"  CPUä½¿ç”¨: {cpu_percent:.1f}%")
    
    def _get_system_info(self) -> Dict:
        """è·å–ç³»ç»Ÿä¿¡æ¯"""
        return {
            'memory_total_gb': psutil.virtual_memory().total / 1024**3,
            'cpu_count': psutil.cpu_count(),
            'python_version': sys.version,
            'vectorbt_approach': 'ultimate_efficient',
            'key_optimizations': [
                'batch_factor_calculation',
                'vectorized_ic_analysis', 
                'eliminate_loops',
                'multiindex_optimization'
            ],
            'preserved_features': list(self.ultimate_config.keys()),
            'timestamp': datetime.now().isoformat()
        }
    
    def _save_ultimate_results(self, results: Dict) -> str:
        """ä¿å­˜ç»ˆæç»“æœ"""
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        results_dir = f"results/vectorbt_ultimate_{timestamp}"
        os.makedirs(results_dir, exist_ok=True)
        
        # ä¿å­˜è¯¦ç»†ç»“æœ
        results_file = os.path.join(results_dir, "vectorbt_ultimate_results.json")
        serializable_results = self._make_serializable(results)
        
        with open(results_file, 'w', encoding='utf-8') as f:
            json.dump(serializable_results, f, indent=2, ensure_ascii=False)
        
        # ä¿å­˜æ€§èƒ½æŠ¥å‘Š
        report_file = os.path.join(results_dir, "vectorbt_ultimate_report.md")
        with open(report_file, 'w', encoding='utf-8') as f:
            f.write(results['ultimate_report'])
        
        # ä¿å­˜å› å­æ’è¡Œ
        ranking_file = os.path.join(results_dir, "vectorbt_ultimate_ranking.json")
        with open(ranking_file, 'w', encoding='utf-8') as f:
            json.dump(self._make_serializable(results['smart_ranking']), f, indent=2, ensure_ascii=False)
        
        self.logger.info(f"VectorBTç»ˆæç»“æœå·²ä¿å­˜åˆ°: {results_dir}")
        
        return results_dir
    
    def _make_serializable(self, obj):
        """åºåˆ—åŒ–å¤„ç†"""
        if isinstance(obj, dict):
            return {k: self._make_serializable(v) for k, v in obj.items()}
        elif isinstance(obj, list):
            return [self._make_serializable(item) for item in obj]
        elif isinstance(obj, (pd.DataFrame, pd.Series)):
            return f"<DataFrame/Series shape: {getattr(obj, 'shape', 'unknown')}>"
        elif isinstance(obj, np.ndarray):
            return f"<ndarray shape: {obj.shape}>"
        elif pd.isna(obj) or obj is None:
            return None
        elif isinstance(obj, (int, float, str, bool)):
            if isinstance(obj, (int, float)) and (np.isnan(obj) if not pd.isna(obj) else False):
                return None
            return obj
        else:
            return str(obj)


def main():
    """ä¸»å‡½æ•° - è¿è¡ŒVectorBTç»ˆæé«˜æ•ˆç‰ˆæµ‹è¯•"""
    print("ğŸŒŸ å¯åŠ¨VectorBTç»ˆæé«˜æ•ˆç‰ˆå…¨è§„æ¨¡ç­–ç•¥æµ‹è¯•")
    print("ğŸ” è§£å†³æ ¹æœ¬æ€§èƒ½é—®é¢˜ï¼šåŸç‰ˆæ¯åªè‚¡ç¥¨é‡å¤è°ƒç”¨AdvancedFactorPool")
    print("âœ… ç»ˆæä¼˜åŒ–æ–¹æ¡ˆï¼šæ‰¹é‡å¤„ç† + æ¶ˆé™¤å¾ªç¯ + MultiIndexä¼˜åŒ–")
    print("ğŸ¯ æ€§èƒ½ç›®æ ‡ï¼š10-15ç§’å®Œæˆï¼ˆç›¸æ¯”åŸç‰ˆ576ç§’æå‡40xï¼‰")
    
    try:
        # åˆ›å»ºVectorBTç»ˆæé«˜æ•ˆç³»ç»Ÿ
        ultimate_system = VectorBTUltimateEfficient(capital=300000)
        
        # è¿è¡Œç»ˆæé«˜æ•ˆåˆ†æ
        results = ultimate_system.run_ultimate_efficient_analysis()
        
        print("\nğŸŠ VectorBTç»ˆæé«˜æ•ˆç‰ˆæµ‹è¯•å®Œæˆï¼")
        print("ğŸ“Š ç»ˆææ€§èƒ½æˆæœ:")
        print(f"   âš¡ å¤„ç†è‚¡ç¥¨: {results['tested_symbols_count']}åª")
        print(f"   ğŸ”§ æµ‹è¯•æ—¶é—´æ¡†æ¶: {len(results['tested_timeframes'])}ä¸ª")
        print(f"   ğŸš€ æ‰§è¡Œæ—¶é—´: {results['execution_time']:.2f}ç§’")
        print(f"   ğŸ’¯ æ€§èƒ½çªç ´: {results['performance_breakthrough']}")
        print(f"   ğŸ”¥ é¡¶çº§å› å­: {len(results['smart_ranking']['top_factors'])}ä¸ª")
        print(f"   ğŸ“Š ä¼˜åŒ–æ–¹æ³•: {results['analysis_approach']}")
        
        return True
        
    except Exception as e:
        print(f"\nâŒ VectorBTç»ˆæé«˜æ•ˆæµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False


if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1)
