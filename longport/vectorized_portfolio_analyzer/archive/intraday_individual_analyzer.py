#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ—¥å†…äº¤æ˜“ä¸“ç”¨ - ä¸ªè‚¡ç‹¬ç«‹ICåˆ†æå™¨
é’ˆå¯¹30ä¸‡æ¸¯å¸èµ„é‡‘çš„æ—¥å†…äº¤æ˜“ä¼˜åŒ–è®¾è®¡
æ¯åªè‚¡ç¥¨ç‹¬ç«‹è®¡ç®—ICï¼Œä¸“æ³¨é«˜é¢‘æ—¶é—´æ¡†æ¶
"""

import os
import sys
import time
import json
import psutil
import numpy as np
import pandas as pd
import talib
from datetime import datetime, timedelta
from typing import List, Dict, Any, Optional, Tuple
import logging
import gc
from pathlib import Path

# æ·»åŠ å½“å‰ç›®å½•åˆ°ç³»ç»Ÿè·¯å¾„
current_dir = os.path.dirname(os.path.abspath(__file__))
sys.path.insert(0, current_dir)

from vectorized_multi_stock_analyzer import VectorizedMultiStockAnalyzer


class IntradayIndividualAnalyzer(VectorizedMultiStockAnalyzer):
    """æ—¥å†…äº¤æ˜“ä¸“ç”¨ - ä¸ªè‚¡ç‹¬ç«‹åˆ†æå™¨"""
    
    def __init__(self, data_directory: str = None, capital: float = 300000):
        """
        åˆå§‹åŒ–æ—¥å†…äº¤æ˜“åˆ†æå™¨
        
        Args:
            data_directory: æ•°æ®ç›®å½•è·¯å¾„
            capital: äº¤æ˜“èµ„é‡‘ï¼ˆæ¸¯å¸ï¼‰
        """
        # ç»§æ‰¿åŸºç¡€åˆ†æå™¨
        if data_directory is None:
            data_directory = "/Users/zhangshenshen/longport/vectorbt_workspace/data"
        super().__init__(data_directory)
        
        # æ—¥å†…äº¤æ˜“ä¸“ç”¨é…ç½®
        self.capital = capital  # 30ä¸‡æ¸¯å¸
        self.intraday_timeframes = ['1m', '2m', '3m', '5m', '10m', '15m', '30m']  # é‡ç‚¹å…³æ³¨é«˜é¢‘æ¡†æ¶
        self.intraday_factors = ['RSI', 'MACD', 'Momentum_ROC']  # é€‚åˆæ—¥å†…çš„å› å­
        
        # ä»“ä½ç®¡ç†å‚æ•°
        self.max_position_per_stock = 0.1  # å•è‚¡æœ€å¤§ä»“ä½10%
        self.max_total_positions = 5  # æœ€å¤šæŒä»“5åªè‚¡ç¥¨
        self.min_trade_amount = 5000  # æœ€å°äº¤æ˜“é‡‘é¢5000æ¸¯å¸
        
        # æ—¥å†…äº¤æ˜“æ—¶é—´çª—å£ï¼ˆæ¸¯è‚¡äº¤æ˜“æ—¶é—´ï¼‰
        self.trading_sessions = {
            'morning': ('09:30', '12:00'),  # æ—©å¸‚
            'afternoon': ('13:00', '16:00')  # åˆå¸‚
        }
        
        self.logger.info(f"æ—¥å†…äº¤æ˜“åˆ†æå™¨åˆå§‹åŒ–å®Œæˆ:")
        self.logger.info(f"  èµ„é‡‘è§„æ¨¡: {self.capital:,.0f} æ¸¯å¸")
        self.logger.info(f"  å…³æ³¨æ—¶é—´æ¡†æ¶: {self.intraday_timeframes}")
        self.logger.info(f"  å•è‚¡æœ€å¤§ä»“ä½: {self.max_position_per_stock:.1%}")
        self.logger.info(f"  æœ€å¤šæŒä»“æ•°: {self.max_total_positions}åª")
    
    def calculate_individual_ic(self, 
                              data: pd.DataFrame, 
                              factors_dict: Dict[str, pd.Series]) -> Dict[str, Dict[str, float]]:
        """
        æ ¸å¿ƒæ”¹è¿›ï¼šæ¯åªè‚¡ç¥¨ç‹¬ç«‹è®¡ç®—IC
        """
        self.logger.info("å¼€å§‹ä¸ªè‚¡ç‹¬ç«‹ICè®¡ç®—")
        
        ic_results = {}
        
        # è·å–æ‰€æœ‰è‚¡ç¥¨åˆ—è¡¨
        symbols = data.index.get_level_values('symbol').unique()
        
        # å¯¹æ¯ä¸ªå› å­åˆ†åˆ«å¤„ç†
        for factor_name in factors_dict.keys():
            self.logger.info(f"  å¤„ç†å› å­: {factor_name}")
            
            individual_ics = []
            individual_stats = []
            
            # å¯¹æ¯åªè‚¡ç¥¨ç‹¬ç«‹è®¡ç®—IC
            for symbol in symbols:
                try:
                    # æå–å•åªè‚¡ç¥¨çš„æ•°æ®
                    symbol_data = data.loc[symbol]
                    symbol_factor = factors_dict[factor_name].loc[symbol]
                    
                    # è®¡ç®—æœªæ¥æ”¶ç›Šç‡
                    symbol_returns = symbol_data['close'].pct_change(periods=1).shift(-1)
                    
                    # ç¡®ä¿æ•°æ®å¯¹é½
                    common_index = symbol_factor.index.intersection(symbol_returns.index)
                    
                    if len(common_index) > 20:  # è‡³å°‘éœ€è¦20ä¸ªæ•°æ®ç‚¹
                        aligned_factor = symbol_factor.loc[common_index]
                        aligned_returns = symbol_returns.loc[common_index]
                        
                        # å»é™¤NaNå€¼
                        valid_mask = aligned_factor.notna() & aligned_returns.notna()
                        clean_factor = aligned_factor[valid_mask]
                        clean_returns = aligned_returns[valid_mask]
                        
                        if len(clean_factor) > 15:
                            # è®¡ç®—ä¸ªè‚¡IC
                            ic = clean_factor.corr(clean_returns)
                            
                            if not np.isnan(ic):
                                individual_ics.append(ic)
                                individual_stats.append({
                                    'symbol': symbol,
                                    'ic': ic,
                                    'sample_size': len(clean_factor),
                                    'factor_mean': float(clean_factor.mean()),
                                    'factor_std': float(clean_factor.std()),
                                    'returns_mean': float(clean_returns.mean()),
                                    'returns_std': float(clean_returns.std()),
                                    'abs_ic': abs(ic)  # ç»å¯¹ICå€¼ï¼Œç”¨äºæ’åº
                                })
                                
                                self.logger.debug(f"    {symbol}: IC={ic:.4f}, æ ·æœ¬={len(clean_factor)}")
                            else:
                                self.logger.warning(f"    {symbol}: ICè®¡ç®—ä¸ºNaN")
                        else:
                            self.logger.warning(f"    {symbol}: æœ‰æ•ˆæ•°æ®ä¸è¶³({len(clean_factor)})")
                    else:
                        self.logger.warning(f"    {symbol}: æ•°æ®ç‚¹ä¸è¶³({len(common_index)})")
                        
                except Exception as e:
                    self.logger.warning(f"    {symbol}: ICè®¡ç®—å¤±è´¥ - {e}")
            
            # æ±‡æ€»ç»Ÿè®¡
            if individual_ics:
                ic_results[factor_name] = {
                    'mean_ic': float(np.mean(individual_ics)),
                    'median_ic': float(np.median(individual_ics)),
                    'std_ic': float(np.std(individual_ics)),
                    'min_ic': float(np.min(individual_ics)),
                    'max_ic': float(np.max(individual_ics)),
                    'positive_ic_ratio': float(np.mean([ic > 0 for ic in individual_ics])),
                    'total_stocks': len(individual_ics),
                    'individual_stats': individual_stats,
                    'ic_ir': float(np.mean(individual_ics) / np.std(individual_ics)) if np.std(individual_ics) > 0 else 0.0
                }
                
                self.logger.info(f"  âœ… {factor_name}: å¹³å‡IC={np.mean(individual_ics):.4f}, "
                               f"æ­£ICæ¯”ä¾‹={np.mean([ic > 0 for ic in individual_ics]):.1%}, "
                               f"è¦†ç›–è‚¡ç¥¨={len(individual_ics)}åª")
            else:
                ic_results[factor_name] = {
                    'mean_ic': 0.0,
                    'total_stocks': 0,
                    'individual_stats': []
                }
                self.logger.warning(f"  âŒ {factor_name}: æ— æœ‰æ•ˆICè®¡ç®—ç»“æœ")
        
        return ic_results
    
    def calculate_intraday_factors(self, 
                                 data: pd.DataFrame, 
                                 factors: List[str] = None) -> Dict[str, pd.Series]:
        """
        ä¼˜åŒ–çš„æ—¥å†…å› å­è®¡ç®— - è€ƒè™‘æ¸¯è‚¡äº¤æ˜“ç‰¹æ€§
        """
        if factors is None:
            factors = self.intraday_factors
        
        self.logger.info(f"å¼€å§‹æ—¥å†…å› å­è®¡ç®—: {factors}")
        
        factors_dict = {}
        grouped = data.groupby('symbol')
        
        for factor_name in factors:
            self.logger.info(f"  è®¡ç®—å› å­: {factor_name}")
            
            factor_results = []
            
            for symbol, group_data in grouped:
                try:
                    # æ ¹æ®å› å­ç±»å‹è°ƒæ•´å‚æ•°
                    factor_values = self._calculate_intraday_factor(group_data, factor_name)
                    
                    if factor_values is not None and len(factor_values) > 0:
                        factor_series = pd.Series(
                            factor_values, 
                            index=group_data.index.get_level_values('timestamp'),
                            name=f"{symbol}_{factor_name}"
                        )
                        
                        factor_df = factor_series.to_frame(factor_name)
                        factor_df['symbol'] = symbol
                        factor_results.append(factor_df)
                        
                except Exception as e:
                    self.logger.warning(f"{symbol}è®¡ç®—{factor_name}å¤±è´¥: {e}")
            
            if factor_results:
                factor_combined = pd.concat(factor_results)
                factor_combined.reset_index(inplace=True)
                factor_combined.set_index(['symbol', 'timestamp'], inplace=True)
                factor_combined.sort_index(inplace=True)
                
                factors_dict[factor_name] = factor_combined[factor_name]
                
                self.logger.info(f"  âœ… {factor_name}è®¡ç®—å®Œæˆ: {len(factor_results)}åªè‚¡ç¥¨")
            else:
                self.logger.warning(f"  âŒ {factor_name}è®¡ç®—å¤±è´¥ï¼šæ— æœ‰æ•ˆæ•°æ®")
        
        return factors_dict
    
    def _calculate_intraday_factor(self, data: pd.DataFrame, factor_name: str) -> np.ndarray:
        """
        æ—¥å†…å› å­è®¡ç®— - é’ˆå¯¹é«˜é¢‘æ•°æ®ä¼˜åŒ–å‚æ•°
        """
        try:
            close = data['close'].values
            high = data['high'].values
            low = data['low'].values
            volume = data['volume'].values
            
            if factor_name == "RSI":
                # æ—¥å†…RSIä½¿ç”¨è¾ƒçŸ­å‘¨æœŸ
                return talib.RSI(close, timeperiod=9)
            
            elif factor_name == "MACD":
                # æ—¥å†…MACDä½¿ç”¨å¿«é€Ÿå‚æ•°
                macd, macd_signal, macd_hist = talib.MACD(close, fastperiod=5, slowperiod=13, signalperiod=4)
                return macd
            
            elif factor_name == "Momentum_ROC":
                # æ—¥å†…åŠ¨é‡ä½¿ç”¨çŸ­å‘¨æœŸ
                return talib.ROC(close, timeperiod=5)
            
            elif factor_name == "Price_Position":
                # æ—¥å†…ä»·æ ¼ä½ç½®
                period = 10  # ç¼©çŸ­å‘¨æœŸ
                rolling_high = pd.Series(high).rolling(period).max()
                rolling_low = pd.Series(low).rolling(period).min()
                price_position = (close - rolling_low) / (rolling_high - rolling_low)
                return price_position.values
            
            elif factor_name == "Volume_Ratio":
                # æ—¥å†…æˆäº¤é‡æ¯”ç‡
                period = 10  # ç¼©çŸ­å‘¨æœŸ
                avg_volume = pd.Series(volume).rolling(period).mean()
                volume_ratio = volume / avg_volume
                return volume_ratio.values
            
            elif factor_name == "Volatility":
                # æ—¥å†…æ³¢åŠ¨ç‡
                period = 10  # ç¼©çŸ­å‘¨æœŸ
                returns = pd.Series(close).pct_change()
                volatility = returns.rolling(period).std()
                return volatility.values
            
            else:
                self.logger.warning(f"æœªçŸ¥æ—¥å†…å› å­: {factor_name}")
                return None
                
        except Exception as e:
            self.logger.error(f"è®¡ç®—æ—¥å†…å› å­{factor_name}å¤±è´¥: {e}")
            return None
    
    def calculate_position_sizing(self, ic_results: Dict[str, Dict]) -> Dict[str, float]:
        """
        åŸºäºICç»“æœè®¡ç®—ä»“ä½é…ç½®
        
        Returns:
            Dict[symbol, position_weight]: è‚¡ç¥¨ä»£ç åˆ°ä»“ä½æƒé‡çš„æ˜ å°„
        """
        self.logger.info("å¼€å§‹è®¡ç®—ä»“ä½é…ç½®")
        
        # æ”¶é›†æ‰€æœ‰è‚¡ç¥¨çš„ç»¼åˆè¯„åˆ†
        stock_scores = {}
        
        for factor_name, factor_results in ic_results.items():
            if 'individual_stats' in factor_results:
                for stock_stat in factor_results['individual_stats']:
                    symbol = stock_stat['symbol']
                    abs_ic = stock_stat['abs_ic']
                    sample_size = stock_stat['sample_size']
                    
                    # è®¡ç®—æƒé‡è¯„åˆ†ï¼šç»å¯¹ICå€¼ * æ ·æœ¬æ•°æƒé‡
                    score = abs_ic * min(sample_size / 100, 1.0)  # æ ·æœ¬æ•°å½’ä¸€åŒ–
                    
                    if symbol not in stock_scores:
                        stock_scores[symbol] = []
                    stock_scores[symbol].append(score)
        
        # è®¡ç®—æ¯åªè‚¡ç¥¨çš„å¹³å‡è¯„åˆ†
        final_scores = {}
        for symbol, scores in stock_scores.items():
            final_scores[symbol] = np.mean(scores)
        
        # é€‰æ‹©topè‚¡ç¥¨å¹¶åˆ†é…ä»“ä½
        sorted_stocks = sorted(final_scores.items(), key=lambda x: x[1], reverse=True)
        selected_stocks = sorted_stocks[:self.max_total_positions]
        
        if not selected_stocks:
            self.logger.warning("æ²¡æœ‰æ‰¾åˆ°åˆé€‚çš„è‚¡ç¥¨")
            return {}
        
        # è®¡ç®—ä»“ä½æƒé‡
        total_score = sum(score for _, score in selected_stocks)
        position_weights = {}
        
        for symbol, score in selected_stocks:
            # åŸºç¡€æƒé‡ + æœ€å°/æœ€å¤§ä»“ä½é™åˆ¶
            base_weight = score / total_score
            adjusted_weight = min(base_weight, self.max_position_per_stock)
            adjusted_weight = max(adjusted_weight, self.min_trade_amount / self.capital)
            
            position_weights[symbol] = adjusted_weight
        
        # å½’ä¸€åŒ–æƒé‡
        total_weight = sum(position_weights.values())
        if total_weight > 0:
            position_weights = {k: v/total_weight for k, v in position_weights.items()}
        
        self.logger.info(f"ä»“ä½é…ç½®å®Œæˆ:")
        for symbol, weight in position_weights.items():
            amount = weight * self.capital
            self.logger.info(f"  {symbol}: {weight:.1%} (çº¦{amount:,.0f}æ¸¯å¸)")
        
        return position_weights
    
    def run_intraday_analysis(self, 
                            symbols: List[str] = None, 
                            timeframes: List[str] = None) -> Dict:
        """
        è¿è¡Œæ—¥å†…äº¤æ˜“åˆ†æ - ä¸ªè‚¡ç‹¬ç«‹ICè®¡ç®—
        """
        if symbols is None:
            symbols = self.all_symbols[:10]  # æµ‹è¯•å‰10åªè‚¡ç¥¨
        if timeframes is None:
            timeframes = self.intraday_timeframes[:4]  # æµ‹è¯•å‰4ä¸ªé«˜é¢‘æ¡†æ¶
        
        self.logger.info(f"ğŸš€ å¼€å§‹æ—¥å†…äº¤æ˜“åˆ†æ:")
        self.logger.info(f"  åˆ†æè‚¡ç¥¨: {len(symbols)}åª")
        self.logger.info(f"  æ—¶é—´æ¡†æ¶: {timeframes}")
        self.logger.info(f"  ç›®æ ‡å› å­: {self.intraday_factors}")
        
        start_time = time.time()
        results = {
            'metadata': {
                'analysis_type': 'intraday_individual',
                'capital': self.capital,
                'symbols': symbols,
                'timeframes': timeframes,
                'factors': self.intraday_factors,
                'start_time': datetime.now().isoformat()
            },
            'timeframe_results': {},
            'position_recommendations': {}
        }
        
        # åˆ†ææ¯ä¸ªæ—¶é—´æ¡†æ¶
        for timeframe in timeframes:
            self.logger.info(f"\nğŸ“ˆ åˆ†ææ—¶é—´æ¡†æ¶: {timeframe}")
            
            try:
                # 1. åŠ è½½æ•°æ®
                data = self.load_timeframe_data_vectorized(timeframe, symbols)
                
                # 2. è®¡ç®—æ—¥å†…å› å­
                factors_dict = self.calculate_intraday_factors(data, self.intraday_factors)
                
                # 3. è®¡ç®—ä¸ªè‚¡ç‹¬ç«‹IC
                ic_results = self.calculate_individual_ic(data, factors_dict)
                
                # 4. è®¡ç®—ä»“ä½å»ºè®®
                position_weights = self.calculate_position_sizing(ic_results)
                
                # 5. å­˜å‚¨ç»“æœ
                results['timeframe_results'][timeframe] = {
                    'data_shape': data.shape,
                    'symbols_analyzed': len(data.index.get_level_values('symbol').unique()),
                    'factors_calculated': list(factors_dict.keys()),
                    'ic_results': ic_results,
                    'analysis_status': 'success'
                }
                
                results['position_recommendations'][timeframe] = position_weights
                
                self.logger.info(f"âœ… {timeframe}åˆ†æå®Œæˆ")
                
            except Exception as e:
                error_msg = f"{timeframe}åˆ†æå¤±è´¥: {str(e)}"
                self.logger.error(error_msg)
                
                results['timeframe_results'][timeframe] = {
                    'analysis_status': 'failed',
                    'error': str(e)
                }
        
        # è®¡ç®—æ€»ä½“ç»Ÿè®¡
        execution_time = time.time() - start_time
        results['metadata']['end_time'] = datetime.now().isoformat()
        results['metadata']['execution_time'] = execution_time
        
        self.logger.info(f"\nğŸ‰ æ—¥å†…åˆ†æå®Œæˆ! æ€»è€—æ—¶: {execution_time:.2f}ç§’")
        
        return results
    
    def save_intraday_results(self, results: Dict, output_dir: str = None) -> str:
        """ä¿å­˜æ—¥å†…äº¤æ˜“åˆ†æç»“æœ"""
        if output_dir is None:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            output_dir = f"results/intraday_analysis_{timestamp}"
        
        os.makedirs(output_dir, exist_ok=True)
        
        # ä¿å­˜è¯¦ç»†ç»“æœ
        results_file = os.path.join(output_dir, "intraday_analysis_results.json")
        with open(results_file, 'w', encoding='utf-8') as f:
            json.dump(results, f, indent=2, ensure_ascii=False)
        
        # ç”Ÿæˆä»“ä½å»ºè®®æŠ¥å‘Š
        self._generate_position_report(results, output_dir)
        
        # ç”Ÿæˆå› å­è¡¨ç°æŠ¥å‘Š
        self._generate_factor_report(results, output_dir)
        
        self.logger.info(f"æ—¥å†…åˆ†æç»“æœå·²ä¿å­˜åˆ°: {output_dir}")
        return output_dir
    
    def _generate_position_report(self, results: Dict, output_dir: str):
        """ç”Ÿæˆä»“ä½å»ºè®®æŠ¥å‘Š"""
        report_file = os.path.join(output_dir, "position_recommendations.md")
        
        with open(report_file, 'w', encoding='utf-8') as f:
            f.write(f"# æ—¥å†…äº¤æ˜“ä»“ä½å»ºè®®æŠ¥å‘Š\n\n")
            f.write(f"**åˆ†ææ—¶é—´**: {results['metadata']['start_time']}\n")
            f.write(f"**èµ„é‡‘è§„æ¨¡**: {results['metadata']['capital']:,.0f} æ¸¯å¸\n")
            f.write(f"**åˆ†æè‚¡ç¥¨**: {len(results['metadata']['symbols'])}åª\n\n")
            
            f.write("## å„æ—¶é—´æ¡†æ¶ä»“ä½å»ºè®®\n\n")
            
            for timeframe, positions in results.get('position_recommendations', {}).items():
                f.write(f"### {timeframe} æ—¶é—´æ¡†æ¶\n\n")
                
                if positions:
                    f.write("| è‚¡ç¥¨ä»£ç  | å»ºè®®ä»“ä½ | èµ„é‡‘åˆ†é… |\n")
                    f.write("|---------|---------|----------|\n")
                    
                    for symbol, weight in positions.items():
                        amount = weight * results['metadata']['capital']
                        f.write(f"| {symbol} | {weight:.1%} | {amount:,.0f} æ¸¯å¸ |\n")
                    
                    f.write(f"\n**æ€»ä»“ä½ä½¿ç”¨**: {sum(positions.values()):.1%}\n")
                    f.write(f"**å‰©ä½™ç°é‡‘**: {(1-sum(positions.values()))*results['metadata']['capital']:,.0f} æ¸¯å¸\n\n")
                else:
                    f.write("æš‚æ— ä»“ä½å»ºè®®\n\n")
    
    def _generate_factor_report(self, results: Dict, output_dir: str):
        """ç”Ÿæˆå› å­è¡¨ç°æŠ¥å‘Š"""
        report_file = os.path.join(output_dir, "factor_performance.md")
        
        with open(report_file, 'w', encoding='utf-8') as f:
            f.write(f"# æ—¥å†…å› å­è¡¨ç°æŠ¥å‘Š\n\n")
            f.write(f"**åˆ†ææ—¶é—´**: {results['metadata']['start_time']}\n")
            f.write(f"**åˆ†æå› å­**: {', '.join(results['metadata']['factors'])}\n\n")
            
            for timeframe, timeframe_results in results.get('timeframe_results', {}).items():
                f.write(f"## {timeframe} æ—¶é—´æ¡†æ¶å› å­è¡¨ç°\n\n")
                
                ic_results = timeframe_results.get('ic_results', {})
                
                if ic_results:
                    f.write("| å› å­ | å¹³å‡IC | ICæ ‡å‡†å·® | IC_IR | æ­£ICæ¯”ä¾‹ | è¦†ç›–è‚¡ç¥¨ |\n")
                    f.write("|-----|--------|---------|-------|----------|----------|\n")
                    
                    for factor_name, factor_stats in ic_results.items():
                        mean_ic = factor_stats.get('mean_ic', 0)
                        std_ic = factor_stats.get('std_ic', 0)
                        ic_ir = factor_stats.get('ic_ir', 0)
                        pos_ratio = factor_stats.get('positive_ic_ratio', 0)
                        total_stocks = factor_stats.get('total_stocks', 0)
                        
                        f.write(f"| {factor_name} | {mean_ic:.4f} | {std_ic:.4f} | {ic_ir:.2f} | {pos_ratio:.1%} | {total_stocks} |\n")
                    
                    f.write("\n")
                else:
                    f.write("æ— å› å­è¡¨ç°æ•°æ®\n\n")


if __name__ == "__main__":
    # åˆ›å»ºæ—¥å†…äº¤æ˜“åˆ†æå™¨
    analyzer = IntradayIndividualAnalyzer()
    
    # è¿è¡Œæ—¥å†…åˆ†ææµ‹è¯•
    print("ğŸš€ å¼€å§‹æ—¥å†…äº¤æ˜“åˆ†ææµ‹è¯•...")
    
    # æµ‹è¯•å‚æ•°
    test_symbols = ['0700.HK', '0005.HK', '0388.HK', '0981.HK', '1211.HK']  # 5åªæ´»è·ƒè‚¡ç¥¨
    test_timeframes = ['1m', '5m', '15m']  # 3ä¸ªé«˜é¢‘æ—¶é—´æ¡†æ¶
    
    # è¿è¡Œåˆ†æ
    results = analyzer.run_intraday_analysis(
        symbols=test_symbols,
        timeframes=test_timeframes
    )
    
    # ä¿å­˜ç»“æœ
    output_dir = analyzer.save_intraday_results(results)
    
    print(f"âœ… æ—¥å†…äº¤æ˜“åˆ†æå®Œæˆ! ç»“æœä¿å­˜åœ¨: {output_dir}")
