#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
VectorBTåŸç”Ÿå…¨è§„æ¨¡ç­–ç•¥æµ‹è¯• - å®Œå…¨æ”¹é€ ç‰ˆ
åŸºäºVectorBTæ ¸å¿ƒä¼˜åŠ¿ï¼Œä¿ç•™æ‰€æœ‰å› å­å’Œæ—¶é—´æ¡†æ¶ï¼Œå®ç°çœŸæ­£çš„å‘é‡åŒ–å¤„ç†
"""

import sys
import os
import time
import json
import numpy as np
import pandas as pd
import vectorbt as vbt
from datetime import datetime
from typing import Dict, List, Optional, Tuple
import warnings
import psutil
import gc
warnings.filterwarnings('ignore')

# æ·»åŠ å½“å‰ç›®å½•åˆ°ç³»ç»Ÿè·¯å¾„
current_dir = os.path.dirname(os.path.abspath(__file__))
sys.path.insert(0, current_dir)

from vectorized_multi_stock_analyzer import VectorizedMultiStockAnalyzer
from advanced_factor_pool import AdvancedFactorPool
from factor_engineering import FactorEngineer
from advanced_ic_analysis import AdvancedICAnalyzer
from critical_fixes import CriticalFixes
from categorical_dtype_fix import CategoricalDtypeFixer

class VectorBTFullScaleReformed:
    """VectorBTåŸç”Ÿå…¨è§„æ¨¡ç­–ç•¥æµ‹è¯• - å®Œå…¨æ”¹é€ ç‰ˆ"""
    
    def __init__(self, capital: float = 300000):
        """åˆå§‹åŒ–VectorBTåŸç”Ÿå…¨è§„æ¨¡ç³»ç»Ÿ"""
        print("ğŸš€ å¯åŠ¨VectorBTåŸç”Ÿå…¨è§„æ¨¡ç­–ç•¥æµ‹è¯• - å®Œå…¨æ”¹é€ ç‰ˆ")
        print("ğŸ’¡ åŸºäºVectorBTæ ¸å¿ƒä¼˜åŠ¿ï¼Œä¿ç•™æ‰€æœ‰å› å­å’Œæ—¶é—´æ¡†æ¶")
        print("ğŸ¯ ç›®æ ‡ï¼šå®ç°çœŸæ­£çš„å‘é‡åŒ–å¤„ç†ï¼Œ10-30ç§’å®Œæˆå…¨éƒ¨åˆ†æ")
        print("=" * 80)
        
        # æ ¸å¿ƒç»„ä»¶ - ä¿ç•™æ‰€æœ‰åŸæœ‰åŠŸèƒ½
        self.data_analyzer = VectorizedMultiStockAnalyzer()
        self.factor_pool = AdvancedFactorPool()
        self.factor_engineer = FactorEngineer()
        self.ic_analyzer = AdvancedICAnalyzer()
        self.critical_fixer = CriticalFixes()
        self.categorical_fixer = CategoricalDtypeFixer()
        
        # é…ç½®å‚æ•°
        self.capital = capital
        self.max_positions = 10
        self.max_single_weight = 0.15
        
        # ğŸ”¥ VectorBTåŸç”Ÿé…ç½® - ä¿ç•™æ‰€æœ‰æ—¶é—´æ¡†æ¶å’Œå› å­
        self.vectorbt_config = {
            'all_timeframes': ['1m', '2m', '3m', '5m', '10m', '15m', '30m', '1h', '4h', '1d'],
            'test_timeframes': ['15m', '1h', '4h', '1d'],  # å…ˆç”¨æ ¸å¿ƒæ—¶é—´æ¡†æ¶æµ‹è¯•ï¼Œåç»­å¯æ‰©å±•
            'batch_processing': True,
            'vectorized_computation': True,
            'multiindex_data': True,
            'preserve_all_factors': True,  # ğŸ”¥ ä¿ç•™æ‰€æœ‰å› å­
            'parallel_processing': True,
            'memory_optimization': True,
            'categorical_fixing': True,  # ğŸ”¥ é›†æˆCategoricalä¿®å¤
            'transparent_scoring': True,
            'robust_signals': True
        }
        
        # VectorBTä¼˜åŒ–è®¾ç½®
        self._setup_vectorbt_settings()
        
        # æ—¥å¿—ç³»ç»Ÿ
        self.logger = self._setup_logger()
        
        # è·å–æ‰€æœ‰å¯ç”¨è‚¡ç¥¨
        self.all_symbols = self.data_analyzer.all_symbols
        
        print(f"âœ… VectorBTåŸç”Ÿç³»ç»Ÿåˆå§‹åŒ–å®Œæˆ")
        print(f"ğŸ“Š ç³»ç»Ÿé…ç½®:")
        print(f"   èµ„é‡‘è§„æ¨¡: {self.capital:,.0f} æ¸¯å¸") 
        print(f"   æœ€å¤§æŒä»“: {self.max_positions} åªè‚¡ç¥¨")
        print(f"   ğŸ”¥ å¯ç”¨è‚¡ç¥¨: {len(self.all_symbols)} åª")
        print(f"   ğŸ”¥ æµ‹è¯•æ—¶é—´æ¡†æ¶: {len(self.vectorbt_config['test_timeframes'])}ä¸ª {self.vectorbt_config['test_timeframes']}")
        print(f"   ğŸ”¥ VectorBTä¼˜åŒ–: å®Œå…¨å‘é‡åŒ– + MultiIndex + å¹¶è¡Œå¤„ç†")
        print(f"   ğŸ”¥ ä¿ç•™åŠŸèƒ½: æ‰€æœ‰å› å­ + Categoricalä¿®å¤ + é€æ˜è¯„åˆ†")
        print("=" * 80)
    
    def _setup_vectorbt_settings(self):
        """è®¾ç½®VectorBTå…¨å±€ä¼˜åŒ–é…ç½®"""
        try:
            # å¯ç”¨ç¼“å­˜å’Œå¹¶è¡Œå¤„ç†
            vbt.settings.caching['enabled'] = True
            vbt.settings.caching['compression'] = 'lz4'
        except:
            pass
        
        try:
            # è®¾ç½®æ•°ç»„åŒ…è£…å™¨
            vbt.settings.array_wrapper['freq'] = 'D'
        except:
            pass
    
    def _setup_logger(self):
        """è®¾ç½®æ—¥å¿—ç³»ç»Ÿ"""
        import logging
        
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        log_dir = f"logs/vectorbt_reformed_{timestamp}"
        os.makedirs(log_dir, exist_ok=True)
        
        logger = logging.getLogger(f"{__name__}.VectorBTReformed")
        logger.setLevel(logging.INFO)
        
        # æ–‡ä»¶å¤„ç†å™¨
        file_handler = logging.FileHandler(f"{log_dir}/vectorbt_reformed.log", encoding='utf-8')
        file_handler.setLevel(logging.INFO)
        
        # æ§åˆ¶å°å¤„ç†å™¨
        console_handler = logging.StreamHandler()
        console_handler.setLevel(logging.INFO)
        
        # æ ¼å¼å™¨
        formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')
        file_handler.setFormatter(formatter)
        console_handler.setFormatter(formatter)
        
        logger.addHandler(file_handler)
        logger.addHandler(console_handler)
        
        return logger
    
    def run_vectorbt_full_scale_analysis(self) -> Dict:
        """è¿è¡ŒVectorBTåŸç”Ÿå…¨è§„æ¨¡åˆ†æ"""
        print("ğŸ¯ å¼€å§‹VectorBTåŸç”Ÿå…¨è§„æ¨¡åˆ†æ...")
        print(f"ğŸ“Š å¤„ç†è‚¡ç¥¨: {len(self.all_symbols)}åª")
        print(f"ğŸ”§ æµ‹è¯•æ—¶é—´æ¡†æ¶: {self.vectorbt_config['test_timeframes']}")
        
        start_time = time.time()
        
        # ç³»ç»Ÿèµ„æºç›‘æ§
        self._log_system_resources("VectorBTæ”¹é€ æµ‹è¯•å¼€å§‹")
        
        try:
            # ğŸ”¥ é˜¶æ®µ1: VectorBTåŸç”Ÿå¤šæ—¶é—´æ¡†æ¶æ•°æ®åŠ è½½ï¼ˆå®Œå…¨å‘é‡åŒ–ï¼‰
            print("\nğŸ“Š é˜¶æ®µ1: VectorBTåŸç”Ÿå¤šæ—¶é—´æ¡†æ¶æ•°æ®åŠ è½½")
            multi_timeframe_data = self._load_multi_timeframe_data_vectorized()
            
            # ğŸ”¥ é˜¶æ®µ2: VectorBTåŸç”Ÿæ‰¹é‡å› å­è®¡ç®—ï¼ˆä¿ç•™æ‰€æœ‰å› å­ï¼‰
            print("\nğŸ”§ é˜¶æ®µ2: VectorBTåŸç”Ÿæ‰¹é‡å› å­è®¡ç®—")
            factor_results = self._calculate_all_factors_vectorized(multi_timeframe_data)
            
            # ğŸ”¥ é˜¶æ®µ3: VectorBTåŸç”Ÿè¶…é«˜é€ŸICåˆ†æï¼ˆçŸ©é˜µçº§è®¡ç®—ï¼‰
            print("\nğŸ“ˆ é˜¶æ®µ3: VectorBTåŸç”Ÿè¶…é«˜é€ŸICåˆ†æ")
            ic_analysis = self._analyze_ic_vectorized(factor_results)
            
            # ğŸ”¥ é˜¶æ®µ4: è·¨æ—¶é—´æ¡†æ¶å› å­æ•´åˆå’Œæ’åº
            print("\nğŸ† é˜¶æ®µ4: è·¨æ—¶é—´æ¡†æ¶å› å­æ•´åˆå’Œæ’åº")
            global_ranking = self._rank_factors_globally_vectorized(ic_analysis)
            
            # ğŸ”¥ é˜¶æ®µ5: æœ€ä¼˜ç­–ç•¥æ„å»º
            print("\nâš¡ é˜¶æ®µ5: æœ€ä¼˜ç­–ç•¥æ„å»º")
            optimal_strategy = self._build_optimal_strategy_vectorized(global_ranking)
            
            # ğŸ”¥ é˜¶æ®µ6: ç»¼åˆæ€§èƒ½è¯„ä¼°
            print("\nğŸ“‹ é˜¶æ®µ6: ç»¼åˆæ€§èƒ½è¯„ä¼°")
            performance_report = self._generate_vectorbt_performance_report(
                multi_timeframe_data, factor_results, ic_analysis, global_ranking, optimal_strategy
            )
            
            total_time = time.time() - start_time
            
            # æœ€ç»ˆç»“æœ
            final_results = {
                'execution_time': total_time,
                'analysis_approach': 'vectorbt_reformed_full_scale',
                'tested_symbols_count': len(self.all_symbols),
                'tested_timeframes': self.vectorbt_config['test_timeframes'],
                'multi_timeframe_data_info': self._get_data_info(multi_timeframe_data),
                'factor_results': factor_results,
                'ic_analysis': ic_analysis,
                'global_ranking': global_ranking,
                'optimal_strategy': optimal_strategy,
                'performance_report': performance_report,
                'vectorbt_config': self.vectorbt_config,
                'system_info': self._get_system_info(),
                'timestamp': datetime.now().isoformat()
            }
            
            # ä¿å­˜ç»“æœ
            results_dir = self._save_vectorbt_results(final_results)
            
            # æœ€ç»ˆæŠ¥å‘Š
            self._log_system_resources("VectorBTæ”¹é€ æµ‹è¯•å®Œæˆ")
            
            print(f"\nğŸ‰ VectorBTåŸç”Ÿå…¨è§„æ¨¡åˆ†æå®Œæˆ!")
            print(f"   âš¡ æ€»è€—æ—¶: {total_time:.2f}ç§’")
            print(f"   ğŸ“Š å¤„ç†è‚¡ç¥¨: {len(self.all_symbols)}åª")
            print(f"   ğŸ”§ æµ‹è¯•æ—¶é—´æ¡†æ¶: {len(self.vectorbt_config['test_timeframes'])}ä¸ª")
            print(f"   ğŸ”¥ é€Ÿåº¦æå‡: {576.9/total_time:.1f}x ç›¸æ¯”ä¼ ç»Ÿæ–¹æ³•")
            print(f"   ğŸ’¾ ç»“æœä¿å­˜: {results_dir}")
            
            return final_results
            
        except Exception as e:
            self.logger.error(f"VectorBTæ”¹é€ åˆ†æå¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            raise
    
    def _load_multi_timeframe_data_vectorized(self) -> Dict[str, pd.DataFrame]:
        """VectorBTåŸç”Ÿæ–¹å¼åŠ è½½å¤šæ—¶é—´æ¡†æ¶æ•°æ®"""
        print("   ğŸ”„ VectorBTåŸç”Ÿå¤šæ—¶é—´æ¡†æ¶æ•°æ®åŠ è½½...")
        
        multi_timeframe_data = {}
        
        for timeframe in self.vectorbt_config['test_timeframes']:
            print(f"     åŠ è½½æ—¶é—´æ¡†æ¶: {timeframe}")
            
            try:
                # ğŸ”¥ ä½¿ç”¨VectorBTä¼˜åŒ–çš„æ‰¹é‡åŠ è½½
                tf_data = self.data_analyzer.load_timeframe_data_vectorized(timeframe, self.all_symbols)
                
                if not tf_data.empty:
                    multi_timeframe_data[timeframe] = tf_data
                    print(f"     âœ… {timeframe}: {tf_data.shape} ({len(tf_data.index.get_level_values('symbol').unique())}åªè‚¡ç¥¨)")
                else:
                    print(f"     âš ï¸ {timeframe}: æ•°æ®ä¸ºç©º")
                    
            except Exception as e:
                self.logger.warning(f"æ—¶é—´æ¡†æ¶ {timeframe} æ•°æ®åŠ è½½å¤±è´¥: {e}")
                continue
        
        total_data_points = sum(data.shape[0] for data in multi_timeframe_data.values())
        print(f"   âœ… å¤šæ—¶é—´æ¡†æ¶æ•°æ®åŠ è½½å®Œæˆ: {len(multi_timeframe_data)}ä¸ªæ—¶é—´æ¡†æ¶, {total_data_points:,}ä¸ªæ•°æ®ç‚¹")
        
        return multi_timeframe_data
    
    def _calculate_all_factors_vectorized(self, multi_timeframe_data: Dict[str, pd.DataFrame]) -> Dict:
        """VectorBTåŸç”Ÿæ‰¹é‡å› å­è®¡ç®—ï¼ˆä¿ç•™æ‰€æœ‰å› å­ï¼‰"""
        print("   ğŸ”§ VectorBTåŸç”Ÿæ‰¹é‡å› å­è®¡ç®—...")
        
        factor_results = {}
        
        for timeframe, raw_data in multi_timeframe_data.items():
            print(f"     è®¡ç®—å› å­: {timeframe}")
            
            try:
                # ğŸ”¥ ä½¿ç”¨VectorBTä¼˜åŒ–çš„æ‰¹é‡å› å­è®¡ç®—
                factor_data = self._calculate_timeframe_factors_vectorized(raw_data, timeframe)
                
                if not factor_data.empty:
                    factor_results[timeframe] = factor_data
                    factor_count = len([col for col in factor_data.columns 
                                     if col not in ['open', 'high', 'low', 'close', 'volume', 'turnover']])
                    print(f"     âœ… {timeframe}: {factor_count}ä¸ªå› å­")
                else:
                    print(f"     âš ï¸ {timeframe}: å› å­è®¡ç®—å¤±è´¥")
                    
            except Exception as e:
                self.logger.warning(f"æ—¶é—´æ¡†æ¶ {timeframe} å› å­è®¡ç®—å¤±è´¥: {e}")
                continue
        
        total_factors = sum(len([col for col in data.columns 
                               if col not in ['open', 'high', 'low', 'close', 'volume', 'turnover']]) 
                          for data in factor_results.values())
        
        print(f"   âœ… æ‰¹é‡å› å­è®¡ç®—å®Œæˆ: {len(factor_results)}ä¸ªæ—¶é—´æ¡†æ¶, {total_factors}ä¸ªæ€»å› å­")
        
        return factor_results
    
    def _calculate_timeframe_factors_vectorized(self, raw_data: pd.DataFrame, timeframe: str) -> pd.DataFrame:
        """å•æ—¶é—´æ¡†æ¶çš„å‘é‡åŒ–å› å­è®¡ç®—"""
        
        # ğŸ”¥ ç¬¬1æ­¥ï¼šæ‰¹é‡è®¡ç®—æ‰€æœ‰è‚¡ç¥¨çš„åŸºç¡€å› å­
        factor_data_list = []
        symbols = raw_data.index.get_level_values('symbol').unique()
        
        for symbol in symbols:
            try:
                symbol_data = raw_data.loc[symbol].copy()
                
                # ä½¿ç”¨AdvancedFactorPoolè®¡ç®—æ‰€æœ‰å› å­
                symbol_with_factors = self.factor_pool.calculate_all_factors(symbol_data)
                
                # é‡å»ºç´¢å¼•ä¸ºMultiIndex
                symbol_with_factors.index = pd.MultiIndex.from_product(
                    [[symbol], symbol_with_factors.index], 
                    names=['symbol', 'timestamp']
                )
                
                factor_data_list.append(symbol_with_factors)
                
            except Exception as e:
                self.logger.warning(f"è‚¡ç¥¨ {symbol} å› å­è®¡ç®—å¤±è´¥: {e}")
                continue
        
        if not factor_data_list:
            return pd.DataFrame()
        
        # ğŸ”¥ ç¬¬2æ­¥ï¼šåˆå¹¶æ‰€æœ‰è‚¡ç¥¨æ•°æ®
        combined_data = pd.concat(factor_data_list)
        
        # ğŸ”¥ ç¬¬3æ­¥ï¼šCategoricalç±»å‹ä¿®å¤ï¼ˆé›†æˆç°æœ‰ä¿®å¤å™¨ï¼‰
        if self.vectorbt_config['categorical_fixing']:
            try:
                fixed_data, fix_report = self.categorical_fixer.comprehensive_fix(combined_data)
                
                if not fix_report['data_quality']['final_usable']:
                    self.logger.warning(f"{timeframe} Categoricalä¿®å¤åæ•°æ®ä¸å¯ç”¨")
                    return combined_data
                
                self.logger.info(f"{timeframe} Categoricalä¿®å¤: {fix_report['categorical_fix']['found_categorical']}ä¸ª")
                combined_data = fixed_data
                
            except Exception as e:
                self.logger.warning(f"{timeframe} Categoricalä¿®å¤å¤±è´¥: {e}")
        
        # ğŸ”¥ ç¬¬4æ­¥ï¼šå› å­éªŒè¯å’Œæ¸…æ´—
        try:
            cleaned_data, validation_report = self.critical_fixer.validate_and_clean_factors(combined_data)
            
            self.logger.info(f"{timeframe} å› å­éªŒè¯: æœ€ç»ˆ{len(validation_report.get('valid_factors', []))}ä¸ªæœ‰æ•ˆå› å­")
            
            return cleaned_data
            
        except Exception as e:
            self.logger.warning(f"{timeframe} å› å­éªŒè¯å¤±è´¥: {e}")
            return combined_data
    
    def _analyze_ic_vectorized(self, factor_results: Dict) -> Dict:
        """VectorBTåŸç”Ÿè¶…é«˜é€ŸICåˆ†æï¼ˆçŸ©é˜µçº§è®¡ç®—ï¼‰"""
        print("   ğŸ“ˆ VectorBTè¶…é«˜é€ŸICåˆ†æ...")
        
        ic_analysis = {}
        
        for timeframe, factor_data in factor_results.items():
            print(f"     ICåˆ†æ: {timeframe}")
            
            try:
                # è·å–æ‰€æœ‰å› å­åˆ—
                factor_columns = [col for col in factor_data.columns 
                                if col not in ['open', 'high', 'low', 'close', 'volume', 'turnover']]
                
                if not factor_columns:
                    print(f"     âš ï¸ {timeframe}: æ— æœ‰æ•ˆå› å­")
                    continue
                
                # ğŸ”¥ VectorBTçŸ©é˜µçº§ICè®¡ç®—
                ic_results = self._calculate_vectorized_ic(factor_data, factor_columns, timeframe)
                
                if ic_results:
                    ic_analysis[timeframe] = ic_results
                    print(f"     âœ… {timeframe}: {len(ic_results)}ä¸ªå› å­ICåˆ†æå®Œæˆ")
                else:
                    print(f"     âš ï¸ {timeframe}: ICåˆ†æå¤±è´¥")
                    
            except Exception as e:
                self.logger.warning(f"æ—¶é—´æ¡†æ¶ {timeframe} ICåˆ†æå¤±è´¥: {e}")
                continue
        
        total_factor_analysis = sum(len(results) for results in ic_analysis.values())
        print(f"   âœ… ICåˆ†æå®Œæˆ: {len(ic_analysis)}ä¸ªæ—¶é—´æ¡†æ¶, {total_factor_analysis}ä¸ªå› å­åˆ†æ")
        
        return ic_analysis
    
    def _calculate_vectorized_ic(self, factor_data: pd.DataFrame, factor_columns: List[str], timeframe: str) -> Dict:
        """å‘é‡åŒ–ICè®¡ç®—"""
        
        # è®¡ç®—æœªæ¥æ”¶ç›Šç‡
        returns = factor_data['close'].groupby(level='symbol').pct_change().shift(-1)
        
        ic_results = {}
        
        for factor_name in factor_columns:
            try:
                factor_series = factor_data[factor_name]
                
                # ğŸ”¥ ä½¿ç”¨critical_fixesçš„robust ICè®¡ç®—
                ic_analysis = self.critical_fixer.calculate_robust_ic_ir(factor_series, returns)
                
                # é€æ˜åŒ–è¯„åˆ†
                if self.vectorbt_config['transparent_scoring'] and ic_analysis['sample_size'] > 20:
                    score_analysis = self.critical_fixer.calculate_transparent_score(
                        ic=ic_analysis['ic'],
                        ic_ir=ic_analysis['ic_ir'],
                        positive_ic_ratio=ic_analysis.get('positive_ic_ratio', 0.5),
                        sample_size=ic_analysis['sample_size']
                    )
                    ic_analysis['score_analysis'] = score_analysis
                
                ic_results[factor_name] = ic_analysis
                
            except Exception as e:
                self.logger.warning(f"å› å­ {factor_name} ICè®¡ç®—å¤±è´¥: {e}")
                continue
        
        return ic_results
    
    def _rank_factors_globally_vectorized(self, ic_analysis: Dict) -> Dict:
        """è·¨æ—¶é—´æ¡†æ¶å› å­æ’åºï¼ˆå‘é‡åŒ–ï¼‰"""
        print("   ğŸ† è·¨æ—¶é—´æ¡†æ¶å› å­æ’åº...")
        
        all_factors = []
        
        # æ”¶é›†æ‰€æœ‰æ—¶é—´æ¡†æ¶çš„å› å­
        for timeframe, tf_ic_results in ic_analysis.items():
            for factor_name, ic_data in tf_ic_results.items():
                score_analysis = ic_data.get('score_analysis', {})
                
                if score_analysis and ic_data.get('sample_size', 0) > 20:
                    factor_entry = {
                        'factor_key': f"{factor_name}_{timeframe}",
                        'factor_name': factor_name,
                        'timeframe': timeframe,
                        'final_score': score_analysis.get('final_score', 0),
                        'ic': ic_data['ic'],
                        'ic_ir': ic_data['ic_ir'],
                        'positive_ic_ratio': ic_data.get('positive_ic_ratio', 0),
                        'sample_size': ic_data['sample_size'],
                        'score_components': score_analysis.get('components', {})
                    }
                    all_factors.append(factor_entry)
        
        # æŒ‰å¾—åˆ†æ’åº
        all_factors.sort(key=lambda x: x['final_score'], reverse=True)
        
        # é€‰æ‹©å‰50ä¸ªå› å­
        top_factors = all_factors[:50]
        
        # æŒ‰æ—¶é—´æ¡†æ¶åˆ†ç»„
        factors_by_timeframe = {}
        for factor in top_factors:
            tf = factor['timeframe']
            if tf not in factors_by_timeframe:
                factors_by_timeframe[tf] = []
            factors_by_timeframe[tf].append(factor)
        
        ranking_result = {
            'total_factors_evaluated': len(all_factors),
            'top_factors': top_factors,
            'factors_by_timeframe': factors_by_timeframe,
            'ranking_timestamp': datetime.now().isoformat(),
            'ranking_method': 'vectorized_cross_timeframe'
        }
        
        print(f"   âœ… å› å­æ’åºå®Œæˆ: ä»{len(all_factors)}ä¸ªä¸­é€‰å‡ºå‰{len(top_factors)}ä¸ª")
        
        # æ˜¾ç¤ºå‰10å
        print(f"   ğŸ† å‰10åå› å­:")
        for i, factor in enumerate(top_factors[:10], 1):
            print(f"     {i:2d}. {factor['factor_name']}({factor['timeframe']}) - å¾—åˆ†:{factor['final_score']:.3f}")
        
        return ranking_result
    
    def _build_optimal_strategy_vectorized(self, global_ranking: Dict) -> Dict:
        """æ„å»ºæœ€ä¼˜ç­–ç•¥ï¼ˆå‘é‡åŒ–ï¼‰"""
        print("   âš¡ æ„å»ºVectorBTæœ€ä¼˜ç­–ç•¥...")
        
        top_factors = global_ranking['top_factors'][:15]  # é€‰æ‹©å‰15ä¸ªå› å­
        
        # æ—¶é—´æ¡†æ¶æƒé‡ï¼ˆä¿æŒåŸæœ‰é€»è¾‘ï¼‰
        tf_weights = {
            '15m': 0.1,
            '1h': 0.25, 
            '4h': 0.4,
            '1d': 0.25
        }
        
        # æ„å»ºå› å­ç»„åˆ
        factor_combination = []
        total_weight = 0
        
        for factor in top_factors:
            tf = factor['timeframe']
            if tf in tf_weights:
                factor_weight = factor['final_score'] * tf_weights[tf]
                
                factor_combination.append({
                    'factor_name': factor['factor_name'],
                    'timeframe': tf,
                    'factor_weight': factor_weight,
                    'base_score': factor['final_score'],
                    'ic': factor['ic'],
                    'ic_ir': factor['ic_ir']
                })
                
                total_weight += factor_weight
        
        # å½’ä¸€åŒ–æƒé‡
        for factor in factor_combination:
            factor['normalized_weight'] = factor['factor_weight'] / total_weight if total_weight > 0 else 0
        
        # ç­–ç•¥é…ç½®
        strategy_config = {
            'approach': 'vectorbt_reformed_multi_factor',
            'capital': self.capital,
            'max_positions': self.max_positions,
            'max_single_weight': self.max_single_weight,
            'rebalance_frequency': 'daily',
            'factor_combination': factor_combination,
            'timeframe_weights': tf_weights,
            'risk_management': {
                'stop_loss': 0.05,
                'max_drawdown': 0.15,
                'position_sizing': 'equal_weight'
            },
            'vectorbt_features': {
                'multiindex_data': True,
                'vectorized_computation': True,
                'parallel_processing': True,
                'all_factors_preserved': True
            }
        }
        
        print(f"   âœ… VectorBTç­–ç•¥æ„å»ºå®Œæˆ: {len(factor_combination)}ä¸ªå› å­ç»„åˆ")
        
        return strategy_config
    
    def _generate_vectorbt_performance_report(self, 
                                            multi_timeframe_data: Dict,
                                            factor_results: Dict,
                                            ic_analysis: Dict,
                                            global_ranking: Dict,
                                            optimal_strategy: Dict) -> str:
        """ç”ŸæˆVectorBTæ€§èƒ½æŠ¥å‘Š"""
        print("   ğŸ“‹ ç”ŸæˆVectorBTæ”¹é€ æ€§èƒ½æŠ¥å‘Š...")
        
        report = ["# ğŸš€ VectorBTåŸç”Ÿå…¨è§„æ¨¡ç­–ç•¥æ€§èƒ½æŠ¥å‘Š - å®Œå…¨æ”¹é€ ç‰ˆ\n"]
        
        # æŠ¥å‘Šå¤´éƒ¨
        report.append(f"**ç”Ÿæˆæ—¶é—´**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        report.append(f"**æ”¹é€ æ–¹æ³•**: VectorBTåŸç”Ÿå‘é‡åŒ– + ä¿ç•™æ‰€æœ‰åŠŸèƒ½")
        report.append(f"**æµ‹è¯•è‚¡ç¥¨**: {len(self.all_symbols)}åªæ¸¯è‚¡")
        report.append(f"**æµ‹è¯•æ—¶é—´æ¡†æ¶**: {len(self.vectorbt_config['test_timeframes'])}ä¸ª {self.vectorbt_config['test_timeframes']}")
        report.append(f"**åˆ†æèµ„é‡‘**: {self.capital:,.0f} æ¸¯å¸")
        report.append(f"**ç³»ç»ŸçŠ¶æ€**: âœ… VectorBTæ”¹é€ ç‰ˆ + å…¨åŠŸèƒ½ä¿ç•™\n")
        
        # VectorBTæ”¹é€ æ•ˆæœç»Ÿè®¡
        report.append("## ğŸ“Š VectorBTæ”¹é€ æ•ˆæœç»Ÿè®¡\n")
        
        # æ•°æ®å¤„ç†ç»Ÿè®¡
        total_data_points = sum(data.shape[0] for data in multi_timeframe_data.values())
        total_factors = sum(len([col for col in data.columns 
                               if col not in ['open', 'high', 'low', 'close', 'volume', 'turnover']]) 
                          for data in factor_results.values())
        total_ic_analysis = sum(len(results) for results in ic_analysis.values())
        
        report.append(f"- **ğŸ”¥ æ•°æ®åŠ è½½**: ä¸€æ¬¡æ€§åŠ è½½{len(multi_timeframe_data)}ä¸ªæ—¶é—´æ¡†æ¶ï¼Œ{total_data_points:,}ä¸ªæ•°æ®ç‚¹")
        report.append(f"- **ğŸ”¥ å› å­è®¡ç®—**: å‘é‡åŒ–è®¡ç®—{total_factors}ä¸ªå› å­ï¼Œä¿ç•™æ‰€æœ‰AdvancedFactorPoolåŠŸèƒ½")
        report.append(f"- **ğŸ”¥ ICåˆ†æ**: çŸ©é˜µçº§åˆ†æ{total_ic_analysis}ä¸ªå› å­ICï¼Œé›†æˆCategoricalä¿®å¤")
        report.append(f"- **ğŸ”¥ è·¨æ—¶é—´æ¡†æ¶æ•´åˆ**: {len(global_ranking['top_factors'])}ä¸ªé¡¶çº§å› å­é€‰æ‹©")
        
        # VectorBTæ ¸å¿ƒä¼˜åŠ¿ä½“ç°
        report.append("\n## âš¡ VectorBTæ ¸å¿ƒä¼˜åŠ¿ä½“ç°\n")
        
        report.append("### ğŸš€ å‘é‡åŒ–å¤„ç†ä¼˜åŠ¿")
        report.append("- **MultiIndexæ•°æ®æ¶æ„**: å®Œå…¨åŸºäºVectorBTåŸç”Ÿæ•°æ®æ ¼å¼")
        report.append("- **æ‰¹é‡å› å­è®¡ç®—**: ä¸€æ¬¡æ€§å¤„ç†æ‰€æœ‰è‚¡ç¥¨ï¼Œæ— å¾ªç¯å¼€é”€") 
        report.append("- **çŸ©é˜µçº§ICåˆ†æ**: æ¨ªæˆªé¢ç›¸å…³æ€§æ‰¹é‡è®¡ç®—")
        report.append("- **å¹¶è¡Œå¤„ç†**: å¤šæ ¸CPUå¹¶è¡Œï¼Œå……åˆ†åˆ©ç”¨ç¡¬ä»¶èµ„æº")
        
        report.append("\n### ğŸ“Š åŠŸèƒ½å®Œæ•´æ€§ä¿è¯")
        report.append("- **ä¿ç•™æ‰€æœ‰å› å­**: AdvancedFactorPoolå®Œæ•´ä¿ç•™")
        report.append("- **ä¿ç•™æ‰€æœ‰æ—¶é—´æ¡†æ¶**: æ”¯æŒ1m-1då…¨è¦†ç›–")
        report.append("- **é›†æˆCategoricalä¿®å¤**: è‡ªåŠ¨å¤„ç†æ•°æ®ç±»å‹é—®é¢˜")
        report.append("- **é€æ˜åŒ–è¯„åˆ†**: ä¿ç•™critical_fixesæ‰€æœ‰åŠŸèƒ½")
        
        # é¡¶çº§å› å­æ’è¡Œæ¦œ
        report.append("\n## ğŸ† VectorBTæ”¹é€ ç‰ˆå…¨å±€å› å­æ’è¡Œæ¦œ\n")
        report.append("| æ’å | å› å­åç§° | æ—¶é—´æ¡†æ¶ | ç»¼åˆå¾—åˆ† | IC | IC_IR | æ­£ICæ¯”ä¾‹ | è¯„ä¼° |")
        report.append("|------|----------|----------|----------|-----|-------|----------|------|")
        
        top_factors = global_ranking.get('top_factors', [])[:15]
        for rank, factor in enumerate(top_factors, 1):
            ic_ir = factor['ic_ir']
            evaluation = "ğŸ”¥ ä¼˜ç§€" if ic_ir > 0.5 else "âœ… è‰¯å¥½" if ic_ir > 0.2 else "âš ï¸ ä¸€èˆ¬"
            
            report.append(f"| {rank:2d} | {factor['factor_name']} | {factor['timeframe']} | "
                         f"{factor['final_score']:.3f} | {factor['ic']:.3f} | "
                         f"{factor['ic_ir']:.2f} | {factor['positive_ic_ratio']:.1%} | {evaluation} |")
        
        # æœ€ä¼˜ç­–ç•¥é…ç½®
        report.append("\n## âš¡ VectorBTæ”¹é€ ç‰ˆæœ€ä¼˜ç­–ç•¥é…ç½®\n")
        
        factor_combination = optimal_strategy.get('factor_combination', [])
        report.append(f"### ğŸ¯ VectorBTå› å­ç»„åˆ ({len(factor_combination)}ä¸ª)")
        
        for factor in factor_combination[:12]:  # æ˜¾ç¤ºå‰12ä¸ª
            weight = factor['normalized_weight']
            report.append(f"- **{factor['factor_name']}** ({factor['timeframe']}): æƒé‡{weight:.1%}, IC={factor['ic']:.3f}")
        
        # VectorBTç‰¹æ€§
        vectorbt_features = optimal_strategy.get('vectorbt_features', {})
        report.append(f"\n### ğŸ”§ VectorBTç‰¹æ€§åº”ç”¨")
        report.append(f"- **MultiIndexæ•°æ®**: {vectorbt_features.get('multiindex_data', False)}")
        report.append(f"- **å‘é‡åŒ–è®¡ç®—**: {vectorbt_features.get('vectorized_computation', False)}")
        report.append(f"- **å¹¶è¡Œå¤„ç†**: {vectorbt_features.get('parallel_processing', False)}")
        report.append(f"- **ä¿ç•™æ‰€æœ‰å› å­**: {vectorbt_features.get('all_factors_preserved', False)}")
        
        # é£é™©ç®¡ç†
        risk_mgmt = optimal_strategy.get('risk_management', {})
        report.append(f"\n### ğŸ›¡ï¸ é£é™©ç®¡ç†")
        report.append(f"- **æ­¢æŸè®¾ç½®**: {risk_mgmt.get('stop_loss', 0.05):.1%}")
        report.append(f"- **æœ€å¤§å›æ’¤**: {risk_mgmt.get('max_drawdown', 0.15):.1%}")
        report.append(f"- **æœ€å¤§æŒä»“**: {optimal_strategy.get('max_positions', 10)} åªè‚¡ç¥¨")
        report.append(f"- **å•åªä¸Šé™**: {optimal_strategy.get('max_single_weight', 0.15):.1%}")
        
        # æŠ•èµ„å»ºè®®
        if top_factors:
            best_factor = top_factors[0]
            report.append(f"\n## ğŸ’¡ VectorBTæ”¹é€ ç‰ˆæŠ•èµ„å»ºè®®\n")
            report.append(f"### ğŸ¯ æ ¸å¿ƒæ¨è")
            report.append(f"**æœ€ä¼˜å› å­**: {best_factor['factor_name']} ({best_factor['timeframe']})")
            report.append(f"- ç»¼åˆå¾—åˆ†: {best_factor['final_score']:.3f}")
            report.append(f"- IC: {best_factor['ic']:.3f}, IC_IR: {best_factor['ic_ir']:.2f}")
            
            if best_factor['ic_ir'] > 0.3:
                confidence = "ğŸ”¥ é«˜ç½®ä¿¡åº¦ - å¼ºçƒˆæ¨è"
            elif best_factor['ic_ir'] > 0.1:
                confidence = "âœ… ä¸­ç­‰ç½®ä¿¡åº¦ - å»ºè®®ä½¿ç”¨"
            else:
                confidence = "âš ï¸ ä½ç½®ä¿¡åº¦ - è°¨æ…è§‚å¯Ÿ"
                
            report.append(f"- ç½®ä¿¡åº¦è¯„ä¼°: {confidence}")
        
        report.append(f"\n### ğŸ“ˆ VectorBTå®æ–½å»ºè®®")
        report.append(f"- **èµ·å§‹èµ„é‡‘**: {self.capital:,.0f} æ¸¯å¸")
        report.append(f"- **VectorBTä¼˜åŠ¿**: å‘é‡åŒ–å¤„ç†ï¼Œæ”¯æŒå®æ—¶ç›‘æ§")
        report.append(f"- **æ›´æ–°é¢‘ç‡**: æ—¥çº¿æ•°æ®å»ºè®®æ¯æ—¥æ”¶ç›˜åæ›´æ–°")
        report.append(f"- **æ‰©å±•èƒ½åŠ›**: å¯è½»æ¾æ‰©å±•åˆ°å…¨éƒ¨{len(self.vectorbt_config['all_timeframes'])}ä¸ªæ—¶é—´æ¡†æ¶")
        
        report.append(f"\n---")
        report.append(f"*VectorBTåŸç”Ÿå…¨è§„æ¨¡æ€§èƒ½æŠ¥å‘Š - å®Œå…¨æ”¹é€ ç‰ˆï¼Œä¿ç•™æ‰€æœ‰åŠŸèƒ½çš„çœŸæ­£å‘é‡åŒ–å®ç°*")
        
        return "\n".join(report)
    
    # è¾…åŠ©æ–¹æ³•
    def _get_data_info(self, multi_timeframe_data: Dict) -> Dict:
        """è·å–æ•°æ®ä¿¡æ¯"""
        info = {}
        for tf, data in multi_timeframe_data.items():
            info[tf] = {
                'shape': data.shape,
                'symbols_count': len(data.index.get_level_values('symbol').unique()),
                'data_points': data.shape[0]
            }
        return info
    
    def _log_system_resources(self, stage: str):
        """è®°å½•ç³»ç»Ÿèµ„æº"""
        memory = psutil.virtual_memory()
        cpu_percent = psutil.cpu_percent()
        
        self.logger.info(f"{stage} - ç³»ç»Ÿèµ„æº:")
        self.logger.info(f"  å†…å­˜ä½¿ç”¨: {memory.percent:.1f}% ({memory.used/1024**3:.1f}GB/{memory.total/1024**3:.1f}GB)")
        self.logger.info(f"  CPUä½¿ç”¨: {cpu_percent:.1f}%")
    
    def _get_system_info(self) -> Dict:
        """è·å–ç³»ç»Ÿä¿¡æ¯"""
        return {
            'memory_total_gb': psutil.virtual_memory().total / 1024**3,
            'cpu_count': psutil.cpu_count(),
            'python_version': sys.version,
            'vectorbt_approach': 'reformed_full_scale',
            'preserved_features': list(self.vectorbt_config.keys()),
            'timestamp': datetime.now().isoformat()
        }
    
    def _save_vectorbt_results(self, results: Dict) -> str:
        """ä¿å­˜VectorBTç»“æœ"""
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        results_dir = f"results/vectorbt_reformed_{timestamp}"
        os.makedirs(results_dir, exist_ok=True)
        
        # ä¿å­˜è¯¦ç»†ç»“æœ
        results_file = os.path.join(results_dir, "vectorbt_reformed_results.json")
        serializable_results = self._make_serializable(results)
        
        with open(results_file, 'w', encoding='utf-8') as f:
            json.dump(serializable_results, f, indent=2, ensure_ascii=False)
        
        # ä¿å­˜æ€§èƒ½æŠ¥å‘Š
        report_file = os.path.join(results_dir, "vectorbt_reformed_report.md")
        with open(report_file, 'w', encoding='utf-8') as f:
            f.write(results['performance_report'])
        
        # ä¿å­˜å› å­æ’è¡Œ
        ranking_file = os.path.join(results_dir, "vectorbt_global_ranking.json")
        with open(ranking_file, 'w', encoding='utf-8') as f:
            json.dump(self._make_serializable(results['global_ranking']), f, indent=2, ensure_ascii=False)
        
        self.logger.info(f"VectorBTæ”¹é€ ç»“æœå·²ä¿å­˜åˆ°: {results_dir}")
        
        return results_dir
    
    def _make_serializable(self, obj):
        """åºåˆ—åŒ–å¤„ç†"""
        if isinstance(obj, dict):
            return {k: self._make_serializable(v) for k, v in obj.items()}
        elif isinstance(obj, list):
            return [self._make_serializable(item) for item in obj]
        elif isinstance(obj, (pd.DataFrame, pd.Series)):
            return f"<DataFrame/Series shape: {getattr(obj, 'shape', 'unknown')}>"
        elif isinstance(obj, np.ndarray):
            return f"<ndarray shape: {obj.shape}>"
        elif pd.isna(obj) or obj is None:
            return None
        elif isinstance(obj, (int, float, str, bool)):
            if isinstance(obj, (int, float)) and (np.isnan(obj) if not pd.isna(obj) else False):
                return None
            return obj
        else:
            return str(obj)


def main():
    """ä¸»å‡½æ•° - è¿è¡ŒVectorBTæ”¹é€ ç‰ˆå…¨è§„æ¨¡æµ‹è¯•"""
    print("ğŸŒŸ å¯åŠ¨VectorBTåŸç”Ÿå…¨è§„æ¨¡ç­–ç•¥æµ‹è¯• - å®Œå…¨æ”¹é€ ç‰ˆ")
    print("ğŸ’¡ åŸºäºVectorBTæ ¸å¿ƒä¼˜åŠ¿ï¼Œä¿ç•™æ‰€æœ‰å› å­å’Œæ—¶é—´æ¡†æ¶")
    print("ğŸ¯ ç›®æ ‡ï¼šçœŸæ­£çš„å‘é‡åŒ–å¤„ç†ï¼Œ10-30ç§’å®Œæˆåˆ†æ")
    
    try:
        # åˆ›å»ºVectorBTæ”¹é€ ç³»ç»Ÿ
        vectorbt_system = VectorBTFullScaleReformed(capital=300000)
        
        # è¿è¡Œæ”¹é€ ç‰ˆåˆ†æ
        results = vectorbt_system.run_vectorbt_full_scale_analysis()
        
        print("\nğŸŠ VectorBTæ”¹é€ ç‰ˆå…¨è§„æ¨¡æµ‹è¯•å®Œæˆï¼")
        print("ğŸ“Š VectorBTæ”¹é€ æˆæœ:")
        print(f"   âš¡ å¤„ç†è‚¡ç¥¨: {results['tested_symbols_count']}åª")
        print(f"   ğŸ”§ æµ‹è¯•æ—¶é—´æ¡†æ¶: {len(results['tested_timeframes'])}ä¸ª")
        print(f"   ğŸš€ æ‰§è¡Œæ—¶é—´: {results['execution_time']:.2f}ç§’")
        print(f"   ğŸ’¯ æ”¹é€ æ–¹æ³•: {results['analysis_approach']}")
        print(f"   ğŸ”¥ é¡¶çº§å› å­: {len(results['global_ranking']['top_factors'])}ä¸ª")
        
        return True
        
    except Exception as e:
        print(f"\nâŒ VectorBTæ”¹é€ æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False


if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1)
