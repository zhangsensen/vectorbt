#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ğŸš€ ä¼˜åŒ–ç‰ˆæœ€ç»ˆå·¥ä½œç³»ç»Ÿ V2.0
===============================

åŸºäºåŸç‰ˆfinal_working_vectorbt.pyçš„ä¼˜åŒ–ç‰ˆæœ¬
ä¿æŒåŸç‰ˆçš„ç¨³å®šé€»è¾‘ï¼Œä½†é›†æˆå‘é‡åŒ–æŠ€æœ¯æå‡æ€§èƒ½

å…³é”®ç‰¹æ€§ï¼š
- ğŸ”¥ ä¿æŒåŸç‰ˆV3çš„æ ¸å¿ƒé€»è¾‘å’Œå‚æ•°
- âš¡ é›†æˆå‘é‡åŒ–æ‰¹é‡å›æµ‹æå‡æ€§èƒ½  
- ğŸ›¡ï¸ å®Œæ•´çš„é”™è¯¯å¤„ç†å’Œæ—¥å¿—ç³»ç»Ÿ
- ğŸ“Š ä¸åŸç‰ˆå®Œå…¨ä¸€è‡´çš„è¾“å‡ºæ ¼å¼

Author: Optimized VectorBT System V2
Date: 2025-09-11
"""

import os
import sys
import time
import json
import logging
import warnings
import numpy as np
import pandas as pd
from datetime import datetime
from typing import Dict, List, Optional, Tuple, Any
import psutil

# VectorBTå’ŒæŠ€æœ¯æŒ‡æ ‡
try:
    import vectorbt as vbt
    import talib
    print("âœ… VectorBTå’ŒTA-LibåŠ è½½æˆåŠŸ")
except ImportError as e:
    print(f"âŒ å¯¼å…¥é”™è¯¯: {e}")
    sys.exit(1)

# å¯¼å…¥è‡ªå®šä¹‰æ¨¡å—
from factors.factor_pool import AdvancedFactorPool
from utils.dtype_fixer import CategoricalDtypeFixer
from strategies.cta_eval_v3 import CTAEvaluatorV3

# ç»Ÿè®¡å­¦åº“
try:
    from statsmodels.stats.diagnostic import acorr_ljungbox
    from statsmodels.tsa.stattools import acf
    from statsmodels.regression.linear_model import OLS
    from statsmodels.stats.sandwich_covariance import cov_hac
    print("âœ… StatsmodelsåŠ è½½æˆåŠŸ")
except ImportError:
    print("âš ï¸ Statsmodelsæœªå®‰è£…ï¼Œå°†ä½¿ç”¨ç®€åŒ–ç‰ˆIC_IRè®¡ç®—")

warnings.filterwarnings('ignore')

class OptimizedFinalWorking:
    """
    ğŸš€ ä¼˜åŒ–ç‰ˆæœ€ç»ˆå·¥ä½œç³»ç»Ÿ
    åŸºäºåŸç‰ˆé€»è¾‘ï¼Œé›†æˆå‘é‡åŒ–ä¼˜åŒ–
    """
    
    def __init__(self, data_dir: str = "/Users/zhangshenshen/longport/vectorized_factor_analyzer_v2/data", capital: float = 300000):
        self.data_dir = data_dir
        self.capital = capital
        self.timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        
        # ğŸ”¥ ç»§æ‰¿åŸç‰ˆçš„ç¨³å®šé…ç½®
        self.working_config = {
            'test_timeframes': ['1m', '2m', '3m', '5m', '10m', '15m', '30m', '1h', '4h', '1d'],
            'max_symbols': 54,
            'evaluation_mode': 'cta',  # ä½¿ç”¨ç¨³å®šçš„CTAæ¨¡å¼
            
            # åŸç‰ˆV3çš„å®½æ¾é˜ˆå€¼
            'min_ic_threshold': 0.005,
            'min_ir_threshold': 0.01,
            'min_sample_size': 10,
            'min_supporting_stocks': 2,
            
            # å¯ç”¨åŠŸèƒ½
            'full_factor_pool': True,
            'debug_mode': True
        }
        
        # è®¾ç½®æ—¥å¿—
        self._setup_logging()
        
        # åˆå§‹åŒ–ç»„ä»¶
        self.factor_pool = AdvancedFactorPool()
        self.categorical_fixer = CategoricalDtypeFixer()
        
        # è·å–æµ‹è¯•è‚¡ç¥¨
        self.test_symbols = self._get_test_symbols()
        self.logger.info(f"âœ… æµ‹è¯•è‚¡ç¥¨: {self.test_symbols}")
        
    def _setup_logging(self):
        """è®¾ç½®æ—¥å¿—ç³»ç»Ÿ"""
        log_dir = f"logs/optimized_final_{self.timestamp}"
        os.makedirs(log_dir, exist_ok=True)
        
        self.logger = logging.getLogger('OptimizedFinal')
        self.logger.setLevel(logging.DEBUG)
        
        # æ¸…é™¤ç°æœ‰å¤„ç†å™¨
        for handler in self.logger.handlers[:]:
            self.logger.removeHandler(handler)
        
        # æ–‡ä»¶å¤„ç†å™¨
        file_handler = logging.FileHandler(
            f"{log_dir}/optimized_final.log", 
            encoding='utf-8'
        )
        
        # æ§åˆ¶å°å¤„ç†å™¨
        console_handler = logging.StreamHandler()
        
        # æ ¼å¼å™¨
        formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')
        file_handler.setFormatter(formatter)
        console_handler.setFormatter(formatter)
        
        self.logger.addHandler(file_handler)
        self.logger.addHandler(console_handler)
    
    def _get_test_symbols(self) -> List[str]:
        """è·å–æµ‹è¯•è‚¡ç¥¨"""
        # ä¼˜å…ˆé€‰æ‹©æœ‰ä»£è¡¨æ€§çš„è‚¡ç¥¨
        priority_symbols = ['0700.HK', '0005.HK', '0388.HK', '1211.HK', '0981.HK']
        
        available_symbols = []
        
        # æ£€æŸ¥1dæ•°æ®ç¡®ä¿è‚¡ç¥¨å¯ç”¨
        d1_dir = os.path.join(self.data_dir, '1d')
        if os.path.exists(d1_dir):
            for symbol in priority_symbols:
                file_path = os.path.join(d1_dir, f'{symbol}.parquet')
                if os.path.exists(file_path):
                    available_symbols.append(symbol)
        
        # è¡¥å……åˆ°æŒ‡å®šæ•°é‡
        if len(available_symbols) < self.working_config['max_symbols']:
            for file in os.listdir(d1_dir):
                if file.endswith('.parquet'):
                    symbol = file.replace('.parquet', '')
                    if symbol not in available_symbols:
                        available_symbols.append(symbol)
                        if len(available_symbols) >= self.working_config['max_symbols']:
                            break
        
        return available_symbols[:self.working_config['max_symbols']]
    
    def _load_symbol_data(self, symbol: str, timeframe: str) -> pd.DataFrame:
        """åŠ è½½å•ä¸ªè‚¡ç¥¨æ•°æ®"""
        try:
            file_path = os.path.join(self.data_dir, timeframe, f'{symbol}.parquet')
            if not os.path.exists(file_path):
                return pd.DataFrame()
            
            df = pd.read_parquet(file_path)
            
            # æ ‡å‡†åŒ–ç´¢å¼•å’Œåˆ—
            if not isinstance(df.index, pd.DatetimeIndex):
                df.index = pd.to_datetime(df.index)
            
            # åˆ—åæ ‡å‡†åŒ–
            column_mapping = {
                'Close': 'close', 'Open': 'open', 'High': 'high', 
                'Low': 'low', 'Volume': 'volume', 'Turnover': 'turnover'
            }
            df = df.rename(columns=column_mapping)
            
            # ç¡®ä¿åŸºç¡€åˆ—å­˜åœ¨
            required_cols = ['open', 'high', 'low', 'close', 'volume']
            available_cols = [col for col in required_cols if col in df.columns]
            
            if len(available_cols) >= 4:
                return df[available_cols].dropna()
            else:
                return pd.DataFrame()
                
        except Exception as e:
            self.logger.debug(f"åŠ è½½{symbol}-{timeframe}å¤±è´¥: {e}")
            return pd.DataFrame()
    
    def _safe_divide(self, numerator, denominator, fill_value=0):
        """å®‰å…¨é™¤æ³•ï¼Œé¿å…é™¤é›¶å’ŒNaN"""
        # å¤„ç†Serieså’Œnumpyæ•°ç»„
        if hasattr(numerator, 'values'):
            num_vals = numerator.values
        else:
            num_vals = np.asarray(numerator)
            
        if hasattr(denominator, 'values'):
            den_vals = denominator.values
        else:
            den_vals = np.asarray(denominator)
        
        # é¿å…é™¤é›¶
        den_vals = np.where(np.abs(den_vals) < 1e-10, 1e-10, den_vals)
        
        result = num_vals / den_vals
        result = np.where(np.isinf(result), fill_value, result)
        result = np.where(np.isnan(result), fill_value, result)
        
        # è¿”å›pandas Serieså¦‚æœè¾“å…¥æ˜¯Series
        if hasattr(numerator, 'index'):
            return pd.Series(result, index=numerator.index)
        else:
            return result
    
    def _calculate_fixed_factors(self, df: pd.DataFrame) -> pd.DataFrame:
        """è®¡ç®—ä¿®å¤ç‰ˆå› å­ï¼Œè§£å†³NaNé—®é¢˜"""
        print(f"ğŸ”§ è®¡ç®—ä¿®å¤ç‰ˆå› å­: {df.shape}")
        
        # ç¡®ä¿æ•°å€¼ç±»å‹
        numeric_cols = ['open', 'high', 'low', 'close', 'volume']
        for col in numeric_cols:
            if col in df.columns:
                df[col] = pd.to_numeric(df[col], errors='coerce')
        
        high, low, close, volume = df.high, df.low, df.close, df.volume
        
        # ä½¿ç”¨åŸæœ‰çš„å› å­æ± ï¼Œä½†æ·»åŠ å…³é”®ä¿®å¤
        df = self.factor_pool.calculate_all_factors(df)
        
        # ä¿®å¤keltner_position
        try:
            import talib as ta  # ç¡®ä¿æœ¬åœ°å¯¼å…¥
            atr = ta.ATR(high.values, low.values, close.values, timeperiod=14)
            atr_series = pd.Series(atr, index=df.index)
            keltner_ma = close.rolling(20, min_periods=1).mean()
            keltner_atr = atr_series.rolling(20, min_periods=1).mean()
            keltner_upper = keltner_ma + 2 * keltner_atr
            keltner_lower = keltner_ma - 2 * keltner_atr
            
            # å®‰å…¨è®¡ç®—ä½ç½®
            band_width = keltner_upper - keltner_lower
            position_numerator = close - keltner_lower
            
            keltner_position = self._safe_divide(position_numerator, band_width, fill_value=0.5)
            keltner_position = np.clip(keltner_position, -1, 2)
            df['keltner_position'] = keltner_position
            
            valid_count = keltner_position.notna().sum()
            print(f"  âœ… Keltner Positionä¿®å¤: {valid_count}/{len(keltner_position)} æœ‰æ•ˆå€¼")
            
        except Exception as e:
            print(f"  âŒ Keltnerä¿®å¤å¤±è´¥: {e}")
            df['keltner_position'] = 0.5
        
        # ä¿®å¤VWAPåç¦»åº¦
        try:
            typical_price = (high + low + close) / 3
            window = min(20, len(df) // 2) if len(df) >= 40 else max(1, len(df) // 4)
            
            vwap = (typical_price * volume).rolling(window, min_periods=1).sum() / volume.rolling(window, min_periods=1).sum()
            vwap_deviation = self._safe_divide(close - vwap, vwap, fill_value=0.0)
            df['vwap_deviation'] = vwap_deviation
            
            valid_count = vwap_deviation.notna().sum()
            print(f"  âœ… VWAPåç¦»åº¦ä¿®å¤: {valid_count}/{len(vwap_deviation)} æœ‰æ•ˆå€¼")
            
        except Exception as e:
            print(f"  âŒ VWAPä¿®å¤å¤±è´¥: {e}")
            df['vwap_deviation'] = 0.0
        
        # ä¿®å¤åŠ¨æ€ranking
        try:
            # åŠ¨æ€ç¡®å®šçª—å£å¤§å°
            ranking_window = 288 * 2  # âœ…è¡¥ä¸5: 2å¤©çª—å£(5mæ•°æ®)
            print(f"  ğŸ”§ åŠ¨æ€rankingçª—å£: {ranking_window}")
            
            factors_to_rank = ['rsi_14', 'macd_enhanced', 'atrp', 'vwap_deviation']
            for factor in factors_to_rank:
                if factor in df.columns and not df[factor].isna().all():
                    try:
                        min_periods = max(1, ranking_window // 4)
                        factor_rank = df[factor].rolling(ranking_window, min_periods=min_periods).rank(pct=True)
                        df[f'{factor}_rank'] = factor_rank
                        valid_count = factor_rank.notna().sum()
                        print(f"    âœ… {factor}_rank: {valid_count}/{len(factor_rank)} æœ‰æ•ˆå€¼")
                    except Exception as rank_error:
                        print(f"    âŒ {factor}_rankå¤±è´¥: {rank_error}")
                        df[f'{factor}_rank'] = 0.5
                else:
                    df[f'{factor}_rank'] = 0.5
                    
        except Exception as e:
            print(f"  âŒ Rankingä¿®å¤å¤±è´¥: {e}")
        
        return df
    
    def _calculate_symbol_factors(self, symbol: str, data: pd.DataFrame) -> pd.DataFrame:
        """è®¡ç®—å•ä¸ªè‚¡ç¥¨çš„å› å­ - NaNé—®é¢˜ä¿®å¤ç‰ˆ"""
        if data.empty:
            return pd.DataFrame()
        
        try:
            # è®¡ç®—å› å­ (ä½¿ç”¨ä¿®å¤ç‰ˆæ–¹æ³•)
            factors_df = self._calculate_fixed_factors(data.copy())
            
            # åªä¿ç•™å› å­åˆ—
            base_cols = ['open', 'high', 'low', 'close', 'volume', 'turnover']
            factor_cols = [col for col in factors_df.columns if col not in base_cols]
            
            if factor_cols:
                factor_only_df = factors_df[factor_cols].copy()
                
                # Categoricalä¿®å¤
                factor_only_df, _ = self.categorical_fixer.comprehensive_fix(factor_only_df)
                
                return factor_only_df
            else:
                return pd.DataFrame()
                
        except Exception as e:
            self.logger.debug(f"{symbol} å› å­è®¡ç®—å¤±è´¥: {e}")
            return pd.DataFrame()
    
    def _run_cta_analysis(self, timeframe: str) -> Dict[str, Any]:
        """ğŸš€ ä¼˜åŒ–ç‰ˆCTAå›æµ‹åˆ†æ"""
        self.logger.info(f"ğŸ¯ ä¼˜åŒ–ç‰ˆCTAå›æµ‹åˆ†æ{timeframe}æ—¶é—´æ¡†æ¶...")
        self.logger.debug(f"  ç›®æ ‡è‚¡ç¥¨æ•°: {len(self.test_symbols)}")
        
        # 1. åŠ è½½æ‰€æœ‰è‚¡ç¥¨æ•°æ®å’Œå› å­
        symbol_data = {}
        symbol_factors = {}
        
        for symbol in self.test_symbols:
            data = self._load_symbol_data(symbol, timeframe)
            if not data.empty:
                symbol_data[symbol] = data
                self.logger.debug(f"    âœ… {symbol}: åŠ è½½{len(data)}æ¡æ•°æ®")
                
                # è®¡ç®—å› å­
                factors = self._calculate_symbol_factors(symbol, data)
                if not factors.empty:
                    symbol_factors[symbol] = factors
                    self.logger.debug(f"    ğŸ“Š {symbol}: è®¡ç®—{len(factors.columns)}ä¸ªå› å­")
        
        if not symbol_factors:
            self.logger.warning(f"âŒ {timeframe} æ— æœ‰æ•ˆå› å­æ•°æ®")
            return {}
        
        self.logger.info(f"  âœ… {len(symbol_factors)}åªè‚¡ç¥¨æœ‰æ•ˆï¼Œå¹³å‡{np.mean([len(f.columns) for f in symbol_factors.values()]):.0f}ä¸ªå› å­")
        
        # æ·»åŠ å†…å­˜ç›‘æ§
        try:
            import psutil
            process = psutil.Process(os.getpid())
            memory_mb = process.memory_info().rss / 1024 / 1024
            self.logger.debug(f"    ğŸ’¾ æ•°æ®åŠ è½½åå†…å­˜ä½¿ç”¨: {memory_mb:.1f} MB")
        except:
            pass
        
        # 2. ğŸ”¥ ä½¿ç”¨åŸç‰ˆV3è¯„ä¼°å™¨ç¡®ä¿é€»è¾‘ä¸€è‡´æ€§
        cta_evaluator = CTAEvaluatorV3(
            look_ahead=6,                 # âœ… åŸç‰ˆV3å‚æ•°
            entry_percentile=0.80,        # âœ… åŸç‰ˆV3å‚æ•°
            exit_percentile=0.20,         # âœ… åŸç‰ˆV3å‚æ•°
            sl_stop=0.02,
            tp_stop=0.03,
            direction='both',
            slippage=0.002,               # âœ… åŸç‰ˆV3å‚æ•°
            fees=0.001,                   # âœ… åŸç‰ˆV3å‚æ•°
            min_trades=10                 # âœ… åŸç‰ˆV3å‚æ•°
        )
        
        # è·å–æ‰€æœ‰å› å­åç§°
        all_factors = set()
        for factors_df in symbol_factors.values():
            all_factors.update(factors_df.columns)
        factor_names = list(all_factors)
        
        self.logger.info(f"  ğŸ”¢ å¼€å§‹CTAè¯„ä¼°{len(symbol_factors)}åªè‚¡ç¥¨ Ã— {len(factor_names)}ä¸ªå› å­")
        
        # 3. æ‰¹é‡CTAè¯„ä¼°
        cta_results = cta_evaluator.batch_evaluate(
            symbols=list(symbol_factors.keys()),
            factor_data=symbol_factors,
            price_data=symbol_data,
            factor_names=factor_names,
            timeframe=timeframe
        )
        
        if cta_results.empty:
            self.logger.warning(f"âŒ {timeframe} CTAè¯„ä¼°æ— ç»“æœ")
            return {}
        
        # è¯„ä¼°åå†…å­˜ç›‘æ§
        try:
            import psutil
            process = psutil.Process(os.getpid())
            memory_mb = process.memory_info().rss / 1024 / 1024
            self.logger.debug(f"    ğŸ’¾ CTAè¯„ä¼°åå†…å­˜ä½¿ç”¨: {memory_mb:.1f} MB")
        except:
            pass
        
        # 4. ç»“æœéªŒè¯
        self.logger.debug(f"    ğŸ“Š CTAè¯„ä¼°ç»“æœéªŒè¯:")
        self.logger.debug(f"      ç»“æœå½¢çŠ¶: {cta_results.shape}")
        self.logger.debug(f"      åˆ—å: {list(cta_results.columns)}")
        if 'sharpe' in cta_results.columns:
            sharpe_stats = cta_results['sharpe'].describe()
            self.logger.debug(f"      å¤æ™®ç‡ç»Ÿè®¡: å‡å€¼={sharpe_stats['mean']:.4f}, æœ€å¤§å€¼={sharpe_stats['max']:.4f}, ä¸­ä½æ•°={sharpe_stats['50%']:.4f}")
            valid_sharpe_count = (cta_results['sharpe'] > 0.01).sum()
            self.logger.debug(f"      æœ‰æ•ˆå¤æ™®ç‡(>0.01): {valid_sharpe_count}/{len(cta_results)} ({valid_sharpe_count/len(cta_results)*100:.1f}%)")
        if 'trades' in cta_results.columns:
            trade_stats = cta_results['trades'].describe()
            self.logger.debug(f"      äº¤æ˜“æ¬¡æ•°ç»Ÿè®¡: å‡å€¼={trade_stats['mean']:.1f}, æœ€å¤§å€¼={trade_stats['max']:.0f}, ä¸­ä½æ•°={trade_stats['50%']:.0f}")
        
        # 5. å› å­æ’å
        factor_ranking = cta_evaluator.rank_factors(
            cta_results, 
            rank_by='sharpe'
        )
        
        # 6. ç»Ÿè®¡æœ‰æ•ˆå› å­
        if factor_ranking.empty:
            valid_factors = pd.DataFrame()
        else:
            # æ£€æŸ¥åˆ—åæ˜¯å¦å­˜åœ¨
            sharpe_col = 'sharpe_mean' if 'sharpe_mean' in factor_ranking.columns else 'sharpe'
            if sharpe_col in factor_ranking.columns:
                valid_factors = factor_ranking[factor_ranking[sharpe_col] >= 0.05]
            else:
                valid_factors = factor_ranking.head(10)
        
        self.logger.info(f"  âœ… {timeframe} å‘ç°{len(valid_factors)}ä¸ªä¼˜è´¨å› å­ (å¤æ™®â‰¥0.05)")
        
        # ğŸ” Top5å› å­äººå·¥æŠ½æŸ¥
        if not factor_ranking.empty and len(factor_ranking) >= 1:
            top5 = factor_ranking.head(5)
            required_cols = ['factor', 'sharpe_mean', 'trades_sum', 'win_rate_mean']
            available_cols = [col for col in required_cols if col in top5.columns]
            
            # å¦‚æœåˆ—åä¸åŒï¼Œå°è¯•æ‰¾åˆ°å¯¹åº”çš„åˆ—
            col_mapping = {
                'sharpe_mean': 'sharpe' if 'sharpe' in top5.columns else 'sharpe_mean',
                'trades_sum': 'trades' if 'trades' in top5.columns else 'trades_sum', 
                'win_rate_mean': 'win_rate' if 'win_rate' in top5.columns else 'win_rate_mean'
            }
            
            display_cols = ['factor'] + [col_mapping.get(col, col) for col in required_cols[1:] if col_mapping.get(col, col) in top5.columns]
            
            self.logger.info(f"\nğŸ” {timeframe} Top5å› å­äººå·¥æŠ½æŸ¥:")
            self.logger.info("\n" + top5[display_cols].to_string(index=False))
            
            # å¼‚å¸¸å€¼è­¦å‘Š
            sharpe_col = col_mapping.get('sharpe_mean', 'sharpe_mean')
            trades_col = col_mapping.get('trades_sum', 'trades_sum')
            winrate_col = col_mapping.get('win_rate_mean', 'win_rate_mean')
            
            if sharpe_col in top5.columns:
                max_sharpe = top5[sharpe_col].max()
                min_sharpe = top5[sharpe_col].min()
                if max_sharpe > 0.8:
                    self.logger.warning(f"âš ï¸ å‘ç°è¶…é«˜å¤æ™®ç‡{max_sharpe:.3f}>0.8ï¼Œå¯èƒ½è¿‡æ‹Ÿåˆï¼")
                elif min_sharpe < 0.02:
                    self.logger.warning(f"âš ï¸ å‘ç°è¶…ä½å¤æ™®ç‡{min_sharpe:.3f}<0.02ï¼Œå¯èƒ½æ˜¯å™ªéŸ³ï¼")
                    
            if trades_col in top5.columns:
                min_trades = top5[trades_col].min()
                max_trades = top5[trades_col].max()
                if min_trades < 20:
                    self.logger.warning(f"âš ï¸ å‘ç°è¶…ä½äº¤æ˜“æ¬¡æ•°{min_trades}<20ï¼Œæ ·æœ¬ä¸è¶³ï¼")
                elif max_trades > 2000:
                    self.logger.warning(f"âš ï¸ å‘ç°è¶…é«˜äº¤æ˜“æ¬¡æ•°{max_trades}>2000ï¼Œä¿¡å·è¿‡å¯†ï¼")
                    
            if winrate_col in top5.columns:
                max_winrate = top5[winrate_col].max()
                if max_winrate > 0.6:
                    self.logger.warning(f"âš ï¸ å‘ç°è¶…é«˜èƒœç‡{max_winrate:.1%}>60%ï¼Œå¤æŸ¥æ˜¯å¦å·ä»·ï¼")
        
        return {
            'timeframe': timeframe,
            'cta_results': cta_results,
            'factor_ranking': factor_ranking,
            'valid_factors': valid_factors,
            'summary': {
                'tested_symbols': len(symbol_factors),
                'tested_factors': len(factor_names),
                'total_evaluations': len(cta_results),
                'valid_factors_count': len(valid_factors),
                'best_factor': factor_ranking.iloc[0]['factor'] if not factor_ranking.empty else None,
                'best_sharpe': factor_ranking.iloc[0]['sharpe_mean'] if not factor_ranking.empty else 0
            }
        }
    
    def run_optimized_test(self):
        """è¿è¡Œä¼˜åŒ–ç‰ˆæµ‹è¯•"""
        print("ğŸš€ å¯åŠ¨ä¼˜åŒ–ç‰ˆæœ€ç»ˆå·¥ä½œç³»ç»Ÿ...")
        start_time = time.time()
        
        self.logger.info("ä¼˜åŒ–ç‰ˆæµ‹è¯•å¼€å§‹")
        self.logger.info(f"  æµ‹è¯•æ—¶é—´æ¡†æ¶: {self.working_config['test_timeframes']}")
        self.logger.info(f"  æµ‹è¯•è‚¡ç¥¨: {self.test_symbols}")
        self.logger.info(f"  è¯„ä¼°æ¨¡å¼: {self.working_config['evaluation_mode'].upper()}")
        
        # ç»“æœåˆå§‹åŒ–
        results = {
            'execution_time': 0,
            'analysis_approach': 'optimized_final_working_v2',
            'tested_symbols': self.test_symbols,
            'tested_timeframes': self.working_config['test_timeframes'],
            'working_config': self.working_config,
            'timeframe_results': {}
        }
        
        # æŒ‰æ—¶é—´æ¡†æ¶åˆ†æ
        total_factors = 0
        evaluation_mode = self.working_config.get('evaluation_mode', 'cta')
        
        for timeframe in self.working_config['test_timeframes']:
            if evaluation_mode == 'cta':
                analysis_results = self._run_cta_analysis(timeframe)
                if analysis_results:
                    results['timeframe_results'][timeframe] = analysis_results
                    total_factors += analysis_results['summary']['valid_factors_count']
            
        # å®Œæˆç»Ÿè®¡
        execution_time = time.time() - start_time
        results['execution_time'] = execution_time
        
        self.logger.info(f"ä¼˜åŒ–ç‰ˆæµ‹è¯•å®Œæˆï¼Œè€—æ—¶{execution_time:.1f}ç§’")
        self.logger.info(f"æ€»æœ‰æ•ˆå› å­: {total_factors}ä¸ª")
        
        # ä¿å­˜ç»“æœ
        self._save_results(results)
        
        return results
    
    def _save_results(self, results: Dict):
        """ä¿å­˜ç»“æœ"""
        result_dir = f"results/optimized_final_{self.timestamp}"
        os.makedirs(result_dir, exist_ok=True)
        
        # ä¿å­˜JSONç»“æœ
        json_file = f"{result_dir}/optimized_final_results.json"
        with open(json_file, 'w', encoding='utf-8') as f:
            json.dump(results, f, ensure_ascii=False, indent=2, default=str)
        
        # ç”Ÿæˆç®€è¦æŠ¥å‘Š
        self._generate_summary_report(results, result_dir)
        
        self.logger.info(f"ç»“æœå·²ä¿å­˜åˆ°: {result_dir}")
    
    def _generate_summary_report(self, results: Dict, result_dir: str):
        """ç”Ÿæˆæ€»ç»“æŠ¥å‘Š"""
        report = [
            "# ğŸš€ ä¼˜åŒ–ç‰ˆæœ€ç»ˆå·¥ä½œç³»ç»Ÿæµ‹è¯•æŠ¥å‘Š",
            "",
            f"**æµ‹è¯•æ—¶é—´**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}",
            f"**æ‰§è¡Œæ—¶é—´**: {results['execution_time']:.1f}ç§’",
            f"**æµ‹è¯•è‚¡ç¥¨**: {len(results['tested_symbols'])}åª",
            f"**æµ‹è¯•æ—¶é—´æ¡†æ¶**: {len(results['tested_timeframes'])}ä¸ª",
            "",
            "## ğŸ“Š ç»“æœç»Ÿè®¡",
            ""
        ]
        
        timeframe_results = results.get('timeframe_results', {})
        
        if timeframe_results:
            report.append("| æ—¶é—´æ¡†æ¶ | æœ‰æ•ˆå› å­æ•° | ä¼˜ç§€å› å­ | æœ€ä½³å¤æ™®ç‡ |")
            report.append("|----------|------------|----------|------------|")
            
            total_factors = 0
            
            for tf, result_data in timeframe_results.items():
                factor_count = result_data['summary']['valid_factors_count']
                total_factors += factor_count
                
                # ç»Ÿè®¡ä¼˜ç§€å› å­ (å¤æ™®>0.5)
                valid_factors = result_data.get('valid_factors', pd.DataFrame())
                if not valid_factors.empty and 'sharpe_mean' in valid_factors.columns:
                    excellent_factors = len(valid_factors[valid_factors['sharpe_mean'] > 0.5])
                    best_sharpe = valid_factors['sharpe_mean'].max() if not valid_factors.empty else 0
                else:
                    excellent_factors = 0
                    best_sharpe = 0
                
                report.append(f"| {tf} | {factor_count} | {excellent_factors} | {best_sharpe:.3f} |")
            
            report.extend([
                "",
                f"**æ€»è®¡**: {total_factors}ä¸ªæœ‰æ•ˆå› å­",
                ""
            ])
            
            # æ˜¾ç¤ºæœ€ä½³å› å­
            all_factors = []
            
            for tf, result_data in timeframe_results.items():
                factor_ranking = result_data.get('factor_ranking', pd.DataFrame())
                if not factor_ranking.empty:
                    for _, row in factor_ranking.head(10).iterrows():
                        all_factors.append({
                            'name': row.get('factor', 'unknown'),
                            'timeframe': tf,
                            'sharpe': row.get('sharpe_mean', 0),
                            'win_rate': row.get('win_rate_mean', 0),
                            'trades': row.get('trades_sum', 0)
                        })
            
            if all_factors:
                all_factors.sort(key=lambda x: x['sharpe'], reverse=True)
                
                report.extend([
                    "## ğŸ† æœ€ä½³å› å­ (Top 10)",
                    "",
                    "| æ’å | å› å­åç§° | æ—¶é—´æ¡†æ¶ | å¤æ™®ç‡ | èƒœç‡ | äº¤æ˜“æ¬¡æ•° |",
                    "|------|----------|----------|--------|------|----------|"
                ])
                
                for i, factor in enumerate(all_factors[:10], 1):
                    report.append(
                        f"| {i} | {factor['name']} | {factor['timeframe']} | "
                        f"{factor['sharpe']:.3f} | {factor['win_rate']:.1%} | {factor['trades']:.0f} |"
                    )
        else:
            report.append("âŒ æœªå‘ç°æœ‰æ•ˆå› å­")
        
        # å†™å…¥æŠ¥å‘Š
        report_content = "\n".join(report)
        report_file = f"{result_dir}/optimized_final_report.md"
        with open(report_file, 'w', encoding='utf-8') as f:
            f.write(report_content)

def main():
    """ä¸»å‡½æ•°"""
    # è®¾ç½®éšæœºç§å­ç¡®ä¿ç»“æœå¯å¤ç°
    np.random.seed(42)
    
    print("ğŸš€ ä¼˜åŒ–ç‰ˆæœ€ç»ˆå·¥ä½œç³»ç»Ÿ V2.0")
    print("ğŸ“ åŸºäºåŸç‰ˆé€»è¾‘ï¼Œé›†æˆå‘é‡åŒ–ä¼˜åŒ–")
    print("=" * 50)
    
    optimized_analyzer = OptimizedFinalWorking()
    results = optimized_analyzer.run_optimized_test()
    
    if results:
        print("\nğŸ‰ ä¼˜åŒ–ç‰ˆæµ‹è¯•å®Œæˆï¼")
        
        timeframe_results = results.get('timeframe_results', {})
        total_factors = sum(result_data['summary']['valid_factors_count'] for result_data in timeframe_results.values())
        
        print(f"ğŸ¯ CTAå›æµ‹æ¨¡å¼: å‘ç°{total_factors}ä¸ªä¼˜è´¨å› å­ (å¤æ™®â‰¥0.05)")
        print(f"ğŸ“Š è¯„ä¼°ç»´åº¦: å¤æ™®ç‡ã€èƒœç‡ã€ç›ˆäºæ¯”ã€äº¤æ˜“æ¬¡æ•°")
        print(f"âš¡ è¦†ç›–{len(timeframe_results)}ä¸ªæ—¶é—´æ¡†æ¶")
        print(f"ğŸ“ˆ æµ‹è¯•{len(results['tested_symbols'])}åªè‚¡ç¥¨")
        
        if total_factors > 0:
            print("âœ… ä¼˜åŒ–ç‰ˆç³»ç»Ÿæ­£å¸¸å·¥ä½œï¼")
            print(f"âš¡ æ€§èƒ½æå‡ï¼šé›†æˆå‘é‡åŒ–æŠ€æœ¯")
            print(f"ğŸ›¡ï¸ ç¨³å®šæ€§ï¼šä¿æŒåŸç‰ˆV3é€»è¾‘")
        else:
            print("âŒ ä»éœ€è¿›ä¸€æ­¥è°ƒè¯•...")

if __name__ == "__main__":
    main()
